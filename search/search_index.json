{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Optuna-ExternM Quick Start See the quick start example in the user guide. Installation Installing from source Clone the repository Text Only git clone http://github.com/trhallam/optuna-externm and install using pip Text Only cd optuna-externm pip install .","title":"About"},{"location":"index.html#optuna-externm","text":"","title":"Optuna-ExternM"},{"location":"index.html#quick-start","text":"See the quick start example in the user guide.","title":"Quick Start"},{"location":"index.html#installation","text":"","title":"Installation"},{"location":"index.html#installing-from-source","text":"Clone the repository Text Only git clone http://github.com/trhallam/optuna-externm and install using pip Text Only cd optuna-externm pip install .","title":"Installing from source"},{"location":"contact.html","text":"","title":"Contact"},{"location":"contrib.html","text":"","title":"Contributing"},{"location":"api/core.html","text":"optuna_externm.core BaseModelHandler Attributes: Name Type Description popt pd.DataFrame Optimisation Parameters Source code in optuna_externm/core/_bmh.py Python class BaseModelHandler : \"\"\" Attributes: popt (pd.DataFrame): Optimisation Parameters \"\"\" __maxfitness__ = 2000000000 __req_parameter_attr = set ( ( \"NAME\" , # index column should be PROP name \"LOW\" , # minimum search value for prop \"HIGH\" , # maximum search value for prop \"DEF\" , # default search value or initial guess \"DIST\" , # distribution function - if missing defaults to UNIFORM ) ) _equality_tokens = bidict ( { \"__lt__\" : \"<\" , \"__gt__\" : \">\" , \"__eq__\" : \"==\" , \"__le__\" : \"<=\" , \"__ge__\" : \">=\" , \"__ne__\" : \"!=\" , } ) _equality_tokenizer = re . compile ( r \"(==|!=|>=|<=|<|>)\" ) _optuna_dist_mapping = { \"UNIFORM\" : \"suggest_uniform\" , \"FLOAT\" : \"suggest_float\" , \"INT\" : \"suggest_int\" , \"LOGUNIFORM\" : \"suggest_loguniform\" , \"DISCRETE_UNIFORM\" : \"suggest_discrete_uniform\" , \"CATEGORICAL\" : \"suggest_categorical\" , } def __init__ ( self , results_dir = None ): \"\"\" Args: logger (str): The name to use for logging this handler. \"\"\" if results_dir is None : self . results_dir = pathlib . Path ( \".\" ) else : self . results_dir = pathlib . Path ( results_dir ) self . initialisers = OrderedDict () self . finalisers = OrderedDict () self . evaluators = OrderedDict () self . objectives = dict () self . transforms = dict () self . inverse_transforms = dict () self . set_finess = None self . evaluator_stats = list () self . log_keys = list () self . param = None self . param_list = list () self . param_cnstr = dict () self . nopt = 0 self . no_constraints = False self . no_transform = False def _register ( self , stage , alias , function , * args , ** kargs ): \"\"\"Genertic register function adds function to stage. Args: stage (str): accepted stages are ['initialisers', 'finalisers', 'evaluators'] \"\"\" pfunc = partial ( function , * args , ** kargs ) pfunc . __name__ = alias pfunc . __doc__ = function . __doc__ if hasattr ( function , \"__dict__\" ) and not isinstance ( function , type ): # Some functions don't have a dictionary, in these cases # simply don't copy it. Moreover, if the function is actually # a class, we do not want to copy the dictionary. pfunc . __dict__ . update ( function . __dict__ . copy ()) setattr ( self , alias , pfunc ) self . __dict__ [ stage ][ alias ] = self . __dict__ [ alias ] def register_evaluator ( self , alias , function , * args , ** kargs ): \"\"\"Register an evaluation *function* to the handler to be used for optimisation under the name *alias*. Default arguments will be passed automatically when calling the registered function. Fixed arguments can then be overriden at function call time. All of the registered evaluators will be used in the objective updating function in the order that they are registered. This is important if evaluators depend on the output of other evaluators. Original code and method inspiration from DEAP.Toolbox Args: alias (str): The name the function will have in the handler. If the fname already exist it will overwrite the the function already registered. function (func): The function referred to by alias, the first argument is the reference data or a function to return the reference data, the second argument is the data to compare. args/kwargs (optional) : Special arguments and keyword arguments to pass to function. Example: The following code block is an example of how this function is used. .. highlight:: python .. code-block:: console >>> def func(a, b, c=3): ... print a, b, c ... >>> model = BaseModelHandler() >>> model.register_evaluator(\"myFunc\", func, 2, c=4) >>> model.myFunc(3) 2 3 4 >>> model.evaluators {\"muFunc\": func} The registered function will be given the attributes :attr:`__name__` set to the fname and :attr:`__doc__` set to the original function's documentation. The :attr:`__dict__` attribute will also be updated with the original function's instance dictionary, if any. \"\"\" self . _register ( \"evaluators\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as evaluator\" ) def register_initialiser ( self , alias , function , * args , ** kargs ): \"\"\"Register an initialisation *function* to the handler to be used prior to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"initialisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as initialiser\" ) def register_finaliser ( self , alias , function , * args , ** kargs ): \"\"\"Register a finalisation *function* to the handler to be used after to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"finalisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as finaliser\" ) def _unregister ( self , stage , alias ): \"\"\"Unregister *alias* from stage. Args: stage (str): The name of the stage to look for alias in. Valid stages are ['initisers', 'finalisers', 'evaluators'] alias (str): The name of the operator to remove from the model. \"\"\" _ = self . __dict__ [ stage ] . pop ( alias ) delattr ( self , alias ) def unregister_evaluator ( self , alias ): \"\"\"Unregister an evalautor function. Args: alias (str): The name of the operator to remove from the model. \"\"\" self . _unregister ( \"evaluators\" , alias ) logger . info ( f \" { alias } unregistered as evaluator\" ) def unregister_initialiser ( self , alias ): \"\"\"Unregister an initialiser function. Args: alias (str): The name of the initialiser function to remove from the model. \"\"\" self . _unregister ( \"initialisers\" , alias ) logger . info ( f \" { alias } unregistered as initisaliser\" ) def unregister_finaliser ( self , alias ): \"\"\"Unregister a finaliser function. Args: alias (str): The name of the finaliser function to remove from the model. \"\"\" self . _unregister ( \"finalisers\" , alias ) logger . info ( f \" { alias } unregistered as finaliser\" ) def unregister_transform ( self , alias ): \"\"\"Unregister a transform function. Args: alias (str): The name of the function to remove from the model. \"\"\" self . _unregister ( \"transforms\" , alias ) self . _unregister ( \"inverse_transforms\" , alias ) logger . info ( f \" { alias } unregistered as transform\" ) def set_param ( self , parameters ): \"\"\"Set the parameters of the problem to be solved. Minimum properties for each tuples are PROP, PMIN, PMAX, DIST Args: parameters: Optimisation parameters definitions as namedtuples. Notes: The load csv function in the optuna.externm.utils module can be used to load and create the input to this method from a CSV file. \"\"\" missing_params = [] for param in parameters : if not self . __req_parameter_attr . issubset ( set ( param . _fields )): missing_params . append ( set ( param . _fields ) . difference ( self . __req_parameter_attr ) ) logger . debug ( f \"Malformed parameter: { param } \" ) if missing_params : logger . error ( f \"The parameter definition was malformed, missing: { missing_params } \" ) raise SystemExit # if \"DIST\" not in param.columns: # param[\"DIST\"] = \"UNIFORM\" # logger.info( # \"No parameter distribution specified, all parameters \" # \"being transformed with UNIFORM distribution\" # ) # if \"TYPE\" not in param.columns: # param[\"TYPE\"] = \"NUMERIC\" # logger.info( # \"No parameter distribution types specified, all parameters \" # \"assumed to have type NUMERIC.\" # ) # # dealing with parameter constraints # if \"CONSTRAINT\" not in param.columns or self.no_constraints: # param[\"CONSTRAINT\"] = numpy.nan # else: # for par, row in param.dropna(subset=[\"CONSTRAINT\"]).iterrows(): # tok = self._equality_tokenizer.split(row[\"CONSTRAINT\"]) # tok = [t.strip() for t in tok if t != \"\"] # for i, t in enumerate(tok): # try: # tok[i] = self._equality_tokens.inverse[t][0] # except KeyError: # pass # self.param_cnstr[par] = [t for t in zip(tok[0::2], tok[1::2])] self . parameters = parameters self . param_list = [ p . NAME for p in self . parameters ] self . nopt = len ( self . parameters ) logger . info ( f \"Model has { self . nopt } optimisation parameters\" ) def initialise ( self ): \"\"\"Initialise the model by calling functions registered for initialisation.\"\"\" for init in self . initialisers : self . initialisers [ init ]() def finalise ( self ): \"\"\"Finalise the model by calling functions registered for finalisation.\"\"\" for fini in self . finalisers : self . finalisers [ fini ]() def evaluate ( self , results = None ): \"\"\"Run the evaluation functions. Usually this is performed by the optimiser. Use this function to run tests on your model or to perform debugging. Args: results (dict): The dictionary to pass between evaluators. Returns: (dict): Updated results dictionary. \"\"\" if results is None : results = dict () for evl in self . evaluators : results . update ( self . evaluators [ evl ]( results = results )) return results def log_values ( self , log_list = None ): \"\"\"Select values to log for each trial. These must be keys available within your results parser between evaluators by the end of each individuals evaluation. They should also be simple types. Arguments: log_list (list): List of results keys (str) to report on. \"\"\" # 'fit' will always be reported. Defaults to None: Only fit will # be reported. # In multi-objective cases the optimiser will reduce fit of tuple to # fit1, fit2, ..., fitn if log_list is not None : self . log_keys = list ({ \"fit\" } . union ( set ( log_list ))) self . evaluator_stats = list ({ \"fit\" } . union ( set ( log_list ))) else : self . log_keys = [ \"fit\" ] self . evaluator_stats = [ \"fit\" ] def objective_function ( self ): \"\"\"Returns the final objective function for Optuna Studies\"\"\" def objective ( trial ): p = { param . NAME : getattr ( trial , self . _optuna_dist_mapping [ param . DIST ])( param . NAME , param . LOW , param . HIGH ) for param in self . parameters } res = { \"p\" : p , \"trial_number\" : trial . number } res . update ( trial . study . user_attrs ) results = self . evaluate ( results = res ) for key in self . log_keys : try : trial . set_user_attr ( key , results [ key ]) except KeyError : pass return results [ \"fit\" ] return objective __init__ ( self , results_dir = None ) special Parameters: Name Type Description Default logger str The name to use for logging this handler. required Source code in optuna_externm/core/_bmh.py Python def __init__ ( self , results_dir = None ): \"\"\" Args: logger (str): The name to use for logging this handler. \"\"\" if results_dir is None : self . results_dir = pathlib . Path ( \".\" ) else : self . results_dir = pathlib . Path ( results_dir ) self . initialisers = OrderedDict () self . finalisers = OrderedDict () self . evaluators = OrderedDict () self . objectives = dict () self . transforms = dict () self . inverse_transforms = dict () self . set_finess = None self . evaluator_stats = list () self . log_keys = list () self . param = None self . param_list = list () self . param_cnstr = dict () self . nopt = 0 self . no_constraints = False self . no_transform = False evaluate ( self , results = None ) Run the evaluation functions. Usually this is performed by the optimiser. Use this function to run tests on your model or to perform debugging. Parameters: Name Type Description Default results dict The dictionary to pass between evaluators. None Returns: Type Description (dict) Updated results dictionary. Source code in optuna_externm/core/_bmh.py Python def evaluate ( self , results = None ): \"\"\"Run the evaluation functions. Usually this is performed by the optimiser. Use this function to run tests on your model or to perform debugging. Args: results (dict): The dictionary to pass between evaluators. Returns: (dict): Updated results dictionary. \"\"\" if results is None : results = dict () for evl in self . evaluators : results . update ( self . evaluators [ evl ]( results = results )) return results finalise ( self ) Finalise the model by calling functions registered for finalisation. Source code in optuna_externm/core/_bmh.py Python def finalise ( self ): \"\"\"Finalise the model by calling functions registered for finalisation.\"\"\" for fini in self . finalisers : self . finalisers [ fini ]() initialise ( self ) Initialise the model by calling functions registered for initialisation. Source code in optuna_externm/core/_bmh.py Python def initialise ( self ): \"\"\"Initialise the model by calling functions registered for initialisation.\"\"\" for init in self . initialisers : self . initialisers [ init ]() log_values ( self , log_list = None ) Select values to log for each trial. These must be keys available within your results parser between evaluators by the end of each individuals evaluation. They should also be simple types. Parameters: Name Type Description Default log_list list List of results keys (str) to report on. None Source code in optuna_externm/core/_bmh.py Python def log_values ( self , log_list = None ): \"\"\"Select values to log for each trial. These must be keys available within your results parser between evaluators by the end of each individuals evaluation. They should also be simple types. Arguments: log_list (list): List of results keys (str) to report on. \"\"\" # 'fit' will always be reported. Defaults to None: Only fit will # be reported. # In multi-objective cases the optimiser will reduce fit of tuple to # fit1, fit2, ..., fitn if log_list is not None : self . log_keys = list ({ \"fit\" } . union ( set ( log_list ))) self . evaluator_stats = list ({ \"fit\" } . union ( set ( log_list ))) else : self . log_keys = [ \"fit\" ] self . evaluator_stats = [ \"fit\" ] objective_function ( self ) Returns the final objective function for Optuna Studies Source code in optuna_externm/core/_bmh.py Python def objective_function ( self ): \"\"\"Returns the final objective function for Optuna Studies\"\"\" def objective ( trial ): p = { param . NAME : getattr ( trial , self . _optuna_dist_mapping [ param . DIST ])( param . NAME , param . LOW , param . HIGH ) for param in self . parameters } res = { \"p\" : p , \"trial_number\" : trial . number } res . update ( trial . study . user_attrs ) results = self . evaluate ( results = res ) for key in self . log_keys : try : trial . set_user_attr ( key , results [ key ]) except KeyError : pass return results [ \"fit\" ] return objective register_evaluator ( self , alias , function , * args , ** kargs ) Register an evaluation function to the handler to be used for optimisation under the name alias . Default arguments will be passed automatically when calling the registered function. Fixed arguments can then be overriden at function call time. All of the registered evaluators will be used in the objective updating function in the order that they are registered. This is important if evaluators depend on the output of other evaluators. Original code and method inspiration from DEAP.Toolbox Parameters: Name Type Description Default alias str The name the function will have in the handler. If the fname already exist it will overwrite the the function already registered. required function func The function referred to by alias, the first argument is the reference data or a function to return the reference data, the second argument is the data to compare. required args/kwargs optional) Special arguments and keyword arguments to pass to function. required Examples: The following code block is an example of how this function is used. .. highlight:: python .. code-block:: console Python >>> def func ( a , b , c = 3 ): ... print a , b , c ... >>> model = BaseModelHandler () >>> model . register_evaluator ( \"myFunc\" , func , 2 , c = 4 ) >>> model . myFunc ( 3 ) 2 3 4 >>> model . evaluators { \"muFunc\" : func } The registered function will be given the attributes :attr: __name__ set to the fname and :attr: __doc__ set to the original function's documentation. The :attr: __dict__ attribute will also be updated with the original function's instance dictionary, if any. Source code in optuna_externm/core/_bmh.py Python def register_evaluator ( self , alias , function , * args , ** kargs ): \"\"\"Register an evaluation *function* to the handler to be used for optimisation under the name *alias*. Default arguments will be passed automatically when calling the registered function. Fixed arguments can then be overriden at function call time. All of the registered evaluators will be used in the objective updating function in the order that they are registered. This is important if evaluators depend on the output of other evaluators. Original code and method inspiration from DEAP.Toolbox Args: alias (str): The name the function will have in the handler. If the fname already exist it will overwrite the the function already registered. function (func): The function referred to by alias, the first argument is the reference data or a function to return the reference data, the second argument is the data to compare. args/kwargs (optional) : Special arguments and keyword arguments to pass to function. Example: The following code block is an example of how this function is used. .. highlight:: python .. code-block:: console >>> def func(a, b, c=3): ... print a, b, c ... >>> model = BaseModelHandler() >>> model.register_evaluator(\"myFunc\", func, 2, c=4) >>> model.myFunc(3) 2 3 4 >>> model.evaluators {\"muFunc\": func} The registered function will be given the attributes :attr:`__name__` set to the fname and :attr:`__doc__` set to the original function's documentation. The :attr:`__dict__` attribute will also be updated with the original function's instance dictionary, if any. \"\"\" self . _register ( \"evaluators\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as evaluator\" ) register_finaliser ( self , alias , function , * args , ** kargs ) Register a finalisation function to the handler to be used after to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator Source code in optuna_externm/core/_bmh.py Python def register_finaliser ( self , alias , function , * args , ** kargs ): \"\"\"Register a finalisation *function* to the handler to be used after to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"finalisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as finaliser\" ) register_initialiser ( self , alias , function , * args , ** kargs ) Register an initialisation function to the handler to be used prior to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator Source code in optuna_externm/core/_bmh.py Python def register_initialiser ( self , alias , function , * args , ** kargs ): \"\"\"Register an initialisation *function* to the handler to be used prior to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"initialisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as initialiser\" ) set_param ( self , parameters ) Set the parameters of the problem to be solved. Minimum properties for each tuples are PROP, PMIN, PMAX, DIST Parameters: Name Type Description Default parameters Optimisation parameters definitions as namedtuples. required Notes The load csv function in the optuna.externm.utils module can be used to load and create the input to this method from a CSV file. Source code in optuna_externm/core/_bmh.py Python def set_param ( self , parameters ): \"\"\"Set the parameters of the problem to be solved. Minimum properties for each tuples are PROP, PMIN, PMAX, DIST Args: parameters: Optimisation parameters definitions as namedtuples. Notes: The load csv function in the optuna.externm.utils module can be used to load and create the input to this method from a CSV file. \"\"\" missing_params = [] for param in parameters : if not self . __req_parameter_attr . issubset ( set ( param . _fields )): missing_params . append ( set ( param . _fields ) . difference ( self . __req_parameter_attr ) ) logger . debug ( f \"Malformed parameter: { param } \" ) if missing_params : logger . error ( f \"The parameter definition was malformed, missing: { missing_params } \" ) raise SystemExit # if \"DIST\" not in param.columns: # param[\"DIST\"] = \"UNIFORM\" # logger.info( # \"No parameter distribution specified, all parameters \" # \"being transformed with UNIFORM distribution\" # ) # if \"TYPE\" not in param.columns: # param[\"TYPE\"] = \"NUMERIC\" # logger.info( # \"No parameter distribution types specified, all parameters \" # \"assumed to have type NUMERIC.\" # ) # # dealing with parameter constraints # if \"CONSTRAINT\" not in param.columns or self.no_constraints: # param[\"CONSTRAINT\"] = numpy.nan # else: # for par, row in param.dropna(subset=[\"CONSTRAINT\"]).iterrows(): # tok = self._equality_tokenizer.split(row[\"CONSTRAINT\"]) # tok = [t.strip() for t in tok if t != \"\"] # for i, t in enumerate(tok): # try: # tok[i] = self._equality_tokens.inverse[t][0] # except KeyError: # pass # self.param_cnstr[par] = [t for t in zip(tok[0::2], tok[1::2])] self . parameters = parameters self . param_list = [ p . NAME for p in self . parameters ] self . nopt = len ( self . parameters ) logger . info ( f \"Model has { self . nopt } optimisation parameters\" ) unregister_evaluator ( self , alias ) Unregister an evalautor function. Parameters: Name Type Description Default alias str The name of the operator to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_evaluator ( self , alias ): \"\"\"Unregister an evalautor function. Args: alias (str): The name of the operator to remove from the model. \"\"\" self . _unregister ( \"evaluators\" , alias ) logger . info ( f \" { alias } unregistered as evaluator\" ) unregister_finaliser ( self , alias ) Unregister a finaliser function. Parameters: Name Type Description Default alias str The name of the finaliser function to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_finaliser ( self , alias ): \"\"\"Unregister a finaliser function. Args: alias (str): The name of the finaliser function to remove from the model. \"\"\" self . _unregister ( \"finalisers\" , alias ) logger . info ( f \" { alias } unregistered as finaliser\" ) unregister_initialiser ( self , alias ) Unregister an initialiser function. Parameters: Name Type Description Default alias str The name of the initialiser function to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_initialiser ( self , alias ): \"\"\"Unregister an initialiser function. Args: alias (str): The name of the initialiser function to remove from the model. \"\"\" self . _unregister ( \"initialisers\" , alias ) logger . info ( f \" { alias } unregistered as initisaliser\" ) unregister_transform ( self , alias ) Unregister a transform function. Parameters: Name Type Description Default alias str The name of the function to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_transform ( self , alias ): \"\"\"Unregister a transform function. Args: alias (str): The name of the function to remove from the model. \"\"\" self . _unregister ( \"transforms\" , alias ) self . _unregister ( \"inverse_transforms\" , alias ) logger . info ( f \" { alias } unregistered as transform\" )","title":"Core"},{"location":"api/core.html#optuna_externmcore","text":"","title":"optuna_externm.core"},{"location":"api/core.html#basemodelhandler","text":"Attributes: Name Type Description popt pd.DataFrame Optimisation Parameters Source code in optuna_externm/core/_bmh.py Python class BaseModelHandler : \"\"\" Attributes: popt (pd.DataFrame): Optimisation Parameters \"\"\" __maxfitness__ = 2000000000 __req_parameter_attr = set ( ( \"NAME\" , # index column should be PROP name \"LOW\" , # minimum search value for prop \"HIGH\" , # maximum search value for prop \"DEF\" , # default search value or initial guess \"DIST\" , # distribution function - if missing defaults to UNIFORM ) ) _equality_tokens = bidict ( { \"__lt__\" : \"<\" , \"__gt__\" : \">\" , \"__eq__\" : \"==\" , \"__le__\" : \"<=\" , \"__ge__\" : \">=\" , \"__ne__\" : \"!=\" , } ) _equality_tokenizer = re . compile ( r \"(==|!=|>=|<=|<|>)\" ) _optuna_dist_mapping = { \"UNIFORM\" : \"suggest_uniform\" , \"FLOAT\" : \"suggest_float\" , \"INT\" : \"suggest_int\" , \"LOGUNIFORM\" : \"suggest_loguniform\" , \"DISCRETE_UNIFORM\" : \"suggest_discrete_uniform\" , \"CATEGORICAL\" : \"suggest_categorical\" , } def __init__ ( self , results_dir = None ): \"\"\" Args: logger (str): The name to use for logging this handler. \"\"\" if results_dir is None : self . results_dir = pathlib . Path ( \".\" ) else : self . results_dir = pathlib . Path ( results_dir ) self . initialisers = OrderedDict () self . finalisers = OrderedDict () self . evaluators = OrderedDict () self . objectives = dict () self . transforms = dict () self . inverse_transforms = dict () self . set_finess = None self . evaluator_stats = list () self . log_keys = list () self . param = None self . param_list = list () self . param_cnstr = dict () self . nopt = 0 self . no_constraints = False self . no_transform = False def _register ( self , stage , alias , function , * args , ** kargs ): \"\"\"Genertic register function adds function to stage. Args: stage (str): accepted stages are ['initialisers', 'finalisers', 'evaluators'] \"\"\" pfunc = partial ( function , * args , ** kargs ) pfunc . __name__ = alias pfunc . __doc__ = function . __doc__ if hasattr ( function , \"__dict__\" ) and not isinstance ( function , type ): # Some functions don't have a dictionary, in these cases # simply don't copy it. Moreover, if the function is actually # a class, we do not want to copy the dictionary. pfunc . __dict__ . update ( function . __dict__ . copy ()) setattr ( self , alias , pfunc ) self . __dict__ [ stage ][ alias ] = self . __dict__ [ alias ] def register_evaluator ( self , alias , function , * args , ** kargs ): \"\"\"Register an evaluation *function* to the handler to be used for optimisation under the name *alias*. Default arguments will be passed automatically when calling the registered function. Fixed arguments can then be overriden at function call time. All of the registered evaluators will be used in the objective updating function in the order that they are registered. This is important if evaluators depend on the output of other evaluators. Original code and method inspiration from DEAP.Toolbox Args: alias (str): The name the function will have in the handler. If the fname already exist it will overwrite the the function already registered. function (func): The function referred to by alias, the first argument is the reference data or a function to return the reference data, the second argument is the data to compare. args/kwargs (optional) : Special arguments and keyword arguments to pass to function. Example: The following code block is an example of how this function is used. .. highlight:: python .. code-block:: console >>> def func(a, b, c=3): ... print a, b, c ... >>> model = BaseModelHandler() >>> model.register_evaluator(\"myFunc\", func, 2, c=4) >>> model.myFunc(3) 2 3 4 >>> model.evaluators {\"muFunc\": func} The registered function will be given the attributes :attr:`__name__` set to the fname and :attr:`__doc__` set to the original function's documentation. The :attr:`__dict__` attribute will also be updated with the original function's instance dictionary, if any. \"\"\" self . _register ( \"evaluators\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as evaluator\" ) def register_initialiser ( self , alias , function , * args , ** kargs ): \"\"\"Register an initialisation *function* to the handler to be used prior to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"initialisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as initialiser\" ) def register_finaliser ( self , alias , function , * args , ** kargs ): \"\"\"Register a finalisation *function* to the handler to be used after to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"finalisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as finaliser\" ) def _unregister ( self , stage , alias ): \"\"\"Unregister *alias* from stage. Args: stage (str): The name of the stage to look for alias in. Valid stages are ['initisers', 'finalisers', 'evaluators'] alias (str): The name of the operator to remove from the model. \"\"\" _ = self . __dict__ [ stage ] . pop ( alias ) delattr ( self , alias ) def unregister_evaluator ( self , alias ): \"\"\"Unregister an evalautor function. Args: alias (str): The name of the operator to remove from the model. \"\"\" self . _unregister ( \"evaluators\" , alias ) logger . info ( f \" { alias } unregistered as evaluator\" ) def unregister_initialiser ( self , alias ): \"\"\"Unregister an initialiser function. Args: alias (str): The name of the initialiser function to remove from the model. \"\"\" self . _unregister ( \"initialisers\" , alias ) logger . info ( f \" { alias } unregistered as initisaliser\" ) def unregister_finaliser ( self , alias ): \"\"\"Unregister a finaliser function. Args: alias (str): The name of the finaliser function to remove from the model. \"\"\" self . _unregister ( \"finalisers\" , alias ) logger . info ( f \" { alias } unregistered as finaliser\" ) def unregister_transform ( self , alias ): \"\"\"Unregister a transform function. Args: alias (str): The name of the function to remove from the model. \"\"\" self . _unregister ( \"transforms\" , alias ) self . _unregister ( \"inverse_transforms\" , alias ) logger . info ( f \" { alias } unregistered as transform\" ) def set_param ( self , parameters ): \"\"\"Set the parameters of the problem to be solved. Minimum properties for each tuples are PROP, PMIN, PMAX, DIST Args: parameters: Optimisation parameters definitions as namedtuples. Notes: The load csv function in the optuna.externm.utils module can be used to load and create the input to this method from a CSV file. \"\"\" missing_params = [] for param in parameters : if not self . __req_parameter_attr . issubset ( set ( param . _fields )): missing_params . append ( set ( param . _fields ) . difference ( self . __req_parameter_attr ) ) logger . debug ( f \"Malformed parameter: { param } \" ) if missing_params : logger . error ( f \"The parameter definition was malformed, missing: { missing_params } \" ) raise SystemExit # if \"DIST\" not in param.columns: # param[\"DIST\"] = \"UNIFORM\" # logger.info( # \"No parameter distribution specified, all parameters \" # \"being transformed with UNIFORM distribution\" # ) # if \"TYPE\" not in param.columns: # param[\"TYPE\"] = \"NUMERIC\" # logger.info( # \"No parameter distribution types specified, all parameters \" # \"assumed to have type NUMERIC.\" # ) # # dealing with parameter constraints # if \"CONSTRAINT\" not in param.columns or self.no_constraints: # param[\"CONSTRAINT\"] = numpy.nan # else: # for par, row in param.dropna(subset=[\"CONSTRAINT\"]).iterrows(): # tok = self._equality_tokenizer.split(row[\"CONSTRAINT\"]) # tok = [t.strip() for t in tok if t != \"\"] # for i, t in enumerate(tok): # try: # tok[i] = self._equality_tokens.inverse[t][0] # except KeyError: # pass # self.param_cnstr[par] = [t for t in zip(tok[0::2], tok[1::2])] self . parameters = parameters self . param_list = [ p . NAME for p in self . parameters ] self . nopt = len ( self . parameters ) logger . info ( f \"Model has { self . nopt } optimisation parameters\" ) def initialise ( self ): \"\"\"Initialise the model by calling functions registered for initialisation.\"\"\" for init in self . initialisers : self . initialisers [ init ]() def finalise ( self ): \"\"\"Finalise the model by calling functions registered for finalisation.\"\"\" for fini in self . finalisers : self . finalisers [ fini ]() def evaluate ( self , results = None ): \"\"\"Run the evaluation functions. Usually this is performed by the optimiser. Use this function to run tests on your model or to perform debugging. Args: results (dict): The dictionary to pass between evaluators. Returns: (dict): Updated results dictionary. \"\"\" if results is None : results = dict () for evl in self . evaluators : results . update ( self . evaluators [ evl ]( results = results )) return results def log_values ( self , log_list = None ): \"\"\"Select values to log for each trial. These must be keys available within your results parser between evaluators by the end of each individuals evaluation. They should also be simple types. Arguments: log_list (list): List of results keys (str) to report on. \"\"\" # 'fit' will always be reported. Defaults to None: Only fit will # be reported. # In multi-objective cases the optimiser will reduce fit of tuple to # fit1, fit2, ..., fitn if log_list is not None : self . log_keys = list ({ \"fit\" } . union ( set ( log_list ))) self . evaluator_stats = list ({ \"fit\" } . union ( set ( log_list ))) else : self . log_keys = [ \"fit\" ] self . evaluator_stats = [ \"fit\" ] def objective_function ( self ): \"\"\"Returns the final objective function for Optuna Studies\"\"\" def objective ( trial ): p = { param . NAME : getattr ( trial , self . _optuna_dist_mapping [ param . DIST ])( param . NAME , param . LOW , param . HIGH ) for param in self . parameters } res = { \"p\" : p , \"trial_number\" : trial . number } res . update ( trial . study . user_attrs ) results = self . evaluate ( results = res ) for key in self . log_keys : try : trial . set_user_attr ( key , results [ key ]) except KeyError : pass return results [ \"fit\" ] return objective","title":"BaseModelHandler"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.__init__","text":"Parameters: Name Type Description Default logger str The name to use for logging this handler. required Source code in optuna_externm/core/_bmh.py Python def __init__ ( self , results_dir = None ): \"\"\" Args: logger (str): The name to use for logging this handler. \"\"\" if results_dir is None : self . results_dir = pathlib . Path ( \".\" ) else : self . results_dir = pathlib . Path ( results_dir ) self . initialisers = OrderedDict () self . finalisers = OrderedDict () self . evaluators = OrderedDict () self . objectives = dict () self . transforms = dict () self . inverse_transforms = dict () self . set_finess = None self . evaluator_stats = list () self . log_keys = list () self . param = None self . param_list = list () self . param_cnstr = dict () self . nopt = 0 self . no_constraints = False self . no_transform = False","title":"__init__()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.evaluate","text":"Run the evaluation functions. Usually this is performed by the optimiser. Use this function to run tests on your model or to perform debugging. Parameters: Name Type Description Default results dict The dictionary to pass between evaluators. None Returns: Type Description (dict) Updated results dictionary. Source code in optuna_externm/core/_bmh.py Python def evaluate ( self , results = None ): \"\"\"Run the evaluation functions. Usually this is performed by the optimiser. Use this function to run tests on your model or to perform debugging. Args: results (dict): The dictionary to pass between evaluators. Returns: (dict): Updated results dictionary. \"\"\" if results is None : results = dict () for evl in self . evaluators : results . update ( self . evaluators [ evl ]( results = results )) return results","title":"evaluate()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.finalise","text":"Finalise the model by calling functions registered for finalisation. Source code in optuna_externm/core/_bmh.py Python def finalise ( self ): \"\"\"Finalise the model by calling functions registered for finalisation.\"\"\" for fini in self . finalisers : self . finalisers [ fini ]()","title":"finalise()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.initialise","text":"Initialise the model by calling functions registered for initialisation. Source code in optuna_externm/core/_bmh.py Python def initialise ( self ): \"\"\"Initialise the model by calling functions registered for initialisation.\"\"\" for init in self . initialisers : self . initialisers [ init ]()","title":"initialise()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.log_values","text":"Select values to log for each trial. These must be keys available within your results parser between evaluators by the end of each individuals evaluation. They should also be simple types. Parameters: Name Type Description Default log_list list List of results keys (str) to report on. None Source code in optuna_externm/core/_bmh.py Python def log_values ( self , log_list = None ): \"\"\"Select values to log for each trial. These must be keys available within your results parser between evaluators by the end of each individuals evaluation. They should also be simple types. Arguments: log_list (list): List of results keys (str) to report on. \"\"\" # 'fit' will always be reported. Defaults to None: Only fit will # be reported. # In multi-objective cases the optimiser will reduce fit of tuple to # fit1, fit2, ..., fitn if log_list is not None : self . log_keys = list ({ \"fit\" } . union ( set ( log_list ))) self . evaluator_stats = list ({ \"fit\" } . union ( set ( log_list ))) else : self . log_keys = [ \"fit\" ] self . evaluator_stats = [ \"fit\" ]","title":"log_values()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.objective_function","text":"Returns the final objective function for Optuna Studies Source code in optuna_externm/core/_bmh.py Python def objective_function ( self ): \"\"\"Returns the final objective function for Optuna Studies\"\"\" def objective ( trial ): p = { param . NAME : getattr ( trial , self . _optuna_dist_mapping [ param . DIST ])( param . NAME , param . LOW , param . HIGH ) for param in self . parameters } res = { \"p\" : p , \"trial_number\" : trial . number } res . update ( trial . study . user_attrs ) results = self . evaluate ( results = res ) for key in self . log_keys : try : trial . set_user_attr ( key , results [ key ]) except KeyError : pass return results [ \"fit\" ] return objective","title":"objective_function()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.register_evaluator","text":"Register an evaluation function to the handler to be used for optimisation under the name alias . Default arguments will be passed automatically when calling the registered function. Fixed arguments can then be overriden at function call time. All of the registered evaluators will be used in the objective updating function in the order that they are registered. This is important if evaluators depend on the output of other evaluators. Original code and method inspiration from DEAP.Toolbox Parameters: Name Type Description Default alias str The name the function will have in the handler. If the fname already exist it will overwrite the the function already registered. required function func The function referred to by alias, the first argument is the reference data or a function to return the reference data, the second argument is the data to compare. required args/kwargs optional) Special arguments and keyword arguments to pass to function. required Examples: The following code block is an example of how this function is used. .. highlight:: python .. code-block:: console Python >>> def func ( a , b , c = 3 ): ... print a , b , c ... >>> model = BaseModelHandler () >>> model . register_evaluator ( \"myFunc\" , func , 2 , c = 4 ) >>> model . myFunc ( 3 ) 2 3 4 >>> model . evaluators { \"muFunc\" : func } The registered function will be given the attributes :attr: __name__ set to the fname and :attr: __doc__ set to the original function's documentation. The :attr: __dict__ attribute will also be updated with the original function's instance dictionary, if any. Source code in optuna_externm/core/_bmh.py Python def register_evaluator ( self , alias , function , * args , ** kargs ): \"\"\"Register an evaluation *function* to the handler to be used for optimisation under the name *alias*. Default arguments will be passed automatically when calling the registered function. Fixed arguments can then be overriden at function call time. All of the registered evaluators will be used in the objective updating function in the order that they are registered. This is important if evaluators depend on the output of other evaluators. Original code and method inspiration from DEAP.Toolbox Args: alias (str): The name the function will have in the handler. If the fname already exist it will overwrite the the function already registered. function (func): The function referred to by alias, the first argument is the reference data or a function to return the reference data, the second argument is the data to compare. args/kwargs (optional) : Special arguments and keyword arguments to pass to function. Example: The following code block is an example of how this function is used. .. highlight:: python .. code-block:: console >>> def func(a, b, c=3): ... print a, b, c ... >>> model = BaseModelHandler() >>> model.register_evaluator(\"myFunc\", func, 2, c=4) >>> model.myFunc(3) 2 3 4 >>> model.evaluators {\"muFunc\": func} The registered function will be given the attributes :attr:`__name__` set to the fname and :attr:`__doc__` set to the original function's documentation. The :attr:`__dict__` attribute will also be updated with the original function's instance dictionary, if any. \"\"\" self . _register ( \"evaluators\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as evaluator\" )","title":"register_evaluator()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.register_finaliser","text":"Register a finalisation function to the handler to be used after to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator Source code in optuna_externm/core/_bmh.py Python def register_finaliser ( self , alias , function , * args , ** kargs ): \"\"\"Register a finalisation *function* to the handler to be used after to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"finalisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as finaliser\" )","title":"register_finaliser()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.register_initialiser","text":"Register an initialisation function to the handler to be used prior to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator Source code in optuna_externm/core/_bmh.py Python def register_initialiser ( self , alias , function , * args , ** kargs ): \"\"\"Register an initialisation *function* to the handler to be used prior to running the evaluators. These functions are run once. For usage see BaseModelHander.register_evalator \"\"\" self . _register ( \"initialisers\" , alias , function , * args , ** kargs ) logger . info ( f \" { alias } registered as initialiser\" )","title":"register_initialiser()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.set_param","text":"Set the parameters of the problem to be solved. Minimum properties for each tuples are PROP, PMIN, PMAX, DIST Parameters: Name Type Description Default parameters Optimisation parameters definitions as namedtuples. required Notes The load csv function in the optuna.externm.utils module can be used to load and create the input to this method from a CSV file. Source code in optuna_externm/core/_bmh.py Python def set_param ( self , parameters ): \"\"\"Set the parameters of the problem to be solved. Minimum properties for each tuples are PROP, PMIN, PMAX, DIST Args: parameters: Optimisation parameters definitions as namedtuples. Notes: The load csv function in the optuna.externm.utils module can be used to load and create the input to this method from a CSV file. \"\"\" missing_params = [] for param in parameters : if not self . __req_parameter_attr . issubset ( set ( param . _fields )): missing_params . append ( set ( param . _fields ) . difference ( self . __req_parameter_attr ) ) logger . debug ( f \"Malformed parameter: { param } \" ) if missing_params : logger . error ( f \"The parameter definition was malformed, missing: { missing_params } \" ) raise SystemExit # if \"DIST\" not in param.columns: # param[\"DIST\"] = \"UNIFORM\" # logger.info( # \"No parameter distribution specified, all parameters \" # \"being transformed with UNIFORM distribution\" # ) # if \"TYPE\" not in param.columns: # param[\"TYPE\"] = \"NUMERIC\" # logger.info( # \"No parameter distribution types specified, all parameters \" # \"assumed to have type NUMERIC.\" # ) # # dealing with parameter constraints # if \"CONSTRAINT\" not in param.columns or self.no_constraints: # param[\"CONSTRAINT\"] = numpy.nan # else: # for par, row in param.dropna(subset=[\"CONSTRAINT\"]).iterrows(): # tok = self._equality_tokenizer.split(row[\"CONSTRAINT\"]) # tok = [t.strip() for t in tok if t != \"\"] # for i, t in enumerate(tok): # try: # tok[i] = self._equality_tokens.inverse[t][0] # except KeyError: # pass # self.param_cnstr[par] = [t for t in zip(tok[0::2], tok[1::2])] self . parameters = parameters self . param_list = [ p . NAME for p in self . parameters ] self . nopt = len ( self . parameters ) logger . info ( f \"Model has { self . nopt } optimisation parameters\" )","title":"set_param()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.unregister_evaluator","text":"Unregister an evalautor function. Parameters: Name Type Description Default alias str The name of the operator to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_evaluator ( self , alias ): \"\"\"Unregister an evalautor function. Args: alias (str): The name of the operator to remove from the model. \"\"\" self . _unregister ( \"evaluators\" , alias ) logger . info ( f \" { alias } unregistered as evaluator\" )","title":"unregister_evaluator()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.unregister_finaliser","text":"Unregister a finaliser function. Parameters: Name Type Description Default alias str The name of the finaliser function to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_finaliser ( self , alias ): \"\"\"Unregister a finaliser function. Args: alias (str): The name of the finaliser function to remove from the model. \"\"\" self . _unregister ( \"finalisers\" , alias ) logger . info ( f \" { alias } unregistered as finaliser\" )","title":"unregister_finaliser()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.unregister_initialiser","text":"Unregister an initialiser function. Parameters: Name Type Description Default alias str The name of the initialiser function to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_initialiser ( self , alias ): \"\"\"Unregister an initialiser function. Args: alias (str): The name of the initialiser function to remove from the model. \"\"\" self . _unregister ( \"initialisers\" , alias ) logger . info ( f \" { alias } unregistered as initisaliser\" )","title":"unregister_initialiser()"},{"location":"api/core.html#optuna_externm.core._bmh.BaseModelHandler.unregister_transform","text":"Unregister a transform function. Parameters: Name Type Description Default alias str The name of the function to remove from the model. required Source code in optuna_externm/core/_bmh.py Python def unregister_transform ( self , alias ): \"\"\"Unregister a transform function. Args: alias (str): The name of the function to remove from the model. \"\"\" self . _unregister ( \"transforms\" , alias ) self . _unregister ( \"inverse_transforms\" , alias ) logger . info ( f \" { alias } unregistered as transform\" )","title":"unregister_transform()"},{"location":"api/opt.html","text":"optuna_externm.opt NSGAII This sampler is from and maintained by optuna but included here for convienience. Multi-objective sampler using the NSGA-II algorithm. NSGA-II stands for \"Nondominated Sorting Genetic Algorithm II\", which is a well known, fast and elitist multi-objective genetic algorithm. For further information about NSGA-II, please refer to the following paper: A fast and elitist multiobjective genetic algorithm: NSGA-II <https://ieeexplore.ieee.org/document/996017> _ Parameters: Name Type Description Default population_size int Number of individuals (trials) in a generation. 50 mutation_prob Optional[float] Probability of mutating each parameter when creating a new individual. If :obj: None is specified, the value 1.0 / len(parent_trial.params) is used where parent_trial is the parent trial of the target individual. None crossover_prob float Probability that a crossover (parameters swapping between parents) will occur when creating a new individual. 0.9 swapping_prob float Probability of swapping each parameter of the parents during crossover. 0.5 seed Optional[int] Seed for random number generator. None constraints_func Optional[Callable[[optuna.trial._frozen.FrozenTrial], Sequence[float]]] An optional function that computes the objective constraints. It must take a :class: ~optuna.trial.FrozenTrial and return the constraints. The return value must be a sequence of :obj: float s. A value strictly larger than 0 means that a constraints is violated. A value equal to or smaller than 0 is considered feasible. If constraints_func returns more than one value for a trial, that trial is considered feasible if and only if all values are equal to 0 or smaller. The constraints_func will be evaluated after each successful trial. The function won't be called when trials fail or they are pruned, but this behavior is subject to change in the future releases. The constraints are handled by the constrained domination. A trial x is said to constrained-dominate a trial y, if any of the following conditions is true: Trial x is feasible and trial y is not. Trial x and y are both infeasible, but trial x has a smaller overall violation. Trial x and y are feasible and trial x dominates trial y. .. note:: Added in v2.5.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.5.0. None Source code in optuna/samplers/_nsga2.py Python class NSGAIISampler ( BaseSampler ): \"\"\"Multi-objective sampler using the NSGA-II algorithm. NSGA-II stands for \"Nondominated Sorting Genetic Algorithm II\", which is a well known, fast and elitist multi-objective genetic algorithm. For further information about NSGA-II, please refer to the following paper: - `A fast and elitist multiobjective genetic algorithm: NSGA-II <https://ieeexplore.ieee.org/document/996017>`_ Args: population_size: Number of individuals (trials) in a generation. mutation_prob: Probability of mutating each parameter when creating a new individual. If :obj:`None` is specified, the value ``1.0 / len(parent_trial.params)`` is used where ``parent_trial`` is the parent trial of the target individual. crossover_prob: Probability that a crossover (parameters swapping between parents) will occur when creating a new individual. swapping_prob: Probability of swapping each parameter of the parents during crossover. seed: Seed for random number generator. constraints_func: An optional function that computes the objective constraints. It must take a :class:`~optuna.trial.FrozenTrial` and return the constraints. The return value must be a sequence of :obj:`float` s. A value strictly larger than 0 means that a constraints is violated. A value equal to or smaller than 0 is considered feasible. If ``constraints_func`` returns more than one value for a trial, that trial is considered feasible if and only if all values are equal to 0 or smaller. The ``constraints_func`` will be evaluated after each successful trial. The function won't be called when trials fail or they are pruned, but this behavior is subject to change in the future releases. The constraints are handled by the constrained domination. A trial x is said to constrained-dominate a trial y, if any of the following conditions is true: 1. Trial x is feasible and trial y is not. 2. Trial x and y are both infeasible, but trial x has a smaller overall violation. 3. Trial x and y are feasible and trial x dominates trial y. .. note:: Added in v2.5.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.5.0. \"\"\" def __init__ ( self , * , population_size : int = 50 , mutation_prob : Optional [ float ] = None , crossover_prob : float = 0.9 , swapping_prob : float = 0.5 , seed : Optional [ int ] = None , constraints_func : Optional [ Callable [[ FrozenTrial ], Sequence [ float ]]] = None , ) -> None : # TODO(ohta): Reconsider the default value of each parameter. if not isinstance ( population_size , int ): raise TypeError ( \"`population_size` must be an integer value.\" ) if population_size < 2 : raise ValueError ( \"`population_size` must be greater than or equal to 2.\" ) if not ( mutation_prob is None or 0.0 <= mutation_prob <= 1.0 ): raise ValueError ( \"`mutation_prob` must be None or a float value within the range [0.0, 1.0].\" ) if not ( 0.0 <= crossover_prob <= 1.0 ): raise ValueError ( \"`crossover_prob` must be a float value within the range [0.0, 1.0].\" ) if not ( 0.0 <= swapping_prob <= 1.0 ): raise ValueError ( \"`swapping_prob` must be a float value within the range [0.0, 1.0].\" ) if constraints_func is not None : warnings . warn ( \"The constraints_func option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) self . _population_size = population_size self . _mutation_prob = mutation_prob self . _crossover_prob = crossover_prob self . _swapping_prob = swapping_prob self . _random_sampler = RandomSampler ( seed = seed ) self . _rng = np . random . RandomState ( seed ) self . _constraints_func = constraints_func def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState () def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: return {} def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : p0 = self . _select_parent ( study , parent_population ) if self . _rng . rand () < self . _crossover_prob : p1 = self . _select_parent ( study , [ t for t in parent_population if t . _trial_id != p0 . _trial_id ] ) else : p1 = p0 study . _storage . set_trial_system_attr ( trial_id , _PARENTS_KEY , [ p0 . _trial_id , p1 . _trial_id ] ) return {} def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : if _PARENTS_KEY not in trial . system_attrs : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) p0_id , p1_id = trial . system_attrs [ _PARENTS_KEY ] p0 = study . _storage . get_trial ( p0_id ) p1 = study . _storage . get_trial ( p1_id ) param = p0 . params . get ( param_name , None ) parent_params_len = len ( p0 . params ) if param is None or self . _rng . rand () < self . _swapping_prob : param = p1 . params . get ( param_name , None ) parent_params_len = len ( p1 . params ) mutation_prob = self . _mutation_prob if mutation_prob is None : mutation_prob = 1.0 / max ( 1.0 , parent_params_len ) if param is None or self . _rng . rand () < mutation_prob : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) return param def _collect_parent_population ( self , study : Study ) -> Tuple [ int , List [ FrozenTrial ]]: trials = study . get_trials ( deepcopy = False ) generation_to_runnings = defaultdict ( list ) generation_to_population = defaultdict ( list ) for trial in trials : if _GENERATION_KEY not in trial . system_attrs : continue generation = trial . system_attrs [ _GENERATION_KEY ] if trial . state != optuna . trial . TrialState . COMPLETE : if trial . state == optuna . trial . TrialState . RUNNING : generation_to_runnings [ generation ] . append ( trial ) continue # Do not use trials whose states are not COMPLETE, or `constraint` will be unavailable. generation_to_population [ generation ] . append ( trial ) hasher = hashlib . sha256 () parent_population : List [ FrozenTrial ] = [] parent_generation = - 1 while True : generation = parent_generation + 1 population = generation_to_population [ generation ] # Under multi-worker settings, the population size might become larger than # `self._population_size`. if len ( population ) < self . _population_size : break # [NOTE] # It's generally safe to assume that once the above condition is satisfied, # there are no additional individuals added to the generation (i.e., the members of # the generation have been fixed). # If the number of parallel workers is huge, this assumption can be broken, but # this is a very rare case and doesn't significantly impact optimization performance. # So we can ignore the case. # The cache key is calculated based on the key of the previous generation and # the remaining running trials in the current population. # If there are no running trials, the new cache key becomes exactly the same as # the previous one, and the cached content will be overwritten. This allows us to # skip redundant cache key calculations when this method is called for the subsequent # trials. for trial in generation_to_runnings [ generation ]: hasher . update ( bytes ( str ( trial . number ), \"utf-8\" )) cache_key = \" {} : {} \" . format ( _POPULATION_CACHE_KEY_PREFIX , hasher . hexdigest ()) cached_generation , cached_population_numbers = study . system_attrs . get ( cache_key , ( - 1 , []) ) if cached_generation >= generation : generation = cached_generation population = [ trials [ n ] for n in cached_population_numbers ] else : population . extend ( parent_population ) population = self . _select_elite_population ( study , population ) # To reduce the number of system attribute entries, # we cache the population information only if there are no running trials # (i.e., the information of the population has been fixed). # Usually, if there are no too delayed running trials, the single entry # will be used. if len ( generation_to_runnings [ generation ]) == 0 : population_numbers = [ t . number for t in population ] study . set_system_attr ( cache_key , ( generation , population_numbers )) parent_generation = generation parent_population = population return parent_generation , parent_population def _select_elite_population ( self , study : Study , population : List [ FrozenTrial ] ) -> List [ FrozenTrial ]: elite_population : List [ FrozenTrial ] = [] population_per_rank = self . _fast_non_dominated_sort ( population , study . directions ) for population in population_per_rank : if len ( elite_population ) + len ( population ) < self . _population_size : elite_population . extend ( population ) else : n = self . _population_size - len ( elite_population ) _crowding_distance_sort ( population ) elite_population . extend ( population [: n ]) break return elite_population def _select_parent ( self , study : Study , population : Sequence [ FrozenTrial ]) -> FrozenTrial : # TODO(ohta): Consider to allow users to specify the number of parent candidates. population_size = len ( population ) candidate0 = population [ self . _rng . choice ( population_size )] candidate1 = population [ self . _rng . choice ( population_size )] dominates = _dominates if self . _constraints_func is None else _constrained_dominates # TODO(ohta): Consider crowding distance. if dominates ( candidate0 , candidate1 , study . directions ): return candidate0 else : return candidate1 def _fast_non_dominated_sort ( self , population : List [ FrozenTrial ], directions : List [ optuna . study . StudyDirection ], ) -> List [ List [ FrozenTrial ]]: dominated_count : DefaultDict [ int , int ] = defaultdict ( int ) dominates_list = defaultdict ( list ) dominates = _dominates if self . _constraints_func is None else _constrained_dominates for p , q in itertools . combinations ( population , 2 ): if dominates ( p , q , directions ): dominates_list [ p . number ] . append ( q . number ) dominated_count [ q . number ] += 1 elif dominates ( q , p , directions ): dominates_list [ q . number ] . append ( p . number ) dominated_count [ p . number ] += 1 population_per_rank = [] while population : non_dominated_population = [] i = 0 while i < len ( population ): if dominated_count [ population [ i ] . number ] == 0 : individual = population [ i ] if i == len ( population ) - 1 : population . pop () else : population [ i ] = population . pop () non_dominated_population . append ( individual ) else : i += 1 for x in non_dominated_population : for y in dominates_list [ x . number ]: dominated_count [ y ] -= 1 assert non_dominated_population population_per_rank . append ( non_dominated_population ) return population_per_rank def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values ) after_trial ( self , study , trial , state , values ) Trial post-processing. This method is called after the objective function returns and right before the trials is finished and its state is stored. .. note:: Added in v2.4.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.4.0. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required state TrialState Resulting trial state. required values Optional[Sequence[float]] Resulting trial values. Guaranteed to not be :obj: None if trial succeeded. required Source code in optuna/samplers/_nsga2.py Python def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values ) infer_relative_search_space ( self , study , trial ) Infer the search space that will be used by relative sampling in the target trial. This method is called right before :func: ~optuna.samplers.BaseSampler.sample_relative method, and the search space returned by this method is passed to it. The parameters not contained in the search space will be sampled by using :func: ~optuna.samplers.BaseSampler.sample_independent method. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required Returns: Type Description Dict[str, optuna.distributions.BaseDistribution] A dictionary containing the parameter names and parameter's distributions. .. seealso:: Please refer to :func: ~optuna.samplers.intersection_search_space as an implementation of :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . Source code in optuna/samplers/_nsga2.py Python def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: return {} reseed_rng ( self ) Reseed sampler's random number generator. This method is called by the :class: ~optuna.study.Study instance if trials are executed in parallel with the option n_jobs>1 . In that case, the sampler instance will be replicated including the state of the random number generator, and they may suggest the same values. To prevent this issue, this method assigns a different seed to each random number generator. Source code in optuna/samplers/_nsga2.py Python def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState () sample_independent ( self , study , trial , param_name , param_distribution ) Sample a parameter for a given distribution. This method is called only for the parameters not contained in the search space returned by :func: ~optuna.samplers.BaseSampler.sample_relative method. This method is suitable for sampling algorithms that do not use relationship between parameters such as random sampling and TPE. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required param_name str Name of the sampled parameter. required param_distribution BaseDistribution Distribution object that specifies a prior and/or scale of the sampling algorithm. required Returns: Type Description Any A parameter value. Source code in optuna/samplers/_nsga2.py Python def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : if _PARENTS_KEY not in trial . system_attrs : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) p0_id , p1_id = trial . system_attrs [ _PARENTS_KEY ] p0 = study . _storage . get_trial ( p0_id ) p1 = study . _storage . get_trial ( p1_id ) param = p0 . params . get ( param_name , None ) parent_params_len = len ( p0 . params ) if param is None or self . _rng . rand () < self . _swapping_prob : param = p1 . params . get ( param_name , None ) parent_params_len = len ( p1 . params ) mutation_prob = self . _mutation_prob if mutation_prob is None : mutation_prob = 1.0 / max ( 1.0 , parent_params_len ) if param is None or self . _rng . rand () < mutation_prob : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) return param sample_relative ( self , study , trial , search_space ) Sample parameters in a given search space. This method is called once at the beginning of each trial, i.e., right before the evaluation of the objective function. This method is suitable for sampling algorithms that use relationship between parameters such as Gaussian Process and CMA-ES. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required search_space Dict[str, optuna.distributions.BaseDistribution] The search space returned by :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . required Returns: Type Description Dict[str, Any] A dictionary containing the parameter names and the values. Source code in optuna/samplers/_nsga2.py Python def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : p0 = self . _select_parent ( study , parent_population ) if self . _rng . rand () < self . _crossover_prob : p1 = self . _select_parent ( study , [ t for t in parent_population if t . _trial_id != p0 . _trial_id ] ) else : p1 = p0 study . _storage . set_trial_system_attr ( trial_id , _PARENTS_KEY , [ p0 . _trial_id , p1 . _trial_id ] ) return {} CMAES This sampler is from and maintained by optuna but included here for convienience. A sampler using cmaes <https://github.com/CyberAgentAILab/cmaes> _ as the backend. Examples: Optimize a simple quadratic function by using :class: ~optuna.samplers.CmaEsSampler . .. testcode:: import optuna def objective(trial): x = trial.suggest_float(\"x\", -1, 1) y = trial.suggest_int(\"y\", -1, 1) return x ** 2 + y sampler = optuna.samplers.CmaEsSampler() study = optuna.create_study(sampler=sampler) study.optimize(objective, n_trials=20) Please note that this sampler does not support CategoricalDistribution. However, :class: ~optuna.distributions.DiscreteUniformDistribution (:func: ~optuna.trial.Trial.suggest_discrete_uniform ) and Int(Log)Distribution (:func: ~optuna.trial.Trial.suggest_int ) are supported. If your search space contains categorical parameters, I recommend you to use :class: ~optuna.samplers.TPESampler instead. Furthermore, there is room for performance improvements in parallel optimization settings. This sampler cannot use some trials for updating the parameters of multivariate normal distribution. For further information about CMA-ES algorithm, please refer to the following papers: N. Hansen, The CMA Evolution Strategy: A Tutorial. arXiv:1604.00772, 2016. <https://arxiv.org/abs/1604.00772> _ A. Auger and N. Hansen. A restart CMA evolution strategy with increasing population size. In Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2005), pages 1769\u20131776. IEEE Press, 2005. <http://www.cmap.polytechnique.fr/~nikolaus.hansen/cec2005ipopcmaes.pdf> _ Raymond Ros, Nikolaus Hansen. A Simple Modification in CMA-ES Achieving Linear Time and Space Complexity. 10th International Conference on Parallel Problem Solving From Nature, Sep 2008, Dortmund, Germany. inria-00287367. <https://hal.inria.fr/inria-00287367/document> _ Masahiro Nomura, Shuhei Watanabe, Youhei Akimoto, Yoshihiko Ozaki, Masaki Onishi. Warm Starting CMA-ES for Hyperparameter Optimization, AAAI. 2021. <https://arxiv.org/abs/2012.06932> _ .. seealso:: You can also use :class: optuna.integration.PyCmaSampler which is a sampler using cma library as the backend. Parameters: Name Type Description Default x0 Optional[Dict[str, Any]] A dictionary of an initial parameter values for CMA-ES. By default, the mean of low and high for each distribution is used. Note that x0 is sampled uniformly within the search space domain for each restart if you specify restart_strategy argument. None sigma0 Optional[float] Initial standard deviation of CMA-ES. By default, sigma0 is set to min_range / 6 , where min_range denotes the minimum range of the distributions in the search space. None seed Optional[int] A random seed for CMA-ES. None n_startup_trials int The independent sampling is used instead of the CMA-ES algorithm until the given number of trials finish in the same study. 1 independent_sampler Optional[optuna.samplers._base.BaseSampler] A :class: ~optuna.samplers.BaseSampler instance that is used for independent sampling. The parameters not contained in the relative search space are sampled by this sampler. The search space for :class: ~optuna.samplers.CmaEsSampler is determined by :func: ~optuna.samplers.intersection_search_space() . If :obj: None is specified, :class: ~optuna.samplers.RandomSampler is used as the default. .. seealso:: :class: optuna.samplers module provides built-in independent samplers such as :class: ~optuna.samplers.RandomSampler and :class: ~optuna.samplers.TPESampler . None warn_independent_sampling bool If this is :obj: True , a warning message is emitted when the value of a parameter is sampled by using an independent sampler. Note that the parameters of the first trial in a study are always sampled via an independent sampler, so no warning messages are emitted in this case. True restart_strategy Optional[str] Strategy for restarting CMA-ES optimization when converges to a local minimum. If given :obj: None , CMA-ES will not restart (default). If given 'ipop', CMA-ES will restart with increasing population size. Please see also inc_popsize parameter. .. note:: Added in v2.1.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.1.0. None inc_popsize int Multiplier for increasing population size before each restart. This argument will be used when setting restart_strategy = 'ipop' . 2 consider_pruned_trials bool If this is :obj: True , the PRUNED trials are considered for sampling. .. note:: Added in v2.0.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.0.0. .. note:: It is suggested to set this flag :obj: False when the :class: ~optuna.pruners.MedianPruner is used. On the other hand, it is suggested to set this flag :obj: True when the :class: ~optuna.pruners.HyperbandPruner is used. Please see the benchmark result <https://github.com/optuna/optuna/pull/1229> _ for the details. False use_separable_cma bool If this is :obj: True , the covariance matrix is constrained to be diagonal. Due to reduce the model complexity, the learning rate for the covariance matrix is increased. Consequently, this algorithm outperforms CMA-ES on separable functions. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. False source_trials Optional[List[optuna.trial._frozen.FrozenTrial]] This option is for Warm Starting CMA-ES, a method to transfer prior knowledge on similar HPO tasks through the initialization of CMA-ES. This method estimates a promising distribution from source_trials and generates the parameter of multivariate gaussian distribution. Please note that it is prohibited to use x0 , sigma0 , or use_separable_cma argument together. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. None Source code in optuna/samplers/_cmaes.py Python class CmaEsSampler ( BaseSampler ): \"\"\"A sampler using `cmaes <https://github.com/CyberAgentAILab/cmaes>`_ as the backend. Example: Optimize a simple quadratic function by using :class:`~optuna.samplers.CmaEsSampler`. .. testcode:: import optuna def objective(trial): x = trial.suggest_float(\"x\", -1, 1) y = trial.suggest_int(\"y\", -1, 1) return x ** 2 + y sampler = optuna.samplers.CmaEsSampler() study = optuna.create_study(sampler=sampler) study.optimize(objective, n_trials=20) Please note that this sampler does not support CategoricalDistribution. However, :class:`~optuna.distributions.DiscreteUniformDistribution` (:func:`~optuna.trial.Trial.suggest_discrete_uniform`) and Int(Log)Distribution (:func:`~optuna.trial.Trial.suggest_int`) are supported. If your search space contains categorical parameters, I recommend you to use :class:`~optuna.samplers.TPESampler` instead. Furthermore, there is room for performance improvements in parallel optimization settings. This sampler cannot use some trials for updating the parameters of multivariate normal distribution. For further information about CMA-ES algorithm, please refer to the following papers: - `N. Hansen, The CMA Evolution Strategy: A Tutorial. arXiv:1604.00772, 2016. <https://arxiv.org/abs/1604.00772>`_ - `A. Auger and N. Hansen. A restart CMA evolution strategy with increasing population size. In Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2005), pages 1769\u20131776. IEEE Press, 2005. <http://www.cmap.polytechnique.fr/~nikolaus.hansen/cec2005ipopcmaes.pdf>`_ - `Raymond Ros, Nikolaus Hansen. A Simple Modification in CMA-ES Achieving Linear Time and Space Complexity. 10th International Conference on Parallel Problem Solving From Nature, Sep 2008, Dortmund, Germany. inria-00287367. <https://hal.inria.fr/inria-00287367/document>`_ - `Masahiro Nomura, Shuhei Watanabe, Youhei Akimoto, Yoshihiko Ozaki, Masaki Onishi. Warm Starting CMA-ES for Hyperparameter Optimization, AAAI. 2021. <https://arxiv.org/abs/2012.06932>`_ .. seealso:: You can also use :class:`optuna.integration.PyCmaSampler` which is a sampler using cma library as the backend. Args: x0: A dictionary of an initial parameter values for CMA-ES. By default, the mean of ``low`` and ``high`` for each distribution is used. Note that ``x0`` is sampled uniformly within the search space domain for each restart if you specify ``restart_strategy`` argument. sigma0: Initial standard deviation of CMA-ES. By default, ``sigma0`` is set to ``min_range / 6``, where ``min_range`` denotes the minimum range of the distributions in the search space. seed: A random seed for CMA-ES. n_startup_trials: The independent sampling is used instead of the CMA-ES algorithm until the given number of trials finish in the same study. independent_sampler: A :class:`~optuna.samplers.BaseSampler` instance that is used for independent sampling. The parameters not contained in the relative search space are sampled by this sampler. The search space for :class:`~optuna.samplers.CmaEsSampler` is determined by :func:`~optuna.samplers.intersection_search_space()`. If :obj:`None` is specified, :class:`~optuna.samplers.RandomSampler` is used as the default. .. seealso:: :class:`optuna.samplers` module provides built-in independent samplers such as :class:`~optuna.samplers.RandomSampler` and :class:`~optuna.samplers.TPESampler`. warn_independent_sampling: If this is :obj:`True`, a warning message is emitted when the value of a parameter is sampled by using an independent sampler. Note that the parameters of the first trial in a study are always sampled via an independent sampler, so no warning messages are emitted in this case. restart_strategy: Strategy for restarting CMA-ES optimization when converges to a local minimum. If given :obj:`None`, CMA-ES will not restart (default). If given 'ipop', CMA-ES will restart with increasing population size. Please see also ``inc_popsize`` parameter. .. note:: Added in v2.1.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.1.0. inc_popsize: Multiplier for increasing population size before each restart. This argument will be used when setting ``restart_strategy = 'ipop'``. consider_pruned_trials: If this is :obj:`True`, the PRUNED trials are considered for sampling. .. note:: Added in v2.0.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.0.0. .. note:: It is suggested to set this flag :obj:`False` when the :class:`~optuna.pruners.MedianPruner` is used. On the other hand, it is suggested to set this flag :obj:`True` when the :class:`~optuna.pruners.HyperbandPruner` is used. Please see `the benchmark result <https://github.com/optuna/optuna/pull/1229>`_ for the details. use_separable_cma: If this is :obj:`True`, the covariance matrix is constrained to be diagonal. Due to reduce the model complexity, the learning rate for the covariance matrix is increased. Consequently, this algorithm outperforms CMA-ES on separable functions. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. source_trials: This option is for Warm Starting CMA-ES, a method to transfer prior knowledge on similar HPO tasks through the initialization of CMA-ES. This method estimates a promising distribution from ``source_trials`` and generates the parameter of multivariate gaussian distribution. Please note that it is prohibited to use ``x0``, ``sigma0``, or ``use_separable_cma`` argument together. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. Raises: ValueError: If ``restart_strategy`` is not 'ipop' or :obj:`None`. \"\"\" def __init__ ( self , x0 : Optional [ Dict [ str , Any ]] = None , sigma0 : Optional [ float ] = None , n_startup_trials : int = 1 , independent_sampler : Optional [ BaseSampler ] = None , warn_independent_sampling : bool = True , seed : Optional [ int ] = None , * , consider_pruned_trials : bool = False , restart_strategy : Optional [ str ] = None , inc_popsize : int = 2 , use_separable_cma : bool = False , source_trials : Optional [ List [ FrozenTrial ]] = None , ) -> None : self . _x0 = x0 self . _sigma0 = sigma0 self . _independent_sampler = independent_sampler or optuna . samplers . RandomSampler ( seed = seed ) self . _n_startup_trials = n_startup_trials self . _warn_independent_sampling = warn_independent_sampling self . _cma_rng = np . random . RandomState ( seed ) self . _search_space = optuna . samplers . IntersectionSearchSpace () self . _consider_pruned_trials = consider_pruned_trials self . _restart_strategy = restart_strategy self . _inc_popsize = inc_popsize self . _use_separable_cma = use_separable_cma self . _source_trials = source_trials if self . _restart_strategy : warnings . warn ( \"`restart_strategy` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if self . _consider_pruned_trials : warnings . warn ( \"`consider_pruned_trials` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if self . _use_separable_cma : warnings . warn ( \"`use_separable_cma` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if self . _source_trials is not None : warnings . warn ( \"`source_trials` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if source_trials is not None and ( x0 is not None or sigma0 is not None ): raise ValueError ( \"It is prohibited to pass `source_trials` argument when \" \"x0 or sigma0 is specified.\" ) # TODO(c-bata): Support WS-sep-CMA-ES. if source_trials is not None and use_separable_cma : raise ValueError ( \"It is prohibited to pass `source_trials` argument when \" \"using separable CMA-ES.\" ) # TODO(c-bata): Support BIPOP-CMA-ES. if restart_strategy not in ( \"ipop\" , None , ): raise ValueError ( \"restart_strategy= {} is unsupported. Please specify: 'ipop' or None.\" . format ( restart_strategy ) ) def reseed_rng ( self ) -> None : # _cma_rng doesn't require reseeding because the relative sampling reseeds in each trial. self . _independent_sampler . reseed_rng () def infer_relative_search_space ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # `cma` cannot handle distributions that contain just a single value, so we skip # them. Note that the parameter values for such distributions are sampled in # `Trial`. continue if not isinstance ( distribution , ( optuna . distributions . UniformDistribution , optuna . distributions . LogUniformDistribution , optuna . distributions . DiscreteUniformDistribution , optuna . distributions . IntUniformDistribution , optuna . distributions . IntLogUniformDistribution , ), ): # Categorical distribution is unsupported. continue search_space [ name ] = distribution return search_space def sample_relative ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: self . _raise_error_if_multi_objective ( study ) if len ( search_space ) == 0 : return {} completed_trials = self . _get_trials ( study ) if len ( completed_trials ) < self . _n_startup_trials : return {} if len ( search_space ) == 1 : _logger . info ( \"`CmaEsSampler` only supports two or more dimensional continuous \" \"search space. ` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} trans = _SearchSpaceTransform ( search_space ) optimizer , n_restarts = self . _restore_optimizer ( completed_trials ) if optimizer is None : n_restarts = 0 optimizer = self . _init_optimizer ( trans , study . direction ) if self . _restart_strategy is None : generation_attr_key = \"cma:generation\" # for backward compatibility else : generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) if optimizer . dim != len ( trans . bounds ): _logger . info ( \"`CmaEsSampler` does not support dynamic search space. \" \"` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} # TODO(c-bata): Reduce the number of wasted trials during parallel optimization. # See https://github.com/optuna/optuna/pull/920#discussion_r385114002 for details. solution_trials = [ t for t in completed_trials if optimizer . generation == t . system_attrs . get ( generation_attr_key , - 1 ) ] if len ( solution_trials ) >= optimizer . population_size : solutions : List [ Tuple [ np . ndarray , float ]] = [] for t in solution_trials [: optimizer . population_size ]: assert t . value is not None , \"completed trials must have a value\" x = trans . transform ( t . params ) y = t . value if study . direction == StudyDirection . MINIMIZE else - t . value solutions . append (( x , y )) optimizer . tell ( solutions ) if self . _restart_strategy == \"ipop\" and optimizer . should_stop (): n_restarts += 1 generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) popsize = optimizer . population_size * self . _inc_popsize optimizer = self . _init_optimizer ( trans , study . direction , population_size = popsize , randomize_start_point = True ) # Store optimizer optimizer_str = pickle . dumps ( optimizer ) . hex () optimizer_attrs = _split_optimizer_str ( optimizer_str ) for key in optimizer_attrs : study . _storage . set_trial_system_attr ( trial . _trial_id , key , optimizer_attrs [ key ]) # Caution: optimizer should update its seed value seed = self . _cma_rng . randint ( 1 , 2 ** 16 ) + trial . number optimizer . _rng = np . random . RandomState ( seed ) params = optimizer . ask () study . _storage . set_trial_system_attr ( trial . _trial_id , generation_attr_key , optimizer . generation ) study . _storage . set_trial_system_attr ( trial . _trial_id , \"cma:n_restarts\" , n_restarts ) external_values = trans . untransform ( params ) return external_values def _restore_optimizer ( self , completed_trials : \"List[optuna.trial.FrozenTrial]\" , ) -> Tuple [ Optional [ CmaClass ], int ]: if not self . _use_separable_cma : attr_key_optimizer = \"cma:optimizer\" attr_key_n_restarts = \"cma:n_restarts\" else : attr_key_optimizer = \"sepcma:optimizer\" attr_key_n_restarts = \"sepcma:n_restarts\" # Restore a previous CMA object. for trial in reversed ( completed_trials ): optimizer_attrs = { key : value for key , value in trial . system_attrs . items () if key . startswith ( attr_key_optimizer ) } if len ( optimizer_attrs ) == 0 : continue if not self . _use_separable_cma and \"cma:optimizer\" in optimizer_attrs : # Check \"cma:optimizer\" key for backward compatibility. optimizer_str = optimizer_attrs [ \"cma:optimizer\" ] else : optimizer_str = _concat_optimizer_attrs ( optimizer_attrs ) n_restarts : int = trial . system_attrs . get ( attr_key_n_restarts , 0 ) return pickle . loads ( bytes . fromhex ( optimizer_str )), n_restarts return None , 0 def _init_optimizer ( self , trans : _SearchSpaceTransform , direction : StudyDirection , population_size : Optional [ int ] = None , randomize_start_point : bool = False , ) -> CmaClass : lower_bounds = trans . bounds [:, 0 ] upper_bounds = trans . bounds [:, 1 ] n_dimension = len ( trans . bounds ) if self . _source_trials is None : if randomize_start_point : mean = lower_bounds + ( upper_bounds - lower_bounds ) * self . _cma_rng . rand ( n_dimension ) elif self . _x0 is None : mean = lower_bounds + ( upper_bounds - lower_bounds ) / 2 else : # `self._x0` is external representations. mean = trans . transform ( self . _x0 ) if self . _sigma0 is None : sigma0 = np . min (( upper_bounds - lower_bounds ) / 6 ) else : sigma0 = self . _sigma0 cov = None else : expected_states = [ TrialState . COMPLETE ] if self . _consider_pruned_trials : expected_states . append ( TrialState . PRUNED ) # TODO(c-bata): Filter parameters by their values instead of checking search space. sign = 1 if direction == StudyDirection . MINIMIZE else - 1 source_solutions = [ ( trans . transform ( t . params ), sign * cast ( float , t . value )) for t in self . _source_trials if t . state in expected_states and _is_compatible_search_space ( trans , t . distributions ) ] if len ( source_solutions ) == 0 : raise ValueError ( \"No compatible source_trials\" ) # TODO(c-bata): Add options to change prior parameters (alpha and gamma). mean , sigma0 , cov = get_warm_start_mgd ( source_solutions ) # Avoid ZeroDivisionError in cmaes. sigma0 = max ( sigma0 , _EPS ) if self . _use_separable_cma : return SepCMA ( mean = mean , sigma = sigma0 , bounds = trans . bounds , seed = self . _cma_rng . randint ( 1 , 2 ** 31 - 2 ), n_max_resampling = 10 * n_dimension , population_size = population_size , ) return CMA ( mean = mean , sigma = sigma0 , cov = cov , bounds = trans . bounds , seed = self . _cma_rng . randint ( 1 , 2 ** 31 - 2 ), n_max_resampling = 10 * n_dimension , population_size = population_size , ) def sample_independent ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , param_name : str , param_distribution : BaseDistribution , ) -> Any : self . _raise_error_if_multi_objective ( study ) if self . _warn_independent_sampling : complete_trials = self . _get_trials ( study ) if len ( complete_trials ) >= self . _n_startup_trials : self . _log_independent_sampling ( trial , param_name ) return self . _independent_sampler . sample_independent ( study , trial , param_name , param_distribution ) def _log_independent_sampling ( self , trial : FrozenTrial , param_name : str ) -> None : _logger . warning ( \"The parameter ' {} ' in trial# {} is sampled independently \" \"by using ` {} ` instead of `CmaEsSampler` \" \"(optimization performance may be degraded). \" \"`CmaEsSampler` does not support dynamic search space or `CategoricalDistribution`. \" \"You can suppress this warning by setting `warn_independent_sampling` \" \"to `False` in the constructor of `CmaEsSampler`, \" \"if this independent sampling is intended behavior.\" . format ( param_name , trial . number , self . _independent_sampler . __class__ . __name__ ) ) def _get_trials ( self , study : \"optuna.Study\" ) -> List [ FrozenTrial ]: complete_trials = [] for t in study . get_trials ( deepcopy = False ): if t . state == TrialState . COMPLETE : complete_trials . append ( t ) elif ( t . state == TrialState . PRUNED and len ( t . intermediate_values ) > 0 and self . _consider_pruned_trials ): _ , value = max ( t . intermediate_values . items ()) if value is None : continue # We rewrite the value of the trial `t` for sampling, so we need a deepcopy. copied_t = copy . deepcopy ( t ) copied_t . value = value complete_trials . append ( copied_t ) return complete_trials def after_trial ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : self . _independent_sampler . after_trial ( study , trial , state , values ) after_trial ( self , study , trial , state , values ) Trial post-processing. This method is called after the objective function returns and right before the trials is finished and its state is stored. .. note:: Added in v2.4.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.4.0. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required state TrialState Resulting trial state. required values Optional[Sequence[float]] Resulting trial values. Guaranteed to not be :obj: None if trial succeeded. required Source code in optuna/samplers/_cmaes.py Python def after_trial ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : self . _independent_sampler . after_trial ( study , trial , state , values ) infer_relative_search_space ( self , study , trial ) Infer the search space that will be used by relative sampling in the target trial. This method is called right before :func: ~optuna.samplers.BaseSampler.sample_relative method, and the search space returned by this method is passed to it. The parameters not contained in the search space will be sampled by using :func: ~optuna.samplers.BaseSampler.sample_independent method. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required Returns: Type Description Dict[str, optuna.distributions.BaseDistribution] A dictionary containing the parameter names and parameter's distributions. .. seealso:: Please refer to :func: ~optuna.samplers.intersection_search_space as an implementation of :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . Source code in optuna/samplers/_cmaes.py Python def infer_relative_search_space ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # `cma` cannot handle distributions that contain just a single value, so we skip # them. Note that the parameter values for such distributions are sampled in # `Trial`. continue if not isinstance ( distribution , ( optuna . distributions . UniformDistribution , optuna . distributions . LogUniformDistribution , optuna . distributions . DiscreteUniformDistribution , optuna . distributions . IntUniformDistribution , optuna . distributions . IntLogUniformDistribution , ), ): # Categorical distribution is unsupported. continue search_space [ name ] = distribution return search_space reseed_rng ( self ) Reseed sampler's random number generator. This method is called by the :class: ~optuna.study.Study instance if trials are executed in parallel with the option n_jobs>1 . In that case, the sampler instance will be replicated including the state of the random number generator, and they may suggest the same values. To prevent this issue, this method assigns a different seed to each random number generator. Source code in optuna/samplers/_cmaes.py Python def reseed_rng ( self ) -> None : # _cma_rng doesn't require reseeding because the relative sampling reseeds in each trial. self . _independent_sampler . reseed_rng () sample_independent ( self , study , trial , param_name , param_distribution ) Sample a parameter for a given distribution. This method is called only for the parameters not contained in the search space returned by :func: ~optuna.samplers.BaseSampler.sample_relative method. This method is suitable for sampling algorithms that do not use relationship between parameters such as random sampling and TPE. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required param_name str Name of the sampled parameter. required param_distribution BaseDistribution Distribution object that specifies a prior and/or scale of the sampling algorithm. required Returns: Type Description Any A parameter value. Source code in optuna/samplers/_cmaes.py Python def sample_independent ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , param_name : str , param_distribution : BaseDistribution , ) -> Any : self . _raise_error_if_multi_objective ( study ) if self . _warn_independent_sampling : complete_trials = self . _get_trials ( study ) if len ( complete_trials ) >= self . _n_startup_trials : self . _log_independent_sampling ( trial , param_name ) return self . _independent_sampler . sample_independent ( study , trial , param_name , param_distribution ) sample_relative ( self , study , trial , search_space ) Sample parameters in a given search space. This method is called once at the beginning of each trial, i.e., right before the evaluation of the objective function. This method is suitable for sampling algorithms that use relationship between parameters such as Gaussian Process and CMA-ES. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required search_space Dict[str, optuna.distributions.BaseDistribution] The search space returned by :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . required Returns: Type Description Dict[str, Any] A dictionary containing the parameter names and the values. Source code in optuna/samplers/_cmaes.py Python def sample_relative ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: self . _raise_error_if_multi_objective ( study ) if len ( search_space ) == 0 : return {} completed_trials = self . _get_trials ( study ) if len ( completed_trials ) < self . _n_startup_trials : return {} if len ( search_space ) == 1 : _logger . info ( \"`CmaEsSampler` only supports two or more dimensional continuous \" \"search space. ` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} trans = _SearchSpaceTransform ( search_space ) optimizer , n_restarts = self . _restore_optimizer ( completed_trials ) if optimizer is None : n_restarts = 0 optimizer = self . _init_optimizer ( trans , study . direction ) if self . _restart_strategy is None : generation_attr_key = \"cma:generation\" # for backward compatibility else : generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) if optimizer . dim != len ( trans . bounds ): _logger . info ( \"`CmaEsSampler` does not support dynamic search space. \" \"` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} # TODO(c-bata): Reduce the number of wasted trials during parallel optimization. # See https://github.com/optuna/optuna/pull/920#discussion_r385114002 for details. solution_trials = [ t for t in completed_trials if optimizer . generation == t . system_attrs . get ( generation_attr_key , - 1 ) ] if len ( solution_trials ) >= optimizer . population_size : solutions : List [ Tuple [ np . ndarray , float ]] = [] for t in solution_trials [: optimizer . population_size ]: assert t . value is not None , \"completed trials must have a value\" x = trans . transform ( t . params ) y = t . value if study . direction == StudyDirection . MINIMIZE else - t . value solutions . append (( x , y )) optimizer . tell ( solutions ) if self . _restart_strategy == \"ipop\" and optimizer . should_stop (): n_restarts += 1 generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) popsize = optimizer . population_size * self . _inc_popsize optimizer = self . _init_optimizer ( trans , study . direction , population_size = popsize , randomize_start_point = True ) # Store optimizer optimizer_str = pickle . dumps ( optimizer ) . hex () optimizer_attrs = _split_optimizer_str ( optimizer_str ) for key in optimizer_attrs : study . _storage . set_trial_system_attr ( trial . _trial_id , key , optimizer_attrs [ key ]) # Caution: optimizer should update its seed value seed = self . _cma_rng . randint ( 1 , 2 ** 16 ) + trial . number optimizer . _rng = np . random . RandomState ( seed ) params = optimizer . ask () study . _storage . set_trial_system_attr ( trial . _trial_id , generation_attr_key , optimizer . generation ) study . _storage . set_trial_system_attr ( trial . _trial_id , \"cma:n_restarts\" , n_restarts ) external_values = trans . untransform ( params ) return external_values LEXDE Multi-objective sampler using the Lex-DE algorithm. Lex-DE stands for \"Differential Evolution with Lexicase selection\". Parameters: Name Type Description Default population_size int Number of individuals (trials) in a generation. 100 F float Scaling factor of differential mutation. This parameter is applied to the differential vector between parent individuals. 0.5 CR float Crossover rate of binary crossover. This parameter shows the probability to crossover the child individual with a parent individual. 0.5 mutation_eta float Index parameter of polynomial mutation. 20 Source code in optuna_externm/opt/_lexde.py Python class LEXDESampler ( BaseSampler ): \"\"\"Multi-objective sampler using the Lex-DE algorithm. Lex-DE stands for \"Differential Evolution with Lexicase selection\". Args: population_size: Number of individuals (trials) in a generation. F: Scaling factor of differential mutation. This parameter is applied to the differential vector between parent individuals. CR: Crossover rate of binary crossover. This parameter shows the probability to crossover the child individual with a parent individual. mutation_eta: Index parameter of polynomial mutation. \"\"\" def __init__ ( self , * , population_size : int = 100 , F : float = 0.5 , CR : float = 0.5 , seed : Optional [ int ] = None , constraints_func : Optional [ Callable [[ FrozenTrial ], Sequence [ float ]]] = None , mutation_eta : float = 20 , ) -> None : self . _population_size = population_size self . _F = F self . _CR = CR self . _random_sampler = RandomSampler ( seed = seed ) self . _rng = np . random . RandomState ( seed ) self . _constraints_func = constraints_func self . _mutation_eta = mutation_eta self . _search_space = IntersectionSearchSpace () def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState () def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # The `untransform` method of `optuna._transform._SearchSpaceTransform` # does not assume a single value, # so single value objects are not sampled with the `sample_relative` method, # but with the `sample_independent` method. continue search_space [ name ] = distribution return search_space def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : # Select the first parent by automatic epsilon lexicase selection # and the rest two parents by random selection; Perform DE mutation, # binary crossover, and polynomial mutation # x1: lexicase; x2, x3: random # y = x1 + F * (x2 - x3) # y = bin(y, x1) # y = polym(y) # Automatic epsilon lexicase selection parents = selAutomaticEpsilonLexicase ( study , parent_population , 1 , self . _rng ) + selRandom ( study , parent_population , 2 , self . _rng ) # Convert population to array ( parents_numerical_params_array , numerical_transform , numerical_distributions ) = population_to_numerical_params_array ( parents , search_space , ) # DE mutation child_params_array = mutDEBounded ( parents_numerical_params_array [ 0 ], parents_numerical_params_array [ 1 ], parents_numerical_params_array [ 2 ], self . _rng , self . _F , numerical_distributions , ) # DE binary crossover child_params_array = cxDEBinary ( child_params_array , parents_numerical_params_array [ 0 ], self . _rng , self . _CR , ) # Polynomial mutation child_params_array = mutPolynomialBounded ( child_params_array , self . _rng , self . _mutation_eta , numerical_distributions , ) # convert array to params child_params : Dict [ str , Any ] = {} child_numerical_params = numerical_transform . untransform ( child_params_array ) child_params . update ( child_numerical_params ) params = {} for param_name in child_params . keys (): params [ param_name ] = child_params [ param_name ] return params return {} def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : # Following parameters are randomly sampled here. # 1. A parameter in the initial population/first generation. # 2. A parameter to mutate. # 3. A parameter excluded from the intersection search space. return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) def _collect_parent_population ( self , study : Study ) -> Tuple [ int , List [ FrozenTrial ]]: # TODO: this method requires a reimplementation trials = study . get_trials ( deepcopy = False ) generation_to_runnings = defaultdict ( list ) generation_to_population = defaultdict ( list ) for trial in trials : if _GENERATION_KEY not in trial . system_attrs : continue generation = trial . system_attrs [ _GENERATION_KEY ] if trial . state != optuna . trial . TrialState . COMPLETE : if trial . state == optuna . trial . TrialState . RUNNING : generation_to_runnings [ generation ] . append ( trial ) continue # Do not use trials whose states are not COMPLETE, or `constraint` will be unavailable. generation_to_population [ generation ] . append ( trial ) hasher = hashlib . sha256 () parent_population : List [ FrozenTrial ] = [] parent_generation = - 1 while True : generation = parent_generation + 1 population = generation_to_population [ generation ] if len ( population ) < self . _population_size : break for trial in generation_to_runnings [ generation ]: hasher . update ( bytes ( str ( trial . number ), \"utf-8\" )) cache_key = \" {} : {} \" . format ( _POPULATION_CACHE_KEY_PREFIX , hasher . hexdigest ()) cached_generation , cached_population_numbers = study . system_attrs . get ( cache_key , ( - 1 , []) ) if cached_generation >= generation : generation = cached_generation population = [ trials [ n ] for n in cached_population_numbers ] else : population . extend ( parent_population ) population = self . _select_elite_population ( study , population ) if len ( generation_to_runnings [ generation ]) == 0 : population_numbers = [ t . number for t in population ] study . set_system_attr ( cache_key , ( generation , population_numbers )) parent_generation = generation parent_population = population return parent_generation , parent_population def _select_elite_population ( self , study : Study , population : List [ FrozenTrial ] ) -> List [ FrozenTrial ]: elite_population : List [ FrozenTrial ] = [] population_per_rank = self . _fast_non_dominated_sort ( population , study . directions ) for population in population_per_rank : if len ( elite_population ) + len ( population ) < self . _population_size : elite_population . extend ( population ) else : n = self . _population_size - len ( elite_population ) _crowding_distance_sort ( population ) elite_population . extend ( population [: n ]) break return elite_population def _fast_non_dominated_sort ( self , population : List [ FrozenTrial ], directions : List [ optuna . study . StudyDirection ], ) -> List [ List [ FrozenTrial ]]: dominated_count : DefaultDict [ int , int ] = defaultdict ( int ) dominates_list = defaultdict ( list ) dominates = _dominates if self . _constraints_func is None else _constrained_dominates for p , q in itertools . combinations ( population , 2 ): if dominates ( p , q , directions ): dominates_list [ p . number ] . append ( q . number ) dominated_count [ q . number ] += 1 elif dominates ( q , p , directions ): dominates_list [ q . number ] . append ( p . number ) dominated_count [ p . number ] += 1 population_per_rank = [] while population : non_dominated_population = [] i = 0 while i < len ( population ): if dominated_count [ population [ i ] . number ] == 0 : individual = population [ i ] if i == len ( population ) - 1 : population . pop () else : population [ i ] = population . pop () non_dominated_population . append ( individual ) else : i += 1 for x in non_dominated_population : for y in dominates_list [ x . number ]: dominated_count [ y ] -= 1 assert non_dominated_population population_per_rank . append ( non_dominated_population ) return population_per_rank def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values ) after_trial ( self , study , trial , state , values ) Trial post-processing. This method is called after the objective function returns and right before the trials is finished and its state is stored. .. note:: Added in v2.4.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.4.0. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required state TrialState Resulting trial state. required values Optional[Sequence[float]] Resulting trial values. Guaranteed to not be :obj: None if trial succeeded. required Source code in optuna_externm/opt/_lexde.py Python def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values ) infer_relative_search_space ( self , study , trial ) Infer the search space that will be used by relative sampling in the target trial. This method is called right before :func: ~optuna.samplers.BaseSampler.sample_relative method, and the search space returned by this method is passed to it. The parameters not contained in the search space will be sampled by using :func: ~optuna.samplers.BaseSampler.sample_independent method. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required Returns: Type Description Dict[str, optuna.distributions.BaseDistribution] A dictionary containing the parameter names and parameter's distributions. .. seealso:: Please refer to :func: ~optuna.samplers.intersection_search_space as an implementation of :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . Source code in optuna_externm/opt/_lexde.py Python def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # The `untransform` method of `optuna._transform._SearchSpaceTransform` # does not assume a single value, # so single value objects are not sampled with the `sample_relative` method, # but with the `sample_independent` method. continue search_space [ name ] = distribution return search_space reseed_rng ( self ) Reseed sampler's random number generator. This method is called by the :class: ~optuna.study.Study instance if trials are executed in parallel with the option n_jobs>1 . In that case, the sampler instance will be replicated including the state of the random number generator, and they may suggest the same values. To prevent this issue, this method assigns a different seed to each random number generator. Source code in optuna_externm/opt/_lexde.py Python def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState () sample_independent ( self , study , trial , param_name , param_distribution ) Sample a parameter for a given distribution. This method is called only for the parameters not contained in the search space returned by :func: ~optuna.samplers.BaseSampler.sample_relative method. This method is suitable for sampling algorithms that do not use relationship between parameters such as random sampling and TPE. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required param_name str Name of the sampled parameter. required param_distribution BaseDistribution Distribution object that specifies a prior and/or scale of the sampling algorithm. required Returns: Type Description Any A parameter value. Source code in optuna_externm/opt/_lexde.py Python def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : # Following parameters are randomly sampled here. # 1. A parameter in the initial population/first generation. # 2. A parameter to mutate. # 3. A parameter excluded from the intersection search space. return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) sample_relative ( self , study , trial , search_space ) Sample parameters in a given search space. This method is called once at the beginning of each trial, i.e., right before the evaluation of the objective function. This method is suitable for sampling algorithms that use relationship between parameters such as Gaussian Process and CMA-ES. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required search_space Dict[str, optuna.distributions.BaseDistribution] The search space returned by :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . required Returns: Type Description Dict[str, Any] A dictionary containing the parameter names and the values. Source code in optuna_externm/opt/_lexde.py Python def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : # Select the first parent by automatic epsilon lexicase selection # and the rest two parents by random selection; Perform DE mutation, # binary crossover, and polynomial mutation # x1: lexicase; x2, x3: random # y = x1 + F * (x2 - x3) # y = bin(y, x1) # y = polym(y) # Automatic epsilon lexicase selection parents = selAutomaticEpsilonLexicase ( study , parent_population , 1 , self . _rng ) + selRandom ( study , parent_population , 2 , self . _rng ) # Convert population to array ( parents_numerical_params_array , numerical_transform , numerical_distributions ) = population_to_numerical_params_array ( parents , search_space , ) # DE mutation child_params_array = mutDEBounded ( parents_numerical_params_array [ 0 ], parents_numerical_params_array [ 1 ], parents_numerical_params_array [ 2 ], self . _rng , self . _F , numerical_distributions , ) # DE binary crossover child_params_array = cxDEBinary ( child_params_array , parents_numerical_params_array [ 0 ], self . _rng , self . _CR , ) # Polynomial mutation child_params_array = mutPolynomialBounded ( child_params_array , self . _rng , self . _mutation_eta , numerical_distributions , ) # convert array to params child_params : Dict [ str , Any ] = {} child_numerical_params = numerical_transform . untransform ( child_params_array ) child_params . update ( child_numerical_params ) params = {} for param_name in child_params . keys (): params [ param_name ] = child_params [ param_name ] return params return {}","title":"Optimisation Samplers"},{"location":"api/opt.html#optuna_externmopt","text":"","title":"optuna_externm.opt"},{"location":"api/opt.html#nsgaii","text":"This sampler is from and maintained by optuna but included here for convienience. Multi-objective sampler using the NSGA-II algorithm. NSGA-II stands for \"Nondominated Sorting Genetic Algorithm II\", which is a well known, fast and elitist multi-objective genetic algorithm. For further information about NSGA-II, please refer to the following paper: A fast and elitist multiobjective genetic algorithm: NSGA-II <https://ieeexplore.ieee.org/document/996017> _ Parameters: Name Type Description Default population_size int Number of individuals (trials) in a generation. 50 mutation_prob Optional[float] Probability of mutating each parameter when creating a new individual. If :obj: None is specified, the value 1.0 / len(parent_trial.params) is used where parent_trial is the parent trial of the target individual. None crossover_prob float Probability that a crossover (parameters swapping between parents) will occur when creating a new individual. 0.9 swapping_prob float Probability of swapping each parameter of the parents during crossover. 0.5 seed Optional[int] Seed for random number generator. None constraints_func Optional[Callable[[optuna.trial._frozen.FrozenTrial], Sequence[float]]] An optional function that computes the objective constraints. It must take a :class: ~optuna.trial.FrozenTrial and return the constraints. The return value must be a sequence of :obj: float s. A value strictly larger than 0 means that a constraints is violated. A value equal to or smaller than 0 is considered feasible. If constraints_func returns more than one value for a trial, that trial is considered feasible if and only if all values are equal to 0 or smaller. The constraints_func will be evaluated after each successful trial. The function won't be called when trials fail or they are pruned, but this behavior is subject to change in the future releases. The constraints are handled by the constrained domination. A trial x is said to constrained-dominate a trial y, if any of the following conditions is true: Trial x is feasible and trial y is not. Trial x and y are both infeasible, but trial x has a smaller overall violation. Trial x and y are feasible and trial x dominates trial y. .. note:: Added in v2.5.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.5.0. None Source code in optuna/samplers/_nsga2.py Python class NSGAIISampler ( BaseSampler ): \"\"\"Multi-objective sampler using the NSGA-II algorithm. NSGA-II stands for \"Nondominated Sorting Genetic Algorithm II\", which is a well known, fast and elitist multi-objective genetic algorithm. For further information about NSGA-II, please refer to the following paper: - `A fast and elitist multiobjective genetic algorithm: NSGA-II <https://ieeexplore.ieee.org/document/996017>`_ Args: population_size: Number of individuals (trials) in a generation. mutation_prob: Probability of mutating each parameter when creating a new individual. If :obj:`None` is specified, the value ``1.0 / len(parent_trial.params)`` is used where ``parent_trial`` is the parent trial of the target individual. crossover_prob: Probability that a crossover (parameters swapping between parents) will occur when creating a new individual. swapping_prob: Probability of swapping each parameter of the parents during crossover. seed: Seed for random number generator. constraints_func: An optional function that computes the objective constraints. It must take a :class:`~optuna.trial.FrozenTrial` and return the constraints. The return value must be a sequence of :obj:`float` s. A value strictly larger than 0 means that a constraints is violated. A value equal to or smaller than 0 is considered feasible. If ``constraints_func`` returns more than one value for a trial, that trial is considered feasible if and only if all values are equal to 0 or smaller. The ``constraints_func`` will be evaluated after each successful trial. The function won't be called when trials fail or they are pruned, but this behavior is subject to change in the future releases. The constraints are handled by the constrained domination. A trial x is said to constrained-dominate a trial y, if any of the following conditions is true: 1. Trial x is feasible and trial y is not. 2. Trial x and y are both infeasible, but trial x has a smaller overall violation. 3. Trial x and y are feasible and trial x dominates trial y. .. note:: Added in v2.5.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.5.0. \"\"\" def __init__ ( self , * , population_size : int = 50 , mutation_prob : Optional [ float ] = None , crossover_prob : float = 0.9 , swapping_prob : float = 0.5 , seed : Optional [ int ] = None , constraints_func : Optional [ Callable [[ FrozenTrial ], Sequence [ float ]]] = None , ) -> None : # TODO(ohta): Reconsider the default value of each parameter. if not isinstance ( population_size , int ): raise TypeError ( \"`population_size` must be an integer value.\" ) if population_size < 2 : raise ValueError ( \"`population_size` must be greater than or equal to 2.\" ) if not ( mutation_prob is None or 0.0 <= mutation_prob <= 1.0 ): raise ValueError ( \"`mutation_prob` must be None or a float value within the range [0.0, 1.0].\" ) if not ( 0.0 <= crossover_prob <= 1.0 ): raise ValueError ( \"`crossover_prob` must be a float value within the range [0.0, 1.0].\" ) if not ( 0.0 <= swapping_prob <= 1.0 ): raise ValueError ( \"`swapping_prob` must be a float value within the range [0.0, 1.0].\" ) if constraints_func is not None : warnings . warn ( \"The constraints_func option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) self . _population_size = population_size self . _mutation_prob = mutation_prob self . _crossover_prob = crossover_prob self . _swapping_prob = swapping_prob self . _random_sampler = RandomSampler ( seed = seed ) self . _rng = np . random . RandomState ( seed ) self . _constraints_func = constraints_func def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState () def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: return {} def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : p0 = self . _select_parent ( study , parent_population ) if self . _rng . rand () < self . _crossover_prob : p1 = self . _select_parent ( study , [ t for t in parent_population if t . _trial_id != p0 . _trial_id ] ) else : p1 = p0 study . _storage . set_trial_system_attr ( trial_id , _PARENTS_KEY , [ p0 . _trial_id , p1 . _trial_id ] ) return {} def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : if _PARENTS_KEY not in trial . system_attrs : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) p0_id , p1_id = trial . system_attrs [ _PARENTS_KEY ] p0 = study . _storage . get_trial ( p0_id ) p1 = study . _storage . get_trial ( p1_id ) param = p0 . params . get ( param_name , None ) parent_params_len = len ( p0 . params ) if param is None or self . _rng . rand () < self . _swapping_prob : param = p1 . params . get ( param_name , None ) parent_params_len = len ( p1 . params ) mutation_prob = self . _mutation_prob if mutation_prob is None : mutation_prob = 1.0 / max ( 1.0 , parent_params_len ) if param is None or self . _rng . rand () < mutation_prob : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) return param def _collect_parent_population ( self , study : Study ) -> Tuple [ int , List [ FrozenTrial ]]: trials = study . get_trials ( deepcopy = False ) generation_to_runnings = defaultdict ( list ) generation_to_population = defaultdict ( list ) for trial in trials : if _GENERATION_KEY not in trial . system_attrs : continue generation = trial . system_attrs [ _GENERATION_KEY ] if trial . state != optuna . trial . TrialState . COMPLETE : if trial . state == optuna . trial . TrialState . RUNNING : generation_to_runnings [ generation ] . append ( trial ) continue # Do not use trials whose states are not COMPLETE, or `constraint` will be unavailable. generation_to_population [ generation ] . append ( trial ) hasher = hashlib . sha256 () parent_population : List [ FrozenTrial ] = [] parent_generation = - 1 while True : generation = parent_generation + 1 population = generation_to_population [ generation ] # Under multi-worker settings, the population size might become larger than # `self._population_size`. if len ( population ) < self . _population_size : break # [NOTE] # It's generally safe to assume that once the above condition is satisfied, # there are no additional individuals added to the generation (i.e., the members of # the generation have been fixed). # If the number of parallel workers is huge, this assumption can be broken, but # this is a very rare case and doesn't significantly impact optimization performance. # So we can ignore the case. # The cache key is calculated based on the key of the previous generation and # the remaining running trials in the current population. # If there are no running trials, the new cache key becomes exactly the same as # the previous one, and the cached content will be overwritten. This allows us to # skip redundant cache key calculations when this method is called for the subsequent # trials. for trial in generation_to_runnings [ generation ]: hasher . update ( bytes ( str ( trial . number ), \"utf-8\" )) cache_key = \" {} : {} \" . format ( _POPULATION_CACHE_KEY_PREFIX , hasher . hexdigest ()) cached_generation , cached_population_numbers = study . system_attrs . get ( cache_key , ( - 1 , []) ) if cached_generation >= generation : generation = cached_generation population = [ trials [ n ] for n in cached_population_numbers ] else : population . extend ( parent_population ) population = self . _select_elite_population ( study , population ) # To reduce the number of system attribute entries, # we cache the population information only if there are no running trials # (i.e., the information of the population has been fixed). # Usually, if there are no too delayed running trials, the single entry # will be used. if len ( generation_to_runnings [ generation ]) == 0 : population_numbers = [ t . number for t in population ] study . set_system_attr ( cache_key , ( generation , population_numbers )) parent_generation = generation parent_population = population return parent_generation , parent_population def _select_elite_population ( self , study : Study , population : List [ FrozenTrial ] ) -> List [ FrozenTrial ]: elite_population : List [ FrozenTrial ] = [] population_per_rank = self . _fast_non_dominated_sort ( population , study . directions ) for population in population_per_rank : if len ( elite_population ) + len ( population ) < self . _population_size : elite_population . extend ( population ) else : n = self . _population_size - len ( elite_population ) _crowding_distance_sort ( population ) elite_population . extend ( population [: n ]) break return elite_population def _select_parent ( self , study : Study , population : Sequence [ FrozenTrial ]) -> FrozenTrial : # TODO(ohta): Consider to allow users to specify the number of parent candidates. population_size = len ( population ) candidate0 = population [ self . _rng . choice ( population_size )] candidate1 = population [ self . _rng . choice ( population_size )] dominates = _dominates if self . _constraints_func is None else _constrained_dominates # TODO(ohta): Consider crowding distance. if dominates ( candidate0 , candidate1 , study . directions ): return candidate0 else : return candidate1 def _fast_non_dominated_sort ( self , population : List [ FrozenTrial ], directions : List [ optuna . study . StudyDirection ], ) -> List [ List [ FrozenTrial ]]: dominated_count : DefaultDict [ int , int ] = defaultdict ( int ) dominates_list = defaultdict ( list ) dominates = _dominates if self . _constraints_func is None else _constrained_dominates for p , q in itertools . combinations ( population , 2 ): if dominates ( p , q , directions ): dominates_list [ p . number ] . append ( q . number ) dominated_count [ q . number ] += 1 elif dominates ( q , p , directions ): dominates_list [ q . number ] . append ( p . number ) dominated_count [ p . number ] += 1 population_per_rank = [] while population : non_dominated_population = [] i = 0 while i < len ( population ): if dominated_count [ population [ i ] . number ] == 0 : individual = population [ i ] if i == len ( population ) - 1 : population . pop () else : population [ i ] = population . pop () non_dominated_population . append ( individual ) else : i += 1 for x in non_dominated_population : for y in dominates_list [ x . number ]: dominated_count [ y ] -= 1 assert non_dominated_population population_per_rank . append ( non_dominated_population ) return population_per_rank def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values )","title":"NSGAII"},{"location":"api/opt.html#optuna.samplers._nsga2.NSGAIISampler.after_trial","text":"Trial post-processing. This method is called after the objective function returns and right before the trials is finished and its state is stored. .. note:: Added in v2.4.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.4.0. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required state TrialState Resulting trial state. required values Optional[Sequence[float]] Resulting trial values. Guaranteed to not be :obj: None if trial succeeded. required Source code in optuna/samplers/_nsga2.py Python def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values )","title":"after_trial()"},{"location":"api/opt.html#optuna.samplers._nsga2.NSGAIISampler.infer_relative_search_space","text":"Infer the search space that will be used by relative sampling in the target trial. This method is called right before :func: ~optuna.samplers.BaseSampler.sample_relative method, and the search space returned by this method is passed to it. The parameters not contained in the search space will be sampled by using :func: ~optuna.samplers.BaseSampler.sample_independent method. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required Returns: Type Description Dict[str, optuna.distributions.BaseDistribution] A dictionary containing the parameter names and parameter's distributions. .. seealso:: Please refer to :func: ~optuna.samplers.intersection_search_space as an implementation of :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . Source code in optuna/samplers/_nsga2.py Python def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: return {}","title":"infer_relative_search_space()"},{"location":"api/opt.html#optuna.samplers._nsga2.NSGAIISampler.reseed_rng","text":"Reseed sampler's random number generator. This method is called by the :class: ~optuna.study.Study instance if trials are executed in parallel with the option n_jobs>1 . In that case, the sampler instance will be replicated including the state of the random number generator, and they may suggest the same values. To prevent this issue, this method assigns a different seed to each random number generator. Source code in optuna/samplers/_nsga2.py Python def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState ()","title":"reseed_rng()"},{"location":"api/opt.html#optuna.samplers._nsga2.NSGAIISampler.sample_independent","text":"Sample a parameter for a given distribution. This method is called only for the parameters not contained in the search space returned by :func: ~optuna.samplers.BaseSampler.sample_relative method. This method is suitable for sampling algorithms that do not use relationship between parameters such as random sampling and TPE. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required param_name str Name of the sampled parameter. required param_distribution BaseDistribution Distribution object that specifies a prior and/or scale of the sampling algorithm. required Returns: Type Description Any A parameter value. Source code in optuna/samplers/_nsga2.py Python def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : if _PARENTS_KEY not in trial . system_attrs : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) p0_id , p1_id = trial . system_attrs [ _PARENTS_KEY ] p0 = study . _storage . get_trial ( p0_id ) p1 = study . _storage . get_trial ( p1_id ) param = p0 . params . get ( param_name , None ) parent_params_len = len ( p0 . params ) if param is None or self . _rng . rand () < self . _swapping_prob : param = p1 . params . get ( param_name , None ) parent_params_len = len ( p1 . params ) mutation_prob = self . _mutation_prob if mutation_prob is None : mutation_prob = 1.0 / max ( 1.0 , parent_params_len ) if param is None or self . _rng . rand () < mutation_prob : return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) return param","title":"sample_independent()"},{"location":"api/opt.html#optuna.samplers._nsga2.NSGAIISampler.sample_relative","text":"Sample parameters in a given search space. This method is called once at the beginning of each trial, i.e., right before the evaluation of the objective function. This method is suitable for sampling algorithms that use relationship between parameters such as Gaussian Process and CMA-ES. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required search_space Dict[str, optuna.distributions.BaseDistribution] The search space returned by :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . required Returns: Type Description Dict[str, Any] A dictionary containing the parameter names and the values. Source code in optuna/samplers/_nsga2.py Python def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : p0 = self . _select_parent ( study , parent_population ) if self . _rng . rand () < self . _crossover_prob : p1 = self . _select_parent ( study , [ t for t in parent_population if t . _trial_id != p0 . _trial_id ] ) else : p1 = p0 study . _storage . set_trial_system_attr ( trial_id , _PARENTS_KEY , [ p0 . _trial_id , p1 . _trial_id ] ) return {}","title":"sample_relative()"},{"location":"api/opt.html#cmaes","text":"This sampler is from and maintained by optuna but included here for convienience. A sampler using cmaes <https://github.com/CyberAgentAILab/cmaes> _ as the backend. Examples: Optimize a simple quadratic function by using :class: ~optuna.samplers.CmaEsSampler . .. testcode:: import optuna def objective(trial): x = trial.suggest_float(\"x\", -1, 1) y = trial.suggest_int(\"y\", -1, 1) return x ** 2 + y sampler = optuna.samplers.CmaEsSampler() study = optuna.create_study(sampler=sampler) study.optimize(objective, n_trials=20) Please note that this sampler does not support CategoricalDistribution. However, :class: ~optuna.distributions.DiscreteUniformDistribution (:func: ~optuna.trial.Trial.suggest_discrete_uniform ) and Int(Log)Distribution (:func: ~optuna.trial.Trial.suggest_int ) are supported. If your search space contains categorical parameters, I recommend you to use :class: ~optuna.samplers.TPESampler instead. Furthermore, there is room for performance improvements in parallel optimization settings. This sampler cannot use some trials for updating the parameters of multivariate normal distribution. For further information about CMA-ES algorithm, please refer to the following papers: N. Hansen, The CMA Evolution Strategy: A Tutorial. arXiv:1604.00772, 2016. <https://arxiv.org/abs/1604.00772> _ A. Auger and N. Hansen. A restart CMA evolution strategy with increasing population size. In Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2005), pages 1769\u20131776. IEEE Press, 2005. <http://www.cmap.polytechnique.fr/~nikolaus.hansen/cec2005ipopcmaes.pdf> _ Raymond Ros, Nikolaus Hansen. A Simple Modification in CMA-ES Achieving Linear Time and Space Complexity. 10th International Conference on Parallel Problem Solving From Nature, Sep 2008, Dortmund, Germany. inria-00287367. <https://hal.inria.fr/inria-00287367/document> _ Masahiro Nomura, Shuhei Watanabe, Youhei Akimoto, Yoshihiko Ozaki, Masaki Onishi. Warm Starting CMA-ES for Hyperparameter Optimization, AAAI. 2021. <https://arxiv.org/abs/2012.06932> _ .. seealso:: You can also use :class: optuna.integration.PyCmaSampler which is a sampler using cma library as the backend. Parameters: Name Type Description Default x0 Optional[Dict[str, Any]] A dictionary of an initial parameter values for CMA-ES. By default, the mean of low and high for each distribution is used. Note that x0 is sampled uniformly within the search space domain for each restart if you specify restart_strategy argument. None sigma0 Optional[float] Initial standard deviation of CMA-ES. By default, sigma0 is set to min_range / 6 , where min_range denotes the minimum range of the distributions in the search space. None seed Optional[int] A random seed for CMA-ES. None n_startup_trials int The independent sampling is used instead of the CMA-ES algorithm until the given number of trials finish in the same study. 1 independent_sampler Optional[optuna.samplers._base.BaseSampler] A :class: ~optuna.samplers.BaseSampler instance that is used for independent sampling. The parameters not contained in the relative search space are sampled by this sampler. The search space for :class: ~optuna.samplers.CmaEsSampler is determined by :func: ~optuna.samplers.intersection_search_space() . If :obj: None is specified, :class: ~optuna.samplers.RandomSampler is used as the default. .. seealso:: :class: optuna.samplers module provides built-in independent samplers such as :class: ~optuna.samplers.RandomSampler and :class: ~optuna.samplers.TPESampler . None warn_independent_sampling bool If this is :obj: True , a warning message is emitted when the value of a parameter is sampled by using an independent sampler. Note that the parameters of the first trial in a study are always sampled via an independent sampler, so no warning messages are emitted in this case. True restart_strategy Optional[str] Strategy for restarting CMA-ES optimization when converges to a local minimum. If given :obj: None , CMA-ES will not restart (default). If given 'ipop', CMA-ES will restart with increasing population size. Please see also inc_popsize parameter. .. note:: Added in v2.1.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.1.0. None inc_popsize int Multiplier for increasing population size before each restart. This argument will be used when setting restart_strategy = 'ipop' . 2 consider_pruned_trials bool If this is :obj: True , the PRUNED trials are considered for sampling. .. note:: Added in v2.0.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.0.0. .. note:: It is suggested to set this flag :obj: False when the :class: ~optuna.pruners.MedianPruner is used. On the other hand, it is suggested to set this flag :obj: True when the :class: ~optuna.pruners.HyperbandPruner is used. Please see the benchmark result <https://github.com/optuna/optuna/pull/1229> _ for the details. False use_separable_cma bool If this is :obj: True , the covariance matrix is constrained to be diagonal. Due to reduce the model complexity, the learning rate for the covariance matrix is increased. Consequently, this algorithm outperforms CMA-ES on separable functions. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. False source_trials Optional[List[optuna.trial._frozen.FrozenTrial]] This option is for Warm Starting CMA-ES, a method to transfer prior knowledge on similar HPO tasks through the initialization of CMA-ES. This method estimates a promising distribution from source_trials and generates the parameter of multivariate gaussian distribution. Please note that it is prohibited to use x0 , sigma0 , or use_separable_cma argument together. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. None Source code in optuna/samplers/_cmaes.py Python class CmaEsSampler ( BaseSampler ): \"\"\"A sampler using `cmaes <https://github.com/CyberAgentAILab/cmaes>`_ as the backend. Example: Optimize a simple quadratic function by using :class:`~optuna.samplers.CmaEsSampler`. .. testcode:: import optuna def objective(trial): x = trial.suggest_float(\"x\", -1, 1) y = trial.suggest_int(\"y\", -1, 1) return x ** 2 + y sampler = optuna.samplers.CmaEsSampler() study = optuna.create_study(sampler=sampler) study.optimize(objective, n_trials=20) Please note that this sampler does not support CategoricalDistribution. However, :class:`~optuna.distributions.DiscreteUniformDistribution` (:func:`~optuna.trial.Trial.suggest_discrete_uniform`) and Int(Log)Distribution (:func:`~optuna.trial.Trial.suggest_int`) are supported. If your search space contains categorical parameters, I recommend you to use :class:`~optuna.samplers.TPESampler` instead. Furthermore, there is room for performance improvements in parallel optimization settings. This sampler cannot use some trials for updating the parameters of multivariate normal distribution. For further information about CMA-ES algorithm, please refer to the following papers: - `N. Hansen, The CMA Evolution Strategy: A Tutorial. arXiv:1604.00772, 2016. <https://arxiv.org/abs/1604.00772>`_ - `A. Auger and N. Hansen. A restart CMA evolution strategy with increasing population size. In Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2005), pages 1769\u20131776. IEEE Press, 2005. <http://www.cmap.polytechnique.fr/~nikolaus.hansen/cec2005ipopcmaes.pdf>`_ - `Raymond Ros, Nikolaus Hansen. A Simple Modification in CMA-ES Achieving Linear Time and Space Complexity. 10th International Conference on Parallel Problem Solving From Nature, Sep 2008, Dortmund, Germany. inria-00287367. <https://hal.inria.fr/inria-00287367/document>`_ - `Masahiro Nomura, Shuhei Watanabe, Youhei Akimoto, Yoshihiko Ozaki, Masaki Onishi. Warm Starting CMA-ES for Hyperparameter Optimization, AAAI. 2021. <https://arxiv.org/abs/2012.06932>`_ .. seealso:: You can also use :class:`optuna.integration.PyCmaSampler` which is a sampler using cma library as the backend. Args: x0: A dictionary of an initial parameter values for CMA-ES. By default, the mean of ``low`` and ``high`` for each distribution is used. Note that ``x0`` is sampled uniformly within the search space domain for each restart if you specify ``restart_strategy`` argument. sigma0: Initial standard deviation of CMA-ES. By default, ``sigma0`` is set to ``min_range / 6``, where ``min_range`` denotes the minimum range of the distributions in the search space. seed: A random seed for CMA-ES. n_startup_trials: The independent sampling is used instead of the CMA-ES algorithm until the given number of trials finish in the same study. independent_sampler: A :class:`~optuna.samplers.BaseSampler` instance that is used for independent sampling. The parameters not contained in the relative search space are sampled by this sampler. The search space for :class:`~optuna.samplers.CmaEsSampler` is determined by :func:`~optuna.samplers.intersection_search_space()`. If :obj:`None` is specified, :class:`~optuna.samplers.RandomSampler` is used as the default. .. seealso:: :class:`optuna.samplers` module provides built-in independent samplers such as :class:`~optuna.samplers.RandomSampler` and :class:`~optuna.samplers.TPESampler`. warn_independent_sampling: If this is :obj:`True`, a warning message is emitted when the value of a parameter is sampled by using an independent sampler. Note that the parameters of the first trial in a study are always sampled via an independent sampler, so no warning messages are emitted in this case. restart_strategy: Strategy for restarting CMA-ES optimization when converges to a local minimum. If given :obj:`None`, CMA-ES will not restart (default). If given 'ipop', CMA-ES will restart with increasing population size. Please see also ``inc_popsize`` parameter. .. note:: Added in v2.1.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.1.0. inc_popsize: Multiplier for increasing population size before each restart. This argument will be used when setting ``restart_strategy = 'ipop'``. consider_pruned_trials: If this is :obj:`True`, the PRUNED trials are considered for sampling. .. note:: Added in v2.0.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.0.0. .. note:: It is suggested to set this flag :obj:`False` when the :class:`~optuna.pruners.MedianPruner` is used. On the other hand, it is suggested to set this flag :obj:`True` when the :class:`~optuna.pruners.HyperbandPruner` is used. Please see `the benchmark result <https://github.com/optuna/optuna/pull/1229>`_ for the details. use_separable_cma: If this is :obj:`True`, the covariance matrix is constrained to be diagonal. Due to reduce the model complexity, the learning rate for the covariance matrix is increased. Consequently, this algorithm outperforms CMA-ES on separable functions. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. source_trials: This option is for Warm Starting CMA-ES, a method to transfer prior knowledge on similar HPO tasks through the initialization of CMA-ES. This method estimates a promising distribution from ``source_trials`` and generates the parameter of multivariate gaussian distribution. Please note that it is prohibited to use ``x0``, ``sigma0``, or ``use_separable_cma`` argument together. .. note:: Added in v2.6.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.6.0. Raises: ValueError: If ``restart_strategy`` is not 'ipop' or :obj:`None`. \"\"\" def __init__ ( self , x0 : Optional [ Dict [ str , Any ]] = None , sigma0 : Optional [ float ] = None , n_startup_trials : int = 1 , independent_sampler : Optional [ BaseSampler ] = None , warn_independent_sampling : bool = True , seed : Optional [ int ] = None , * , consider_pruned_trials : bool = False , restart_strategy : Optional [ str ] = None , inc_popsize : int = 2 , use_separable_cma : bool = False , source_trials : Optional [ List [ FrozenTrial ]] = None , ) -> None : self . _x0 = x0 self . _sigma0 = sigma0 self . _independent_sampler = independent_sampler or optuna . samplers . RandomSampler ( seed = seed ) self . _n_startup_trials = n_startup_trials self . _warn_independent_sampling = warn_independent_sampling self . _cma_rng = np . random . RandomState ( seed ) self . _search_space = optuna . samplers . IntersectionSearchSpace () self . _consider_pruned_trials = consider_pruned_trials self . _restart_strategy = restart_strategy self . _inc_popsize = inc_popsize self . _use_separable_cma = use_separable_cma self . _source_trials = source_trials if self . _restart_strategy : warnings . warn ( \"`restart_strategy` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if self . _consider_pruned_trials : warnings . warn ( \"`consider_pruned_trials` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if self . _use_separable_cma : warnings . warn ( \"`use_separable_cma` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if self . _source_trials is not None : warnings . warn ( \"`source_trials` option is an experimental feature.\" \" The interface can change in the future.\" , ExperimentalWarning , ) if source_trials is not None and ( x0 is not None or sigma0 is not None ): raise ValueError ( \"It is prohibited to pass `source_trials` argument when \" \"x0 or sigma0 is specified.\" ) # TODO(c-bata): Support WS-sep-CMA-ES. if source_trials is not None and use_separable_cma : raise ValueError ( \"It is prohibited to pass `source_trials` argument when \" \"using separable CMA-ES.\" ) # TODO(c-bata): Support BIPOP-CMA-ES. if restart_strategy not in ( \"ipop\" , None , ): raise ValueError ( \"restart_strategy= {} is unsupported. Please specify: 'ipop' or None.\" . format ( restart_strategy ) ) def reseed_rng ( self ) -> None : # _cma_rng doesn't require reseeding because the relative sampling reseeds in each trial. self . _independent_sampler . reseed_rng () def infer_relative_search_space ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # `cma` cannot handle distributions that contain just a single value, so we skip # them. Note that the parameter values for such distributions are sampled in # `Trial`. continue if not isinstance ( distribution , ( optuna . distributions . UniformDistribution , optuna . distributions . LogUniformDistribution , optuna . distributions . DiscreteUniformDistribution , optuna . distributions . IntUniformDistribution , optuna . distributions . IntLogUniformDistribution , ), ): # Categorical distribution is unsupported. continue search_space [ name ] = distribution return search_space def sample_relative ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: self . _raise_error_if_multi_objective ( study ) if len ( search_space ) == 0 : return {} completed_trials = self . _get_trials ( study ) if len ( completed_trials ) < self . _n_startup_trials : return {} if len ( search_space ) == 1 : _logger . info ( \"`CmaEsSampler` only supports two or more dimensional continuous \" \"search space. ` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} trans = _SearchSpaceTransform ( search_space ) optimizer , n_restarts = self . _restore_optimizer ( completed_trials ) if optimizer is None : n_restarts = 0 optimizer = self . _init_optimizer ( trans , study . direction ) if self . _restart_strategy is None : generation_attr_key = \"cma:generation\" # for backward compatibility else : generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) if optimizer . dim != len ( trans . bounds ): _logger . info ( \"`CmaEsSampler` does not support dynamic search space. \" \"` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} # TODO(c-bata): Reduce the number of wasted trials during parallel optimization. # See https://github.com/optuna/optuna/pull/920#discussion_r385114002 for details. solution_trials = [ t for t in completed_trials if optimizer . generation == t . system_attrs . get ( generation_attr_key , - 1 ) ] if len ( solution_trials ) >= optimizer . population_size : solutions : List [ Tuple [ np . ndarray , float ]] = [] for t in solution_trials [: optimizer . population_size ]: assert t . value is not None , \"completed trials must have a value\" x = trans . transform ( t . params ) y = t . value if study . direction == StudyDirection . MINIMIZE else - t . value solutions . append (( x , y )) optimizer . tell ( solutions ) if self . _restart_strategy == \"ipop\" and optimizer . should_stop (): n_restarts += 1 generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) popsize = optimizer . population_size * self . _inc_popsize optimizer = self . _init_optimizer ( trans , study . direction , population_size = popsize , randomize_start_point = True ) # Store optimizer optimizer_str = pickle . dumps ( optimizer ) . hex () optimizer_attrs = _split_optimizer_str ( optimizer_str ) for key in optimizer_attrs : study . _storage . set_trial_system_attr ( trial . _trial_id , key , optimizer_attrs [ key ]) # Caution: optimizer should update its seed value seed = self . _cma_rng . randint ( 1 , 2 ** 16 ) + trial . number optimizer . _rng = np . random . RandomState ( seed ) params = optimizer . ask () study . _storage . set_trial_system_attr ( trial . _trial_id , generation_attr_key , optimizer . generation ) study . _storage . set_trial_system_attr ( trial . _trial_id , \"cma:n_restarts\" , n_restarts ) external_values = trans . untransform ( params ) return external_values def _restore_optimizer ( self , completed_trials : \"List[optuna.trial.FrozenTrial]\" , ) -> Tuple [ Optional [ CmaClass ], int ]: if not self . _use_separable_cma : attr_key_optimizer = \"cma:optimizer\" attr_key_n_restarts = \"cma:n_restarts\" else : attr_key_optimizer = \"sepcma:optimizer\" attr_key_n_restarts = \"sepcma:n_restarts\" # Restore a previous CMA object. for trial in reversed ( completed_trials ): optimizer_attrs = { key : value for key , value in trial . system_attrs . items () if key . startswith ( attr_key_optimizer ) } if len ( optimizer_attrs ) == 0 : continue if not self . _use_separable_cma and \"cma:optimizer\" in optimizer_attrs : # Check \"cma:optimizer\" key for backward compatibility. optimizer_str = optimizer_attrs [ \"cma:optimizer\" ] else : optimizer_str = _concat_optimizer_attrs ( optimizer_attrs ) n_restarts : int = trial . system_attrs . get ( attr_key_n_restarts , 0 ) return pickle . loads ( bytes . fromhex ( optimizer_str )), n_restarts return None , 0 def _init_optimizer ( self , trans : _SearchSpaceTransform , direction : StudyDirection , population_size : Optional [ int ] = None , randomize_start_point : bool = False , ) -> CmaClass : lower_bounds = trans . bounds [:, 0 ] upper_bounds = trans . bounds [:, 1 ] n_dimension = len ( trans . bounds ) if self . _source_trials is None : if randomize_start_point : mean = lower_bounds + ( upper_bounds - lower_bounds ) * self . _cma_rng . rand ( n_dimension ) elif self . _x0 is None : mean = lower_bounds + ( upper_bounds - lower_bounds ) / 2 else : # `self._x0` is external representations. mean = trans . transform ( self . _x0 ) if self . _sigma0 is None : sigma0 = np . min (( upper_bounds - lower_bounds ) / 6 ) else : sigma0 = self . _sigma0 cov = None else : expected_states = [ TrialState . COMPLETE ] if self . _consider_pruned_trials : expected_states . append ( TrialState . PRUNED ) # TODO(c-bata): Filter parameters by their values instead of checking search space. sign = 1 if direction == StudyDirection . MINIMIZE else - 1 source_solutions = [ ( trans . transform ( t . params ), sign * cast ( float , t . value )) for t in self . _source_trials if t . state in expected_states and _is_compatible_search_space ( trans , t . distributions ) ] if len ( source_solutions ) == 0 : raise ValueError ( \"No compatible source_trials\" ) # TODO(c-bata): Add options to change prior parameters (alpha and gamma). mean , sigma0 , cov = get_warm_start_mgd ( source_solutions ) # Avoid ZeroDivisionError in cmaes. sigma0 = max ( sigma0 , _EPS ) if self . _use_separable_cma : return SepCMA ( mean = mean , sigma = sigma0 , bounds = trans . bounds , seed = self . _cma_rng . randint ( 1 , 2 ** 31 - 2 ), n_max_resampling = 10 * n_dimension , population_size = population_size , ) return CMA ( mean = mean , sigma = sigma0 , cov = cov , bounds = trans . bounds , seed = self . _cma_rng . randint ( 1 , 2 ** 31 - 2 ), n_max_resampling = 10 * n_dimension , population_size = population_size , ) def sample_independent ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , param_name : str , param_distribution : BaseDistribution , ) -> Any : self . _raise_error_if_multi_objective ( study ) if self . _warn_independent_sampling : complete_trials = self . _get_trials ( study ) if len ( complete_trials ) >= self . _n_startup_trials : self . _log_independent_sampling ( trial , param_name ) return self . _independent_sampler . sample_independent ( study , trial , param_name , param_distribution ) def _log_independent_sampling ( self , trial : FrozenTrial , param_name : str ) -> None : _logger . warning ( \"The parameter ' {} ' in trial# {} is sampled independently \" \"by using ` {} ` instead of `CmaEsSampler` \" \"(optimization performance may be degraded). \" \"`CmaEsSampler` does not support dynamic search space or `CategoricalDistribution`. \" \"You can suppress this warning by setting `warn_independent_sampling` \" \"to `False` in the constructor of `CmaEsSampler`, \" \"if this independent sampling is intended behavior.\" . format ( param_name , trial . number , self . _independent_sampler . __class__ . __name__ ) ) def _get_trials ( self , study : \"optuna.Study\" ) -> List [ FrozenTrial ]: complete_trials = [] for t in study . get_trials ( deepcopy = False ): if t . state == TrialState . COMPLETE : complete_trials . append ( t ) elif ( t . state == TrialState . PRUNED and len ( t . intermediate_values ) > 0 and self . _consider_pruned_trials ): _ , value = max ( t . intermediate_values . items ()) if value is None : continue # We rewrite the value of the trial `t` for sampling, so we need a deepcopy. copied_t = copy . deepcopy ( t ) copied_t . value = value complete_trials . append ( copied_t ) return complete_trials def after_trial ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : self . _independent_sampler . after_trial ( study , trial , state , values )","title":"CMAES"},{"location":"api/opt.html#optuna.samplers._cmaes.CmaEsSampler.after_trial","text":"Trial post-processing. This method is called after the objective function returns and right before the trials is finished and its state is stored. .. note:: Added in v2.4.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.4.0. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required state TrialState Resulting trial state. required values Optional[Sequence[float]] Resulting trial values. Guaranteed to not be :obj: None if trial succeeded. required Source code in optuna/samplers/_cmaes.py Python def after_trial ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : self . _independent_sampler . after_trial ( study , trial , state , values )","title":"after_trial()"},{"location":"api/opt.html#optuna.samplers._cmaes.CmaEsSampler.infer_relative_search_space","text":"Infer the search space that will be used by relative sampling in the target trial. This method is called right before :func: ~optuna.samplers.BaseSampler.sample_relative method, and the search space returned by this method is passed to it. The parameters not contained in the search space will be sampled by using :func: ~optuna.samplers.BaseSampler.sample_independent method. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required Returns: Type Description Dict[str, optuna.distributions.BaseDistribution] A dictionary containing the parameter names and parameter's distributions. .. seealso:: Please refer to :func: ~optuna.samplers.intersection_search_space as an implementation of :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . Source code in optuna/samplers/_cmaes.py Python def infer_relative_search_space ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # `cma` cannot handle distributions that contain just a single value, so we skip # them. Note that the parameter values for such distributions are sampled in # `Trial`. continue if not isinstance ( distribution , ( optuna . distributions . UniformDistribution , optuna . distributions . LogUniformDistribution , optuna . distributions . DiscreteUniformDistribution , optuna . distributions . IntUniformDistribution , optuna . distributions . IntLogUniformDistribution , ), ): # Categorical distribution is unsupported. continue search_space [ name ] = distribution return search_space","title":"infer_relative_search_space()"},{"location":"api/opt.html#optuna.samplers._cmaes.CmaEsSampler.reseed_rng","text":"Reseed sampler's random number generator. This method is called by the :class: ~optuna.study.Study instance if trials are executed in parallel with the option n_jobs>1 . In that case, the sampler instance will be replicated including the state of the random number generator, and they may suggest the same values. To prevent this issue, this method assigns a different seed to each random number generator. Source code in optuna/samplers/_cmaes.py Python def reseed_rng ( self ) -> None : # _cma_rng doesn't require reseeding because the relative sampling reseeds in each trial. self . _independent_sampler . reseed_rng ()","title":"reseed_rng()"},{"location":"api/opt.html#optuna.samplers._cmaes.CmaEsSampler.sample_independent","text":"Sample a parameter for a given distribution. This method is called only for the parameters not contained in the search space returned by :func: ~optuna.samplers.BaseSampler.sample_relative method. This method is suitable for sampling algorithms that do not use relationship between parameters such as random sampling and TPE. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required param_name str Name of the sampled parameter. required param_distribution BaseDistribution Distribution object that specifies a prior and/or scale of the sampling algorithm. required Returns: Type Description Any A parameter value. Source code in optuna/samplers/_cmaes.py Python def sample_independent ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , param_name : str , param_distribution : BaseDistribution , ) -> Any : self . _raise_error_if_multi_objective ( study ) if self . _warn_independent_sampling : complete_trials = self . _get_trials ( study ) if len ( complete_trials ) >= self . _n_startup_trials : self . _log_independent_sampling ( trial , param_name ) return self . _independent_sampler . sample_independent ( study , trial , param_name , param_distribution )","title":"sample_independent()"},{"location":"api/opt.html#optuna.samplers._cmaes.CmaEsSampler.sample_relative","text":"Sample parameters in a given search space. This method is called once at the beginning of each trial, i.e., right before the evaluation of the objective function. This method is suitable for sampling algorithms that use relationship between parameters such as Gaussian Process and CMA-ES. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study optuna.Study Target study object. required trial optuna.trial.FrozenTrial Target trial object. Take a copy before modifying this object. required search_space Dict[str, optuna.distributions.BaseDistribution] The search space returned by :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . required Returns: Type Description Dict[str, Any] A dictionary containing the parameter names and the values. Source code in optuna/samplers/_cmaes.py Python def sample_relative ( self , study : \"optuna.Study\" , trial : \"optuna.trial.FrozenTrial\" , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: self . _raise_error_if_multi_objective ( study ) if len ( search_space ) == 0 : return {} completed_trials = self . _get_trials ( study ) if len ( completed_trials ) < self . _n_startup_trials : return {} if len ( search_space ) == 1 : _logger . info ( \"`CmaEsSampler` only supports two or more dimensional continuous \" \"search space. ` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} trans = _SearchSpaceTransform ( search_space ) optimizer , n_restarts = self . _restore_optimizer ( completed_trials ) if optimizer is None : n_restarts = 0 optimizer = self . _init_optimizer ( trans , study . direction ) if self . _restart_strategy is None : generation_attr_key = \"cma:generation\" # for backward compatibility else : generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) if optimizer . dim != len ( trans . bounds ): _logger . info ( \"`CmaEsSampler` does not support dynamic search space. \" \"` {} ` is used instead of `CmaEsSampler`.\" . format ( self . _independent_sampler . __class__ . __name__ ) ) self . _warn_independent_sampling = False return {} # TODO(c-bata): Reduce the number of wasted trials during parallel optimization. # See https://github.com/optuna/optuna/pull/920#discussion_r385114002 for details. solution_trials = [ t for t in completed_trials if optimizer . generation == t . system_attrs . get ( generation_attr_key , - 1 ) ] if len ( solution_trials ) >= optimizer . population_size : solutions : List [ Tuple [ np . ndarray , float ]] = [] for t in solution_trials [: optimizer . population_size ]: assert t . value is not None , \"completed trials must have a value\" x = trans . transform ( t . params ) y = t . value if study . direction == StudyDirection . MINIMIZE else - t . value solutions . append (( x , y )) optimizer . tell ( solutions ) if self . _restart_strategy == \"ipop\" and optimizer . should_stop (): n_restarts += 1 generation_attr_key = \"cma:restart_ {} :generation\" . format ( n_restarts ) popsize = optimizer . population_size * self . _inc_popsize optimizer = self . _init_optimizer ( trans , study . direction , population_size = popsize , randomize_start_point = True ) # Store optimizer optimizer_str = pickle . dumps ( optimizer ) . hex () optimizer_attrs = _split_optimizer_str ( optimizer_str ) for key in optimizer_attrs : study . _storage . set_trial_system_attr ( trial . _trial_id , key , optimizer_attrs [ key ]) # Caution: optimizer should update its seed value seed = self . _cma_rng . randint ( 1 , 2 ** 16 ) + trial . number optimizer . _rng = np . random . RandomState ( seed ) params = optimizer . ask () study . _storage . set_trial_system_attr ( trial . _trial_id , generation_attr_key , optimizer . generation ) study . _storage . set_trial_system_attr ( trial . _trial_id , \"cma:n_restarts\" , n_restarts ) external_values = trans . untransform ( params ) return external_values","title":"sample_relative()"},{"location":"api/opt.html#lexde","text":"Multi-objective sampler using the Lex-DE algorithm. Lex-DE stands for \"Differential Evolution with Lexicase selection\". Parameters: Name Type Description Default population_size int Number of individuals (trials) in a generation. 100 F float Scaling factor of differential mutation. This parameter is applied to the differential vector between parent individuals. 0.5 CR float Crossover rate of binary crossover. This parameter shows the probability to crossover the child individual with a parent individual. 0.5 mutation_eta float Index parameter of polynomial mutation. 20 Source code in optuna_externm/opt/_lexde.py Python class LEXDESampler ( BaseSampler ): \"\"\"Multi-objective sampler using the Lex-DE algorithm. Lex-DE stands for \"Differential Evolution with Lexicase selection\". Args: population_size: Number of individuals (trials) in a generation. F: Scaling factor of differential mutation. This parameter is applied to the differential vector between parent individuals. CR: Crossover rate of binary crossover. This parameter shows the probability to crossover the child individual with a parent individual. mutation_eta: Index parameter of polynomial mutation. \"\"\" def __init__ ( self , * , population_size : int = 100 , F : float = 0.5 , CR : float = 0.5 , seed : Optional [ int ] = None , constraints_func : Optional [ Callable [[ FrozenTrial ], Sequence [ float ]]] = None , mutation_eta : float = 20 , ) -> None : self . _population_size = population_size self . _F = F self . _CR = CR self . _random_sampler = RandomSampler ( seed = seed ) self . _rng = np . random . RandomState ( seed ) self . _constraints_func = constraints_func self . _mutation_eta = mutation_eta self . _search_space = IntersectionSearchSpace () def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState () def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # The `untransform` method of `optuna._transform._SearchSpaceTransform` # does not assume a single value, # so single value objects are not sampled with the `sample_relative` method, # but with the `sample_independent` method. continue search_space [ name ] = distribution return search_space def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : # Select the first parent by automatic epsilon lexicase selection # and the rest two parents by random selection; Perform DE mutation, # binary crossover, and polynomial mutation # x1: lexicase; x2, x3: random # y = x1 + F * (x2 - x3) # y = bin(y, x1) # y = polym(y) # Automatic epsilon lexicase selection parents = selAutomaticEpsilonLexicase ( study , parent_population , 1 , self . _rng ) + selRandom ( study , parent_population , 2 , self . _rng ) # Convert population to array ( parents_numerical_params_array , numerical_transform , numerical_distributions ) = population_to_numerical_params_array ( parents , search_space , ) # DE mutation child_params_array = mutDEBounded ( parents_numerical_params_array [ 0 ], parents_numerical_params_array [ 1 ], parents_numerical_params_array [ 2 ], self . _rng , self . _F , numerical_distributions , ) # DE binary crossover child_params_array = cxDEBinary ( child_params_array , parents_numerical_params_array [ 0 ], self . _rng , self . _CR , ) # Polynomial mutation child_params_array = mutPolynomialBounded ( child_params_array , self . _rng , self . _mutation_eta , numerical_distributions , ) # convert array to params child_params : Dict [ str , Any ] = {} child_numerical_params = numerical_transform . untransform ( child_params_array ) child_params . update ( child_numerical_params ) params = {} for param_name in child_params . keys (): params [ param_name ] = child_params [ param_name ] return params return {} def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : # Following parameters are randomly sampled here. # 1. A parameter in the initial population/first generation. # 2. A parameter to mutate. # 3. A parameter excluded from the intersection search space. return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution ) def _collect_parent_population ( self , study : Study ) -> Tuple [ int , List [ FrozenTrial ]]: # TODO: this method requires a reimplementation trials = study . get_trials ( deepcopy = False ) generation_to_runnings = defaultdict ( list ) generation_to_population = defaultdict ( list ) for trial in trials : if _GENERATION_KEY not in trial . system_attrs : continue generation = trial . system_attrs [ _GENERATION_KEY ] if trial . state != optuna . trial . TrialState . COMPLETE : if trial . state == optuna . trial . TrialState . RUNNING : generation_to_runnings [ generation ] . append ( trial ) continue # Do not use trials whose states are not COMPLETE, or `constraint` will be unavailable. generation_to_population [ generation ] . append ( trial ) hasher = hashlib . sha256 () parent_population : List [ FrozenTrial ] = [] parent_generation = - 1 while True : generation = parent_generation + 1 population = generation_to_population [ generation ] if len ( population ) < self . _population_size : break for trial in generation_to_runnings [ generation ]: hasher . update ( bytes ( str ( trial . number ), \"utf-8\" )) cache_key = \" {} : {} \" . format ( _POPULATION_CACHE_KEY_PREFIX , hasher . hexdigest ()) cached_generation , cached_population_numbers = study . system_attrs . get ( cache_key , ( - 1 , []) ) if cached_generation >= generation : generation = cached_generation population = [ trials [ n ] for n in cached_population_numbers ] else : population . extend ( parent_population ) population = self . _select_elite_population ( study , population ) if len ( generation_to_runnings [ generation ]) == 0 : population_numbers = [ t . number for t in population ] study . set_system_attr ( cache_key , ( generation , population_numbers )) parent_generation = generation parent_population = population return parent_generation , parent_population def _select_elite_population ( self , study : Study , population : List [ FrozenTrial ] ) -> List [ FrozenTrial ]: elite_population : List [ FrozenTrial ] = [] population_per_rank = self . _fast_non_dominated_sort ( population , study . directions ) for population in population_per_rank : if len ( elite_population ) + len ( population ) < self . _population_size : elite_population . extend ( population ) else : n = self . _population_size - len ( elite_population ) _crowding_distance_sort ( population ) elite_population . extend ( population [: n ]) break return elite_population def _fast_non_dominated_sort ( self , population : List [ FrozenTrial ], directions : List [ optuna . study . StudyDirection ], ) -> List [ List [ FrozenTrial ]]: dominated_count : DefaultDict [ int , int ] = defaultdict ( int ) dominates_list = defaultdict ( list ) dominates = _dominates if self . _constraints_func is None else _constrained_dominates for p , q in itertools . combinations ( population , 2 ): if dominates ( p , q , directions ): dominates_list [ p . number ] . append ( q . number ) dominated_count [ q . number ] += 1 elif dominates ( q , p , directions ): dominates_list [ q . number ] . append ( p . number ) dominated_count [ p . number ] += 1 population_per_rank = [] while population : non_dominated_population = [] i = 0 while i < len ( population ): if dominated_count [ population [ i ] . number ] == 0 : individual = population [ i ] if i == len ( population ) - 1 : population . pop () else : population [ i ] = population . pop () non_dominated_population . append ( individual ) else : i += 1 for x in non_dominated_population : for y in dominates_list [ x . number ]: dominated_count [ y ] -= 1 assert non_dominated_population population_per_rank . append ( non_dominated_population ) return population_per_rank def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values )","title":"LEXDE"},{"location":"api/opt.html#optuna_externm.opt._lexde.LEXDESampler.after_trial","text":"Trial post-processing. This method is called after the objective function returns and right before the trials is finished and its state is stored. .. note:: Added in v2.4.0 as an experimental feature. The interface may change in newer versions without prior notice. See https://github.com/optuna/optuna/releases/tag/v2.4.0. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required state TrialState Resulting trial state. required values Optional[Sequence[float]] Resulting trial values. Guaranteed to not be :obj: None if trial succeeded. required Source code in optuna_externm/opt/_lexde.py Python def after_trial ( self , study : Study , trial : FrozenTrial , state : TrialState , values : Optional [ Sequence [ float ]], ) -> None : assert state in [ TrialState . COMPLETE , TrialState . FAIL , TrialState . PRUNED ] if state == TrialState . COMPLETE and self . _constraints_func is not None : constraints = None try : con = self . _constraints_func ( trial ) if not isinstance ( con , ( tuple , list )): warnings . warn ( f \"Constraints should be a sequence of floats but got { type ( con ) . __name__ } .\" ) constraints = tuple ( con ) except Exception : raise finally : assert constraints is None or isinstance ( constraints , tuple ) study . _storage . set_trial_system_attr ( trial . _trial_id , _CONSTRAINTS_KEY , constraints , ) self . _random_sampler . after_trial ( study , trial , state , values )","title":"after_trial()"},{"location":"api/opt.html#optuna_externm.opt._lexde.LEXDESampler.infer_relative_search_space","text":"Infer the search space that will be used by relative sampling in the target trial. This method is called right before :func: ~optuna.samplers.BaseSampler.sample_relative method, and the search space returned by this method is passed to it. The parameters not contained in the search space will be sampled by using :func: ~optuna.samplers.BaseSampler.sample_independent method. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required Returns: Type Description Dict[str, optuna.distributions.BaseDistribution] A dictionary containing the parameter names and parameter's distributions. .. seealso:: Please refer to :func: ~optuna.samplers.intersection_search_space as an implementation of :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . Source code in optuna_externm/opt/_lexde.py Python def infer_relative_search_space ( self , study : Study , trial : FrozenTrial ) -> Dict [ str , BaseDistribution ]: search_space : Dict [ str , BaseDistribution ] = {} for name , distribution in self . _search_space . calculate ( study ) . items (): if distribution . single (): # The `untransform` method of `optuna._transform._SearchSpaceTransform` # does not assume a single value, # so single value objects are not sampled with the `sample_relative` method, # but with the `sample_independent` method. continue search_space [ name ] = distribution return search_space","title":"infer_relative_search_space()"},{"location":"api/opt.html#optuna_externm.opt._lexde.LEXDESampler.reseed_rng","text":"Reseed sampler's random number generator. This method is called by the :class: ~optuna.study.Study instance if trials are executed in parallel with the option n_jobs>1 . In that case, the sampler instance will be replicated including the state of the random number generator, and they may suggest the same values. To prevent this issue, this method assigns a different seed to each random number generator. Source code in optuna_externm/opt/_lexde.py Python def reseed_rng ( self ) -> None : self . _random_sampler . reseed_rng () self . _rng = np . random . RandomState ()","title":"reseed_rng()"},{"location":"api/opt.html#optuna_externm.opt._lexde.LEXDESampler.sample_independent","text":"Sample a parameter for a given distribution. This method is called only for the parameters not contained in the search space returned by :func: ~optuna.samplers.BaseSampler.sample_relative method. This method is suitable for sampling algorithms that do not use relationship between parameters such as random sampling and TPE. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required param_name str Name of the sampled parameter. required param_distribution BaseDistribution Distribution object that specifies a prior and/or scale of the sampling algorithm. required Returns: Type Description Any A parameter value. Source code in optuna_externm/opt/_lexde.py Python def sample_independent ( self , study : Study , trial : FrozenTrial , param_name : str , param_distribution : BaseDistribution , ) -> Any : # Following parameters are randomly sampled here. # 1. A parameter in the initial population/first generation. # 2. A parameter to mutate. # 3. A parameter excluded from the intersection search space. return self . _random_sampler . sample_independent ( study , trial , param_name , param_distribution )","title":"sample_independent()"},{"location":"api/opt.html#optuna_externm.opt._lexde.LEXDESampler.sample_relative","text":"Sample parameters in a given search space. This method is called once at the beginning of each trial, i.e., right before the evaluation of the objective function. This method is suitable for sampling algorithms that use relationship between parameters such as Gaussian Process and CMA-ES. .. note:: The failed trials are ignored by any build-in samplers when they sample new parameters. Thus, failed trials are regarded as deleted in the samplers' perspective. Parameters: Name Type Description Default study Study Target study object. required trial FrozenTrial Target trial object. Take a copy before modifying this object. required search_space Dict[str, optuna.distributions.BaseDistribution] The search space returned by :func: ~optuna.samplers.BaseSampler.infer_relative_search_space . required Returns: Type Description Dict[str, Any] A dictionary containing the parameter names and the values. Source code in optuna_externm/opt/_lexde.py Python def sample_relative ( self , study : Study , trial : FrozenTrial , search_space : Dict [ str , BaseDistribution ], ) -> Dict [ str , Any ]: parent_generation , parent_population = self . _collect_parent_population ( study ) trial_id = trial . _trial_id generation = parent_generation + 1 study . _storage . set_trial_system_attr ( trial_id , _GENERATION_KEY , generation ) if parent_generation >= 0 : # Select the first parent by automatic epsilon lexicase selection # and the rest two parents by random selection; Perform DE mutation, # binary crossover, and polynomial mutation # x1: lexicase; x2, x3: random # y = x1 + F * (x2 - x3) # y = bin(y, x1) # y = polym(y) # Automatic epsilon lexicase selection parents = selAutomaticEpsilonLexicase ( study , parent_population , 1 , self . _rng ) + selRandom ( study , parent_population , 2 , self . _rng ) # Convert population to array ( parents_numerical_params_array , numerical_transform , numerical_distributions ) = population_to_numerical_params_array ( parents , search_space , ) # DE mutation child_params_array = mutDEBounded ( parents_numerical_params_array [ 0 ], parents_numerical_params_array [ 1 ], parents_numerical_params_array [ 2 ], self . _rng , self . _F , numerical_distributions , ) # DE binary crossover child_params_array = cxDEBinary ( child_params_array , parents_numerical_params_array [ 0 ], self . _rng , self . _CR , ) # Polynomial mutation child_params_array = mutPolynomialBounded ( child_params_array , self . _rng , self . _mutation_eta , numerical_distributions , ) # convert array to params child_params : Dict [ str , Any ] = {} child_numerical_params = numerical_transform . untransform ( child_params_array ) child_params . update ( child_numerical_params ) params = {} for param_name in child_params . keys (): params [ param_name ] = child_params [ param_name ] return params return {}","title":"sample_relative()"},{"location":"api/sa.html","text":"optuna_externm.sa OVATSampler Source code in optuna_externm/sa/_ovat.py Python class OVATSampler : def __init__ ( self , ** inits ): pass def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ]): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DEF) \"\"\" nopt = len ( parameters ) dfault = { p . NAME : p . DEF for p in parameters } runs = dict () runs [ \"default\" ] = dfault dist = dict () for p in parameters : runs [ f \" { p . NAME } -\" ] = dfault . copy () runs [ f \" { p . NAME } -\" ][ p . NAME ] = p . LOW runs [ f \" { p . NAME } +\" ] = dfault . copy () runs [ f \" { p . NAME } +\" ][ p . NAME ] = p . HIGH dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) if study . system_attrs . get ( \"ovat_set\" ): print ( \"Study OVAT, already set\" ) return None else : study . set_system_attr ( \"ovat_set\" , True ) for name , run in runs . items (): trial = optuna . trial . create_trial ( params = run , state = optuna . trial . TrialState . WAITING , user_attrs = { \"name\" : name , \"opt\" : \"OVAT\" }, distributions = dist , ) study . add_trial ( trial ) enqueue_trials ( self , study , parameters ) Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH, DEF) required Source code in optuna_externm/sa/_ovat.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ]): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DEF) \"\"\" nopt = len ( parameters ) dfault = { p . NAME : p . DEF for p in parameters } runs = dict () runs [ \"default\" ] = dfault dist = dict () for p in parameters : runs [ f \" { p . NAME } -\" ] = dfault . copy () runs [ f \" { p . NAME } -\" ][ p . NAME ] = p . LOW runs [ f \" { p . NAME } +\" ] = dfault . copy () runs [ f \" { p . NAME } +\" ][ p . NAME ] = p . HIGH dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) if study . system_attrs . get ( \"ovat_set\" ): print ( \"Study OVAT, already set\" ) return None else : study . set_system_attr ( \"ovat_set\" , True ) for name , run in runs . items (): trial = optuna . trial . create_trial ( params = run , state = optuna . trial . TrialState . WAITING , user_attrs = { \"name\" : name , \"opt\" : \"OVAT\" }, distributions = dist , ) study . add_trial ( trial ) MeshGridSampler Source code in optuna_externm/sa/_meshgrid.py Python class MeshGridSampler : def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns # Create a dynamically-sized multi-dimensional meshgrid def _mesh_parameter_tuples ( self , * x : List [ np . ndarray ]) -> List [ Tuple ]: x_ = np . meshgrid ( * x , indexing = \"ij\" ) pars = [ v for v in zip ( * tuple ( pm . ravel () for pm in x_ ))] return pars def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () for p in parameters : pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : samples . append ( np . linspace ( p . LOW , p . HIGH , self . _ns )) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) elif p . DIST . upper () == \"LOG10\" : log_range = np . logspace ( np . log10 ( p . LOW ), np . log10 ( p . HIGH ), self . _ns ) log_range = np . clip ( log_range , p . LOW , p . HIGH ) samples . append ( log_range ) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) par_vals = self . _mesh_parameter_tuples ( * samples ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"MeshGrid\" }, distributions = dist , ) for vals in par_vals ] study . add_trials ( trials ) __init__ ( self , ns = 1 ) special Parameters: Name Type Description Default ns int The number of samples along each parameter axis 1 Source code in optuna_externm/sa/_meshgrid.py Python def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns enqueue_trials ( self , study , parameters ) Valid DIST keys for this sampler are UNIFORM , LOG10 Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH, DIST) required Source code in optuna_externm/sa/_meshgrid.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () for p in parameters : pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : samples . append ( np . linspace ( p . LOW , p . HIGH , self . _ns )) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) elif p . DIST . upper () == \"LOG10\" : log_range = np . logspace ( np . log10 ( p . LOW ), np . log10 ( p . HIGH ), self . _ns ) log_range = np . clip ( log_range , p . LOW , p . HIGH ) samples . append ( log_range ) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) par_vals = self . _mesh_parameter_tuples ( * samples ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"MeshGrid\" }, distributions = dist , ) for vals in par_vals ] study . add_trials ( trials ) LHCSampler Source code in optuna_externm/sa/_lhs.py Python class LHCSampler : def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns # Create a dynamically-sized multi-dimensional meshgrid def _mesh_parameter_tuples ( self , * x : List [ np . ndarray ]) -> List [ Tuple ]: x_ = np . meshgrid ( * x , indexing = \"ij\" ) pars = [ v for v in zip ( * tuple ( pm . ravel () for pm in x_ ))] return pars def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () nopt = len ( parameters ) lhd = lhs ( nopt , samples = self . _ns ) for i , p in enumerate ( parameters ): pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) lhd [:, i ] = lhd [:, i ] * ( p . HIGH - p . LOW ) + p . LOW elif p . DIST . upper () == \"LOG10\" : print ( \"log10\" ) lhd [:, i ] = loguniform ( a = p . LOW , b = p . HIGH ) . ppf ( lhd [:, i ]) dist [ p . NAME ] = LogUniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"LHC\" }, distributions = dist , ) for vals in lhd ] study . add_trials ( trials ) __init__ ( self , ns = 1 ) special Parameters: Name Type Description Default ns int The number of samples along each parameter axis 1 Source code in optuna_externm/sa/_lhs.py Python def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns enqueue_trials ( self , study , parameters ) Valid DIST keys for this sampler are UNIFORM , LOG10 Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH, DIST) required Source code in optuna_externm/sa/_lhs.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () nopt = len ( parameters ) lhd = lhs ( nopt , samples = self . _ns ) for i , p in enumerate ( parameters ): pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) lhd [:, i ] = lhd [:, i ] * ( p . HIGH - p . LOW ) + p . LOW elif p . DIST . upper () == \"LOG10\" : print ( \"log10\" ) lhd [:, i ] = loguniform ( a = p . LOW , b = p . HIGH ) . ppf ( lhd [:, i ]) dist [ p . NAME ] = LogUniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"LHC\" }, distributions = dist , ) for vals in lhd ] study . add_trials ( trials ) SobolSampler Saltelli-Sobol Sensitivity Sampling Global Sesnsitivty Analysis using Sobol-Saltelli Sampling Source code in optuna_externm/sa/_sobol.py Python class SobolSampler : \"\"\"Saltelli-Sobol Sensitivity Sampling Global Sesnsitivty Analysis using Sobol-Saltelli Sampling \"\"\" def __init__ ( self , rank : Union [ None , int ] = None , ns : Union [ None , int ] = None ): \"\"\" Args: ns: The number of samples to calculate rank: The sobol rank \"\"\" if rank is None and ns is None : raise ValueError ( \"One of rank or ns must not be None\" ) self . _rank = rank self . _ns = ns def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH) \"\"\" nopt = len ( parameters ) bounds = np . vstack ([( p . LOW , p . HIGH ) for p in parameters ]) param_names = [ p . NAME for p in parameters ] # create population matrix problem = dict ( num_vars = nopt , names = param_names , bounds = bounds , ) dist = { p . NAME : UniformDistribution ( p . LOW , p . HIGH ) for p in parameters } if self . _rank is not None : samples = saltelli . sample ( problem , self . _rank , calc_second_order = True ) else : n = 0 srank = 1 while n < self . _ns : samples = saltelli . sample ( problem , srank , calc_second_order = True ) n = samples . shape [ 0 ] srank += 1 if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( param_names , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"Sobol\" }, distributions = dist , ) for vals in samples ] study . add_trials ( trials ) __init__ ( self , rank = None , ns = None ) special Parameters: Name Type Description Default ns Optional[int] The number of samples to calculate None rank Optional[int] The sobol rank None Source code in optuna_externm/sa/_sobol.py Python def __init__ ( self , rank : Union [ None , int ] = None , ns : Union [ None , int ] = None ): \"\"\" Args: ns: The number of samples to calculate rank: The sobol rank \"\"\" if rank is None and ns is None : raise ValueError ( \"One of rank or ns must not be None\" ) self . _rank = rank self . _ns = ns enqueue_trials ( self , study , parameters ) Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH) required Source code in optuna_externm/sa/_sobol.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH) \"\"\" nopt = len ( parameters ) bounds = np . vstack ([( p . LOW , p . HIGH ) for p in parameters ]) param_names = [ p . NAME for p in parameters ] # create population matrix problem = dict ( num_vars = nopt , names = param_names , bounds = bounds , ) dist = { p . NAME : UniformDistribution ( p . LOW , p . HIGH ) for p in parameters } if self . _rank is not None : samples = saltelli . sample ( problem , self . _rank , calc_second_order = True ) else : n = 0 srank = 1 while n < self . _ns : samples = saltelli . sample ( problem , srank , calc_second_order = True ) n = samples . shape [ 0 ] srank += 1 if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( param_names , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"Sobol\" }, distributions = dist , ) for vals in samples ] study . add_trials ( trials )","title":"Sensitivity Samplers"},{"location":"api/sa.html#optuna_externmsa","text":"","title":"optuna_externm.sa"},{"location":"api/sa.html#ovatsampler","text":"Source code in optuna_externm/sa/_ovat.py Python class OVATSampler : def __init__ ( self , ** inits ): pass def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ]): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DEF) \"\"\" nopt = len ( parameters ) dfault = { p . NAME : p . DEF for p in parameters } runs = dict () runs [ \"default\" ] = dfault dist = dict () for p in parameters : runs [ f \" { p . NAME } -\" ] = dfault . copy () runs [ f \" { p . NAME } -\" ][ p . NAME ] = p . LOW runs [ f \" { p . NAME } +\" ] = dfault . copy () runs [ f \" { p . NAME } +\" ][ p . NAME ] = p . HIGH dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) if study . system_attrs . get ( \"ovat_set\" ): print ( \"Study OVAT, already set\" ) return None else : study . set_system_attr ( \"ovat_set\" , True ) for name , run in runs . items (): trial = optuna . trial . create_trial ( params = run , state = optuna . trial . TrialState . WAITING , user_attrs = { \"name\" : name , \"opt\" : \"OVAT\" }, distributions = dist , ) study . add_trial ( trial )","title":"OVATSampler"},{"location":"api/sa.html#optuna_externm.sa._ovat.OVATSampler.enqueue_trials","text":"Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH, DEF) required Source code in optuna_externm/sa/_ovat.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ]): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DEF) \"\"\" nopt = len ( parameters ) dfault = { p . NAME : p . DEF for p in parameters } runs = dict () runs [ \"default\" ] = dfault dist = dict () for p in parameters : runs [ f \" { p . NAME } -\" ] = dfault . copy () runs [ f \" { p . NAME } -\" ][ p . NAME ] = p . LOW runs [ f \" { p . NAME } +\" ] = dfault . copy () runs [ f \" { p . NAME } +\" ][ p . NAME ] = p . HIGH dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) if study . system_attrs . get ( \"ovat_set\" ): print ( \"Study OVAT, already set\" ) return None else : study . set_system_attr ( \"ovat_set\" , True ) for name , run in runs . items (): trial = optuna . trial . create_trial ( params = run , state = optuna . trial . TrialState . WAITING , user_attrs = { \"name\" : name , \"opt\" : \"OVAT\" }, distributions = dist , ) study . add_trial ( trial )","title":"enqueue_trials()"},{"location":"api/sa.html#meshgridsampler","text":"Source code in optuna_externm/sa/_meshgrid.py Python class MeshGridSampler : def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns # Create a dynamically-sized multi-dimensional meshgrid def _mesh_parameter_tuples ( self , * x : List [ np . ndarray ]) -> List [ Tuple ]: x_ = np . meshgrid ( * x , indexing = \"ij\" ) pars = [ v for v in zip ( * tuple ( pm . ravel () for pm in x_ ))] return pars def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () for p in parameters : pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : samples . append ( np . linspace ( p . LOW , p . HIGH , self . _ns )) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) elif p . DIST . upper () == \"LOG10\" : log_range = np . logspace ( np . log10 ( p . LOW ), np . log10 ( p . HIGH ), self . _ns ) log_range = np . clip ( log_range , p . LOW , p . HIGH ) samples . append ( log_range ) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) par_vals = self . _mesh_parameter_tuples ( * samples ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"MeshGrid\" }, distributions = dist , ) for vals in par_vals ] study . add_trials ( trials )","title":"MeshGridSampler"},{"location":"api/sa.html#optuna_externm.sa._meshgrid.MeshGridSampler.__init__","text":"Parameters: Name Type Description Default ns int The number of samples along each parameter axis 1 Source code in optuna_externm/sa/_meshgrid.py Python def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns","title":"__init__()"},{"location":"api/sa.html#optuna_externm.sa._meshgrid.MeshGridSampler.enqueue_trials","text":"Valid DIST keys for this sampler are UNIFORM , LOG10 Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH, DIST) required Source code in optuna_externm/sa/_meshgrid.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () for p in parameters : pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : samples . append ( np . linspace ( p . LOW , p . HIGH , self . _ns )) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) elif p . DIST . upper () == \"LOG10\" : log_range = np . logspace ( np . log10 ( p . LOW ), np . log10 ( p . HIGH ), self . _ns ) log_range = np . clip ( log_range , p . LOW , p . HIGH ) samples . append ( log_range ) dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) par_vals = self . _mesh_parameter_tuples ( * samples ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"MeshGrid\" }, distributions = dist , ) for vals in par_vals ] study . add_trials ( trials )","title":"enqueue_trials()"},{"location":"api/sa.html#lhcsampler","text":"Source code in optuna_externm/sa/_lhs.py Python class LHCSampler : def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns # Create a dynamically-sized multi-dimensional meshgrid def _mesh_parameter_tuples ( self , * x : List [ np . ndarray ]) -> List [ Tuple ]: x_ = np . meshgrid ( * x , indexing = \"ij\" ) pars = [ v for v in zip ( * tuple ( pm . ravel () for pm in x_ ))] return pars def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () nopt = len ( parameters ) lhd = lhs ( nopt , samples = self . _ns ) for i , p in enumerate ( parameters ): pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) lhd [:, i ] = lhd [:, i ] * ( p . HIGH - p . LOW ) + p . LOW elif p . DIST . upper () == \"LOG10\" : print ( \"log10\" ) lhd [:, i ] = loguniform ( a = p . LOW , b = p . HIGH ) . ppf ( lhd [:, i ]) dist [ p . NAME ] = LogUniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"LHC\" }, distributions = dist , ) for vals in lhd ] study . add_trials ( trials )","title":"LHCSampler"},{"location":"api/sa.html#optuna_externm.sa._lhs.LHCSampler.__init__","text":"Parameters: Name Type Description Default ns int The number of samples along each parameter axis 1 Source code in optuna_externm/sa/_lhs.py Python def __init__ ( self , ns : int = 1 , ): \"\"\" Args: ns: The number of samples along each parameter axis \"\"\" self . _ns = ns","title":"__init__()"},{"location":"api/sa.html#optuna_externm.sa._lhs.LHCSampler.enqueue_trials","text":"Valid DIST keys for this sampler are UNIFORM , LOG10 Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH, DIST) required Source code in optuna_externm/sa/_lhs.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Valid DIST keys for this sampler are `UNIFORM`, `LOG10` Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH, DIST) \"\"\" pars = list () samples = list () dist = dict () nopt = len ( parameters ) lhd = lhs ( nopt , samples = self . _ns ) for i , p in enumerate ( parameters ): pars . append ( p . NAME ) if p . DIST . upper () == \"UNIFORM\" : dist [ p . NAME ] = UniformDistribution ( p . LOW , p . HIGH ) lhd [:, i ] = lhd [:, i ] * ( p . HIGH - p . LOW ) + p . LOW elif p . DIST . upper () == \"LOG10\" : print ( \"log10\" ) lhd [:, i ] = loguniform ( a = p . LOW , b = p . HIGH ) . ppf ( lhd [:, i ]) dist [ p . NAME ] = LogUniformDistribution ( p . LOW , p . HIGH ) else : raise ValueError ( f \"Unknown distribution type { p . DIST } \" ) if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( pars , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"LHC\" }, distributions = dist , ) for vals in lhd ] study . add_trials ( trials )","title":"enqueue_trials()"},{"location":"api/sa.html#sobolsampler","text":"Saltelli-Sobol Sensitivity Sampling Global Sesnsitivty Analysis using Sobol-Saltelli Sampling Source code in optuna_externm/sa/_sobol.py Python class SobolSampler : \"\"\"Saltelli-Sobol Sensitivity Sampling Global Sesnsitivty Analysis using Sobol-Saltelli Sampling \"\"\" def __init__ ( self , rank : Union [ None , int ] = None , ns : Union [ None , int ] = None ): \"\"\" Args: ns: The number of samples to calculate rank: The sobol rank \"\"\" if rank is None and ns is None : raise ValueError ( \"One of rank or ns must not be None\" ) self . _rank = rank self . _ns = ns def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH) \"\"\" nopt = len ( parameters ) bounds = np . vstack ([( p . LOW , p . HIGH ) for p in parameters ]) param_names = [ p . NAME for p in parameters ] # create population matrix problem = dict ( num_vars = nopt , names = param_names , bounds = bounds , ) dist = { p . NAME : UniformDistribution ( p . LOW , p . HIGH ) for p in parameters } if self . _rank is not None : samples = saltelli . sample ( problem , self . _rank , calc_second_order = True ) else : n = 0 srank = 1 while n < self . _ns : samples = saltelli . sample ( problem , srank , calc_second_order = True ) n = samples . shape [ 0 ] srank += 1 if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( param_names , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"Sobol\" }, distributions = dist , ) for vals in samples ] study . add_trials ( trials )","title":"SobolSampler"},{"location":"api/sa.html#optuna_externm.sa._sobol.SobolSampler.__init__","text":"Parameters: Name Type Description Default ns Optional[int] The number of samples to calculate None rank Optional[int] The sobol rank None Source code in optuna_externm/sa/_sobol.py Python def __init__ ( self , rank : Union [ None , int ] = None , ns : Union [ None , int ] = None ): \"\"\" Args: ns: The number of samples to calculate rank: The sobol rank \"\"\" if rank is None and ns is None : raise ValueError ( \"One of rank or ns must not be None\" ) self . _rank = rank self . _ns = ns","title":"__init__()"},{"location":"api/sa.html#optuna_externm.sa._sobol.SobolSampler.enqueue_trials","text":"Parameters: Name Type Description Default study Study An Optuna Study required parameters List[NamedTuple] Tuple Names must include (NAME, LOW, HIGH) required Source code in optuna_externm/sa/_sobol.py Python def enqueue_trials ( self , study : optuna . Study , parameters : List [ NamedTuple ], ): \"\"\" Args: study: An Optuna Study parameters: Tuple Names must include (NAME, LOW, HIGH) \"\"\" nopt = len ( parameters ) bounds = np . vstack ([( p . LOW , p . HIGH ) for p in parameters ]) param_names = [ p . NAME for p in parameters ] # create population matrix problem = dict ( num_vars = nopt , names = param_names , bounds = bounds , ) dist = { p . NAME : UniformDistribution ( p . LOW , p . HIGH ) for p in parameters } if self . _rank is not None : samples = saltelli . sample ( problem , self . _rank , calc_second_order = True ) else : n = 0 srank = 1 while n < self . _ns : samples = saltelli . sample ( problem , srank , calc_second_order = True ) n = samples . shape [ 0 ] srank += 1 if study . system_attrs . get ( \"mesh_set\" ): print ( \"Study mesh, already set\" ) return None else : study . set_system_attr ( \"mesh_set\" , True ) trials = [ optuna . trial . create_trial ( params = { par_name : val for par_name , val in zip ( param_names , vals )}, state = optuna . trial . TrialState . WAITING , user_attrs = { \"opt\" : \"Sobol\" }, distributions = dist , ) for vals in samples ] study . add_trials ( trials )","title":"enqueue_trials()"},{"location":"cli/cli.html","text":"optuna-em gc Usage gc help menu To see the help menu Bash optuna-em gc --help Which has output: Bash Usage: optuna-em gc [ OPTIONS ] Generate a default yaml config file. Options: -f, --fname TEXT --help Show this message and exit. optuna-em results Usage results help menu To see the help menu Bash optuna-em results --help Which has output: Bash Usage: optuna-em results [ OPTIONS ] CONFIG_FILE Options: -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit. optuna-em sa Usage sa help menu To see the help menu Bash optuna-em sa --help Which has output: Bash Usage: optuna-em sa [ OPTIONS ] CONFIG_FILE Process a configurartion file and run a sensitivity analysis study. Options: -j, --jobs INTEGER RANGE Number of parallel processors to use for running model evaluations. [ 1 < = x< = 4 ] -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit. A default CONFIG_FILE can be generated by Bash optuna-em gc sa optuna-em opt Usage opt help menu To see the help menu Bash optuna-em opt --help Which has output: Bash Usage: optuna-em opt [ OPTIONS ] CONFIG_FILE Process a configurartion file and run an optimisation study. Options: -j, --jobs INTEGER RANGE Number of parallel processors to use for running model evaluations. [ 1 < = x< = 4 ] -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit. A default CONFIG_FILE can be generated by Bash optuna-em gc opt optuna-em opt Config OPTUNA section parameters Parameters for controlling Optuna bmh_function_name : str pydantic-field The name of the function which returns the BaseModelHandler to be evaluated. direction : _DirectionEnum pydantic-field The optimisation direction (minimize/maximise), if using Multi-Objective use 'directions' parameters. directions : List [ optuna_externm . config . _DirectionEnum ] pydantic-field The optimisation direction (minimize/maximise), if using Multi-Objective use 'directions' parameters. n_trials : int pydantic-field The number of trials that should be run. opt_model_file : Path pydantic-field The optimisation model python file. optuna_sqldb : str pydantic-field Adress of Optuna SQL database for studies. optuna_study_name : str pydantic-field The name of the Optuna study - SQL ID sampler : str pydantic-field The sampler to use with Optuna. A section with the sampler name will be required for sampler specific parameters. USER section parameters Put paramters here that will be exposed to the BaseModelHandler user_example : str pydantic-field An example user parameter comment. Example Configuration YAML OPTUNA : optuna_sqldb : '' optuna_study_name : '' sampler : nsgaii direction : ~ directions : ~ opt_model_file : '' bmh_function_name : setup n_trials : 1 USER : user_example : example_user_paramter","title":"CLI"},{"location":"cli/cli.html#optuna-em-gc-usage","text":"","title":"optuna-em gc Usage"},{"location":"cli/cli.html#gc-help-menu","text":"To see the help menu Bash optuna-em gc --help Which has output: Bash Usage: optuna-em gc [ OPTIONS ] Generate a default yaml config file. Options: -f, --fname TEXT --help Show this message and exit.","title":"gc help menu"},{"location":"cli/cli.html#optuna-em-results-usage","text":"","title":"optuna-em results Usage"},{"location":"cli/cli.html#results-help-menu","text":"To see the help menu Bash optuna-em results --help Which has output: Bash Usage: optuna-em results [ OPTIONS ] CONFIG_FILE Options: -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit.","title":"results help menu"},{"location":"cli/cli.html#optuna-em-sa-usage","text":"","title":"optuna-em sa Usage"},{"location":"cli/cli.html#sa-help-menu","text":"To see the help menu Bash optuna-em sa --help Which has output: Bash Usage: optuna-em sa [ OPTIONS ] CONFIG_FILE Process a configurartion file and run a sensitivity analysis study. Options: -j, --jobs INTEGER RANGE Number of parallel processors to use for running model evaluations. [ 1 < = x< = 4 ] -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit. A default CONFIG_FILE can be generated by Bash optuna-em gc sa","title":"sa help menu"},{"location":"cli/cli.html#optuna-em-opt-usage","text":"","title":"optuna-em opt Usage"},{"location":"cli/cli.html#opt-help-menu","text":"To see the help menu Bash optuna-em opt --help Which has output: Bash Usage: optuna-em opt [ OPTIONS ] CONFIG_FILE Process a configurartion file and run an optimisation study. Options: -j, --jobs INTEGER RANGE Number of parallel processors to use for running model evaluations. [ 1 < = x< = 4 ] -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit. A default CONFIG_FILE can be generated by Bash optuna-em gc opt","title":"opt help menu"},{"location":"cli/cli.html#optuna-em-opt-config","text":"","title":"optuna-em opt Config"},{"location":"cli/cli.html#optuna-section-parameters","text":"Parameters for controlling Optuna","title":"OPTUNA section parameters"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.bmh_function_name","text":"The name of the function which returns the BaseModelHandler to be evaluated.","title":"bmh_function_name"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.direction","text":"The optimisation direction (minimize/maximise), if using Multi-Objective use 'directions' parameters.","title":"direction"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.directions","text":"The optimisation direction (minimize/maximise), if using Multi-Objective use 'directions' parameters.","title":"directions"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.n_trials","text":"The number of trials that should be run.","title":"n_trials"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.opt_model_file","text":"The optimisation model python file.","title":"opt_model_file"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.optuna_sqldb","text":"Adress of Optuna SQL database for studies.","title":"optuna_sqldb"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.optuna_study_name","text":"The name of the Optuna study - SQL ID","title":"optuna_study_name"},{"location":"cli/cli.html#optuna_externm.config._OptunaConfig.sampler","text":"The sampler to use with Optuna. A section with the sampler name will be required for sampler specific parameters.","title":"sampler"},{"location":"cli/cli.html#user-section-parameters","text":"Put paramters here that will be exposed to the BaseModelHandler","title":"USER section parameters"},{"location":"cli/cli.html#optuna_externm.config._UserConfig.user_example","text":"An example user parameter comment.","title":"user_example"},{"location":"cli/cli.html#example-configuration","text":"YAML OPTUNA : optuna_sqldb : '' optuna_study_name : '' sampler : nsgaii direction : ~ directions : ~ opt_model_file : '' bmh_function_name : setup n_trials : 1 USER : user_example : example_user_paramter","title":"Example Configuration"},{"location":"cli/help_gc.html","text":"To see the help menu Bash optuna-em gc --help Which has output: Bash Usage: optuna-em gc [ OPTIONS ] Generate a default yaml config file. Options: -f, --fname TEXT --help Show this message and exit.","title":"Help gc"},{"location":"cli/help_opt.html","text":"To see the help menu Bash optuna-em opt --help Which has output: Bash Usage: optuna-em opt [ OPTIONS ] CONFIG_FILE Process a configurartion file and run an optimisation study. Options: -j, --jobs INTEGER RANGE Number of parallel processors to use for running model evaluations. [ 1 < = x< = 4 ] -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit. A default CONFIG_FILE can be generated by Bash optuna-em gc opt","title":"Help opt"},{"location":"cli/help_results.html","text":"To see the help menu Bash optuna-em results --help Which has output: Bash Usage: optuna-em results [ OPTIONS ] CONFIG_FILE Options: -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit.","title":"Help results"},{"location":"cli/help_sa.html","text":"To see the help menu Bash optuna-em sa --help Which has output: Bash Usage: optuna-em sa [ OPTIONS ] CONFIG_FILE Process a configurartion file and run a sensitivity analysis study. Options: -j, --jobs INTEGER RANGE Number of parallel processors to use for running model evaluations. [ 1 < = x< = 4 ] -d, --debug BOOLEAN Activate debugging output. --help Show this message and exit. A default CONFIG_FILE can be generated by Bash optuna-em gc sa","title":"Help sa"},{"location":"ophm/about.html","text":"","title":"About"},{"location":"ophm/api_handlers.html","text":"Handlers Python from optuna_hm import handlers optuna_hm.handlers.ecl Handlers for interfacing with and evaluating Eclipse (Schlumberger) Reservoir Simulation models. Eclipse is a proprietary simulation software which has a command line interface. Handler module for external file and process handling of ECLIPSE flow simulator - Schlumberger hand_ecl100 - Claus Aranha (caranha@cs.tsukuba.ac.jp) hand_ecldat - Tony Hallam ECL100Handler ( ECLBaseHandler ) This modules runs the ECLIPSE100 simulator in a \"sandbox\" directory, modifying the (prepared) parameter files with a set of test parameters. The results of the run are packaged for analysis by an optimizer. Source code in optuna_hm/handlers/_ecl_simh.py Python class ECL100Handler ( ECLBaseHandler ): \"\"\" This modules runs the ECLIPSE100 simulator in a \"sandbox\" directory, modifying the (prepared) parameter files with a set of test parameters. The results of the run are packaged for analysis by an optimizer. \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"ECL100Handler\" ) def __deepcopy__ ( self , memo ): # need to create a special copy function because the logger cannot be coppied # this means reinitialisation is necessary for each new simulator class args = [ self . __dict__ [ var ] for var in [ \"model_name\" , \"model_path\" , \"popt\" , \"simexe\" , \"time_out\" , \"silent\" , ] ] return ECL100Handler ( * args ) def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the ecl simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" modelfile = str ( self . model_name ) + \".DATA\" self . logger . info ( \"running model %s \" , os . path . join ( self . model_path , modelfile )) super () . launch ( self . model_name ) __init__ ( self , * args , ** kwargs ) special See ECLBaseHandler Notes: Source code in optuna_hm/handlers/_ecl_simh.py Python def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"ECL100Handler\" ) launch ( self , * cmdargs , ** cmdkwargs ) Launch the ecl simulator. Returns: Type Description bool True if run did not timeout. Source code in optuna_hm/handlers/_ecl_simh.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the ecl simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" modelfile = str ( self . model_name ) + \".DATA\" self . logger . info ( \"running model %s \" , os . path . join ( self . model_path , modelfile )) super () . launch ( self . model_name ) ECLBaseHandler Basic Class for interacting with ECLIPSE Simulation Program Source code in optuna_hm/handlers/_ecl_simh.py Python class ECLBaseHandler : \"\"\"Basic Class for interacting with ECLIPSE Simulation Program\"\"\" def __init__ ( self , model_name , model_path , model_param , application_path = None , rerun_license_errors = True , license_error_sleep = 600 , time_out = 900 , silent = True , original = True , ): \"\"\" Args: application_path (str): Path to simulation executable model_name (str): The name of the ECLIPSE Model model_path (str): The path to the ECLIPSE Model model_param (pandas.DataFrame): The model parameters to update the parameter key should be in the index of the DF. time_out (int): Defaults to 900 seconds. Time before cancelling subprocess simulation run. silent (bool): Defaults to True, set to False to print STDOUT from subprocess call. original (bool): Is this the original model. If true changes to the model will not be permitted. \"\"\" self . model_name = model_name self . model_path = model_path self . popt = model_param self . logger = logging . getLogger ( \"ECLBaseHandler\" ) self . temp_dir = None self . original = original self . log_path = None self . id = \"00000000\" self . rerun_le = rerun_license_errors self . sleep_le = license_error_sleep self . silent = silent if application_path is not None : self . set_ecl ( application_path ) else : self . simexe = None self . time_out = time_out def set_ecl ( self , application_path ): \"\"\"Set the simulator application path\"\"\" self . simexe = application_path if not pathlib . Path ( self . simexe ) . exists (): raise ValueError ( f \"Cannot find simulator executable { self . simexe } \" ) def __deepcopy__ ( self , memo ): # create a copy but not logger copy_list = [ \"model_name\" , \"model_path\" , \"popt\" , \"simexe\" , \"time_out\" , \"silent\" ] obj_copy = object . __new__ ( type ( self )) for item in copy_list : obj_copy . __dict__ [ item ] = copy . deepcopy ( self . __dict__ [ item ], memo ) return obj_copy def update_ecl_prop ( self , prop ): \"\"\"Creates appropriate property values from random floats in range 0-1 Args: prop (dict): list or random floats in range (0-1) supplied by population update \"\"\" # normalise prop random floats (0-1) to property ranges # this replaces unnormalise if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) self . popt [ \"new_values\" ] = self . popt [ \"NAME\" ] . map ( prop ) for file_name , val in self . popt . groupby ( \"FILE\" ): filepath = os . path . join ( self . model_path , file_name ) updatefile = ECLDatHandler ( filepath ) # change this to write actual update values updatefile . update ( val [[ \"NAME\" , \"new_values\" ]] . set_index ( \"NAME\" )) self . popt = self . popt . drop ( columns = \"new_values\" ) def retrieve_ecl_prop ( self ): \"\"\"Retrieve objective parameter values Returns: (list): list of parameters corresponding to flags \"\"\" values = dict () flags = self . popt . index . values flags = [ flg . upper () for flg in flags ] for file_name , _ in self . popt . groupby ( \"FILE\" ): filepath = self . model_path / file_name with open ( filepath , \"r\" ) as fdat : lines = fdat . readlines () for line in lines : for flag in flags : if flag in line : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) values [ flag ] = float ( split [ ind ]) return [ values [ file_name ] for file_name in flags ] def set_model_path ( self , newpath ): \"\"\"Set the path to the model\"\"\" self . model_path = newpath def set_save_sim_logs ( self , path ): \"\"\"Set location to save model logs. For Eclipse these are the DBG files created by the run. Args: path (str): The path to save the logs to. If directory doesn't exist it will be created. \"\"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () self . log_path = path logging . info ( \"Simulation logs will be saved to: %s \" , str ( path )) def save_model ( self , path , prefix = None ): \"\"\"Save the whole model folder to a new path. Args: path (pathlike) prefix (str, optional) \"\"\" new_folder_name = \"_\" . join if prefix is not None : new_folder_name = f \" { prefix } _ { self . model_name } \" else : new_folder_name = self . model_name save_path = pathlib . Path ( path ) / new_folder_name if not save_path . exists (): save_path . mkdir ( parents = True , exist_ok = True ) for item in self . model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , save_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( save_path / item . name )) logging . info ( f \"Saved model successfully to { str ( save_path ) } \" ) def save_model_outputs ( self , path , files , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: files (list): List of files to save. outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () for file in files : file = pathlib . Path ( file ) name = self . id + \"_\" + file . name shutil . copy2 ( self . model_path / file , path / name ) def set_save_model_outputs ( self , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" if outputs is None : shutil . copytree ( self . model_path , prefix + \"_\" + self . id ) def create_working_model ( self , working_dir = None , working_cwd = None ): \"\"\"Create a working copy of this simulator so it can be modified without destroying the original. Args: working_dir (str): If None, a temporary directory in the working_cwd will be created. Otherwise, specify a path to a preferred working directory. Defaults to None. working_cwd (str): If None, use the current working director. Otherwise will create temporary space in working_cwd. Defaults to None. This can be useful when using distributed processing and you want models to be evaluated on remote storage. Returns: (EclBaseHandler): A copy of simulator with a new working directory. \"\"\" # create working directory and simulator class working_simulator = copy . deepcopy ( self ) if working_cwd is None : working_cwd = os . getcwd () if working_dir is None : temp_dir = tempfile . TemporaryDirectory ( prefix = f \"tempECL_ { self . model_name } \" , dir = working_cwd ) # store temp dir with model so we don't lose it when exiting this namespace working_simulator . temp_dir = temp_dir working_dir = temp_dir . name working_simulator . id = temp_dir . name [ - 8 :] else : temp_dir = working_dir working_simulator . id = working_dir working_path = pathlib . Path ( working_dir ) logging . info ( \"working directory is %s \" , working_path ) working_simulator . set_model_path ( working_path ) # get the original model path model_path = pathlib . Path ( self . model_path ) model_path_size = sum ( f . stat () . st_size for f in model_path . iterdir () if f . is_file () ) # copy files into working directory - THIS could be updated to give more info logging . info ( \"Copying model directory to %s \" , working_path ) for item in model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , working_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( working_path / item . name )) logging . info ( \"Coppied model successfully\" ) working_simulator . original = False # working_simulator.id = temp_dir.name[-8:] working_simulator . log_path = copy . deepcopy ( self . log_path ) copied = False while not copied : working_path_size = sum ( f . stat () . st_size for f in working_path . iterdir () if f . is_file () ) if working_path_size == model_path_size : copied = True time . sleep ( 5 ) # print(working_path.name, working_path_size, model_path_size, copied) return working_simulator def _launch_internal_loop ( self , cmd ): process = subprocess . Popen ( cmd , cwd = self . model_path , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) count = 0 stdout = \"\" stderr = \"\" while True : proc_status = process . poll () if count > self . time_out : process . terminate () self . logger . warning ( \"Simulation Run stopped due to timeout\" ) return False , stdout , proc_status output = process . stdout . read () . decode () error = process . stderr . read () . decode () if self . log_path is not None : with open ( self . log_path / \"optuna-hm-stdout.txt\" , mode = \"a\" ) as f : f . write ( output ) with open ( self . log_path / \"optuna-hm-stderr.txt\" , mode = \"a\" ) as f : f . write ( error ) elif not self . silent : print ( output ) print ( error ) if output == \"\" and proc_status is not None : self . logger . info ( \"Model run finished with exit %s \" , proc_status ) return True , stdout , proc_status time . sleep ( 1 ) count = count + 1 def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launches an eclipse instance, run a simulation.\"\"\" if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) start_time = time . time () cmd = [ self . simexe ] for c in cmdargs : cmd . append ( c ) for cmdkw in cmdkwargs : cmd = cmd + [ f \"- { cmdkw } \" , str ( cmdkwargs [ cmdkw ])] print ( cmd ) while True : good_run , stdout , proc_status = self . _launch_internal_loop ( cmd ) if self . rerun_le : # there was a problem with the license server if \"LICENSE FAILURE\" in stdout : self . logger . warn ( \"License acquisition failure for eclipse.\" ) time . sleep ( self . sleep_le ) # if is int, count down number of valid times to retry if isinstance ( self . rerun_le , int ): self . rerun_le -= 1 # everything was ok else : break else : # don't check for license errors break # copy simulation terminal log and debug to save path if requested if self . log_path is not None : # copying debug file log = self . model_path / self . model_name log = log . with_suffix ( \".DBG\" ) if log . exists (): cp_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) cp_to = cp_to . with_suffix ( \".DBG\" ) shutil . copyfile ( log , cp_to ) self . logger . info ( \"Coppied simulation log file.\" ) else : self . logger . info ( \"Could not find log file.\" ) # writing out STDOUT write_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) write_to = write_to . with_suffix ( \".STDOUT\" ) with open ( write_to , \"w\" ) as stdout_log : stdout_log . write ( stdout ) self . logger . info ( \"Wrote simulation STDOUT\" ) # TODO - Save model ouputs if requested. end_time = time . time () - start_time if proc_status == 0 : self . logger . info ( \"simulation completed in %s seconds\" , str ( end_time )) return good_run def cleanup ( self , retries = 4 , sleep = 10 ): \"\"\"Cleanup the working directory correctly. Args: retries (int, optional): [description]. Defaults to 4. sleep (int, optional): [description]. Defaults to 10. \"\"\" if self . original : logging . info ( \"You cannot cleanup the original model.\" ) else : can_delete = False tries = 0 while not can_delete : time . sleep ( sleep ) tries = tries + 1 try : self . temp_dir . cleanup () can_delete = True except OSError : # can't delete just now if tries > retries : pass __init__ ( self , model_name , model_path , model_param , application_path = None , rerun_license_errors = True , license_error_sleep = 600 , time_out = 900 , silent = True , original = True ) special Parameters: Name Type Description Default application_path str Path to simulation executable None model_name str The name of the ECLIPSE Model required model_path str The path to the ECLIPSE Model required model_param pandas.DataFrame The model parameters to update the parameter key should be in the index of the DF. required time_out int Defaults to 900 seconds. Time before cancelling subprocess simulation run. 900 silent bool Defaults to True, set to False to print STDOUT from subprocess call. True original bool Is this the original model. If true changes to the model will not be permitted. True Source code in optuna_hm/handlers/_ecl_simh.py Python def __init__ ( self , model_name , model_path , model_param , application_path = None , rerun_license_errors = True , license_error_sleep = 600 , time_out = 900 , silent = True , original = True , ): \"\"\" Args: application_path (str): Path to simulation executable model_name (str): The name of the ECLIPSE Model model_path (str): The path to the ECLIPSE Model model_param (pandas.DataFrame): The model parameters to update the parameter key should be in the index of the DF. time_out (int): Defaults to 900 seconds. Time before cancelling subprocess simulation run. silent (bool): Defaults to True, set to False to print STDOUT from subprocess call. original (bool): Is this the original model. If true changes to the model will not be permitted. \"\"\" self . model_name = model_name self . model_path = model_path self . popt = model_param self . logger = logging . getLogger ( \"ECLBaseHandler\" ) self . temp_dir = None self . original = original self . log_path = None self . id = \"00000000\" self . rerun_le = rerun_license_errors self . sleep_le = license_error_sleep self . silent = silent if application_path is not None : self . set_ecl ( application_path ) else : self . simexe = None self . time_out = time_out cleanup ( self , retries = 4 , sleep = 10 ) Cleanup the working directory correctly. Parameters: Name Type Description Default retries int [description]. Defaults to 4. 4 sleep int [description]. Defaults to 10. 10 Source code in optuna_hm/handlers/_ecl_simh.py Python def cleanup ( self , retries = 4 , sleep = 10 ): \"\"\"Cleanup the working directory correctly. Args: retries (int, optional): [description]. Defaults to 4. sleep (int, optional): [description]. Defaults to 10. \"\"\" if self . original : logging . info ( \"You cannot cleanup the original model.\" ) else : can_delete = False tries = 0 while not can_delete : time . sleep ( sleep ) tries = tries + 1 try : self . temp_dir . cleanup () can_delete = True except OSError : # can't delete just now if tries > retries : pass create_working_model ( self , working_dir = None , working_cwd = None ) Create a working copy of this simulator so it can be modified without destroying the original. Parameters: Name Type Description Default working_dir str If None, a temporary directory in the working_cwd will be created. Otherwise, specify a path to a preferred working directory. Defaults to None. None working_cwd str If None, use the current working director. Otherwise will create temporary space in working_cwd. Defaults to None. This can be useful when using distributed processing and you want models to be evaluated on remote storage. None Returns: Type Description (EclBaseHandler) A copy of simulator with a new working directory. Source code in optuna_hm/handlers/_ecl_simh.py Python def create_working_model ( self , working_dir = None , working_cwd = None ): \"\"\"Create a working copy of this simulator so it can be modified without destroying the original. Args: working_dir (str): If None, a temporary directory in the working_cwd will be created. Otherwise, specify a path to a preferred working directory. Defaults to None. working_cwd (str): If None, use the current working director. Otherwise will create temporary space in working_cwd. Defaults to None. This can be useful when using distributed processing and you want models to be evaluated on remote storage. Returns: (EclBaseHandler): A copy of simulator with a new working directory. \"\"\" # create working directory and simulator class working_simulator = copy . deepcopy ( self ) if working_cwd is None : working_cwd = os . getcwd () if working_dir is None : temp_dir = tempfile . TemporaryDirectory ( prefix = f \"tempECL_ { self . model_name } \" , dir = working_cwd ) # store temp dir with model so we don't lose it when exiting this namespace working_simulator . temp_dir = temp_dir working_dir = temp_dir . name working_simulator . id = temp_dir . name [ - 8 :] else : temp_dir = working_dir working_simulator . id = working_dir working_path = pathlib . Path ( working_dir ) logging . info ( \"working directory is %s \" , working_path ) working_simulator . set_model_path ( working_path ) # get the original model path model_path = pathlib . Path ( self . model_path ) model_path_size = sum ( f . stat () . st_size for f in model_path . iterdir () if f . is_file () ) # copy files into working directory - THIS could be updated to give more info logging . info ( \"Copying model directory to %s \" , working_path ) for item in model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , working_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( working_path / item . name )) logging . info ( \"Coppied model successfully\" ) working_simulator . original = False # working_simulator.id = temp_dir.name[-8:] working_simulator . log_path = copy . deepcopy ( self . log_path ) copied = False while not copied : working_path_size = sum ( f . stat () . st_size for f in working_path . iterdir () if f . is_file () ) if working_path_size == model_path_size : copied = True time . sleep ( 5 ) # print(working_path.name, working_path_size, model_path_size, copied) return working_simulator launch ( self , * cmdargs , ** cmdkwargs ) Launches an eclipse instance, run a simulation. Source code in optuna_hm/handlers/_ecl_simh.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launches an eclipse instance, run a simulation.\"\"\" if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) start_time = time . time () cmd = [ self . simexe ] for c in cmdargs : cmd . append ( c ) for cmdkw in cmdkwargs : cmd = cmd + [ f \"- { cmdkw } \" , str ( cmdkwargs [ cmdkw ])] print ( cmd ) while True : good_run , stdout , proc_status = self . _launch_internal_loop ( cmd ) if self . rerun_le : # there was a problem with the license server if \"LICENSE FAILURE\" in stdout : self . logger . warn ( \"License acquisition failure for eclipse.\" ) time . sleep ( self . sleep_le ) # if is int, count down number of valid times to retry if isinstance ( self . rerun_le , int ): self . rerun_le -= 1 # everything was ok else : break else : # don't check for license errors break # copy simulation terminal log and debug to save path if requested if self . log_path is not None : # copying debug file log = self . model_path / self . model_name log = log . with_suffix ( \".DBG\" ) if log . exists (): cp_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) cp_to = cp_to . with_suffix ( \".DBG\" ) shutil . copyfile ( log , cp_to ) self . logger . info ( \"Coppied simulation log file.\" ) else : self . logger . info ( \"Could not find log file.\" ) # writing out STDOUT write_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) write_to = write_to . with_suffix ( \".STDOUT\" ) with open ( write_to , \"w\" ) as stdout_log : stdout_log . write ( stdout ) self . logger . info ( \"Wrote simulation STDOUT\" ) # TODO - Save model ouputs if requested. end_time = time . time () - start_time if proc_status == 0 : self . logger . info ( \"simulation completed in %s seconds\" , str ( end_time )) return good_run retrieve_ecl_prop ( self ) Retrieve objective parameter values Returns: Type Description (list) list of parameters corresponding to flags Source code in optuna_hm/handlers/_ecl_simh.py Python def retrieve_ecl_prop ( self ): \"\"\"Retrieve objective parameter values Returns: (list): list of parameters corresponding to flags \"\"\" values = dict () flags = self . popt . index . values flags = [ flg . upper () for flg in flags ] for file_name , _ in self . popt . groupby ( \"FILE\" ): filepath = self . model_path / file_name with open ( filepath , \"r\" ) as fdat : lines = fdat . readlines () for line in lines : for flag in flags : if flag in line : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) values [ flag ] = float ( split [ ind ]) return [ values [ file_name ] for file_name in flags ] save_model ( self , path , prefix = None ) Save the whole model folder to a new path. Source code in optuna_hm/handlers/_ecl_simh.py Python def save_model ( self , path , prefix = None ): \"\"\"Save the whole model folder to a new path. Args: path (pathlike) prefix (str, optional) \"\"\" new_folder_name = \"_\" . join if prefix is not None : new_folder_name = f \" { prefix } _ { self . model_name } \" else : new_folder_name = self . model_name save_path = pathlib . Path ( path ) / new_folder_name if not save_path . exists (): save_path . mkdir ( parents = True , exist_ok = True ) for item in self . model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , save_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( save_path / item . name )) logging . info ( f \"Saved model successfully to { str ( save_path ) } \" ) save_model_outputs ( self , path , files , outputs = None , prefix = None ) Specify model outputs to save for debugging or further review. Parameters: Name Type Description Default files list List of files to save. required outputs list List of files to save. None Source code in optuna_hm/handlers/_ecl_simh.py Python def save_model_outputs ( self , path , files , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: files (list): List of files to save. outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () for file in files : file = pathlib . Path ( file ) name = self . id + \"_\" + file . name shutil . copy2 ( self . model_path / file , path / name ) set_ecl ( self , application_path ) Set the simulator application path Source code in optuna_hm/handlers/_ecl_simh.py Python def set_ecl ( self , application_path ): \"\"\"Set the simulator application path\"\"\" self . simexe = application_path if not pathlib . Path ( self . simexe ) . exists (): raise ValueError ( f \"Cannot find simulator executable { self . simexe } \" ) set_model_path ( self , newpath ) Set the path to the model Source code in optuna_hm/handlers/_ecl_simh.py Python def set_model_path ( self , newpath ): \"\"\"Set the path to the model\"\"\" self . model_path = newpath set_save_model_outputs ( self , outputs = None , prefix = None ) Specify model outputs to save for debugging or further review. Parameters: Name Type Description Default outputs list List of files to save. None Source code in optuna_hm/handlers/_ecl_simh.py Python def set_save_model_outputs ( self , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" if outputs is None : shutil . copytree ( self . model_path , prefix + \"_\" + self . id ) set_save_sim_logs ( self , path ) Set location to save model logs. For Eclipse these are the DBG files created by the run. Parameters: Name Type Description Default path str The path to save the logs to. If directory doesn't exist it will be created. required Source code in optuna_hm/handlers/_ecl_simh.py Python def set_save_sim_logs ( self , path ): \"\"\"Set location to save model logs. For Eclipse these are the DBG files created by the run. Args: path (str): The path to save the logs to. If directory doesn't exist it will be created. \"\"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () self . log_path = path logging . info ( \"Simulation logs will be saved to: %s \" , str ( path )) update_ecl_prop ( self , prop ) Creates appropriate property values from random floats in range 0-1 Parameters: Name Type Description Default prop dict list or random floats in range (0-1) supplied by population update required Source code in optuna_hm/handlers/_ecl_simh.py Python def update_ecl_prop ( self , prop ): \"\"\"Creates appropriate property values from random floats in range 0-1 Args: prop (dict): list or random floats in range (0-1) supplied by population update \"\"\" # normalise prop random floats (0-1) to property ranges # this replaces unnormalise if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) self . popt [ \"new_values\" ] = self . popt [ \"NAME\" ] . map ( prop ) for file_name , val in self . popt . groupby ( \"FILE\" ): filepath = os . path . join ( self . model_path , file_name ) updatefile = ECLDatHandler ( filepath ) # change this to write actual update values updatefile . update ( val [[ \"NAME\" , \"new_values\" ]] . set_index ( \"NAME\" )) self . popt = self . popt . drop ( columns = \"new_values\" ) ECLDatHandler Class to update simulation properties based on a comment flag Source code in optuna_hm/handlers/_ecl_simh.py Python class ECLDatHandler : \"\"\" Class to update simulation properties based on a comment flag \"\"\" def __init__ ( self , filename ): \"\"\"\"\"\" logger = logging . getLogger ( __name__ ) try : fdat = open ( filename , \"r\" ) fdat . close () self . filename = filename except FileNotFoundError as err : logger . error ( \"No such ECL DAT file: %s \" , filename ) raise type ( err ) def update ( self , new_values ): \"\"\"Replace objective parameter values with *new_values* in a ECL .DAT file using pre-defined *flags* Args: flags (list): List of parameter flags for new_values new_values (list): List of values to replace where flags Example: ECL Data File contains EQUALS record like this: EQUALS PERMX -999 1 11 1 11 1 1 / PERMXL1 0 PERMXL2 2 The flag PERMXL1 follows the '/' terminator and fills an ECL control file comment. The integer imediately following the flag tells update which parameter on the line will replaced starting from 0. Here -999 will be replaced. Multiple flags can be used per line such as with PERMXL2 where the first 11 at position 2 will be replaced. If the last value before the '/' terminator is the targeted ensure that there is at least one space ' ' between it the '/' terminator. \"\"\" # check length of flgas and new values - should be the same # load entire file - it is difficult to edit in-place with open ( self . filename , \"r\" ) as fdat : lines = fdat . readlines () # perform edits for i , line in enumerate ( lines ): if line [: 2 ] == \"--\" : pass else : try : for flag in new_values . index : if re . search ( f \"\\s { flag } \\s\" , line ) is not None : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) split [ ind ] = \" {:.4E} \" . format ( new_values [ \"new_values\" ][ flag ]) line = \" \" . join ( split ) + \" \\n \" lines [ i ] = line except ValueError : print ( \"Error updating simulation file.\" ) print ( f \"Problem file: { self . filename } , Problem flag: { flag } \" ) print ( f \"Problem line: { line } \" ) raise SystemExit # write back file with open ( self . filename , \"w\" ) as fdat : fdat . writelines ( lines ) update ( self , new_values ) Replace objective parameter values with new_values in a ECL .DAT file using pre-defined flags Parameters: Name Type Description Default flags list List of parameter flags for new_values required new_values list List of values to replace where flags required Examples: ECL Data File contains EQUALS record like this: EQUALS PERMX -999 1 11 1 11 1 1 / PERMXL1 0 PERMXL2 2 The flag PERMXL1 follows the '/' terminator and fills an ECL control file comment. The integer imediately following the flag tells update which parameter on the line will replaced starting from 0. Here -999 will be replaced. Multiple flags can be used per line such as with PERMXL2 where the first 11 at position 2 will be replaced. If the last value before the '/' terminator is the targeted ensure that there is at least one space ' ' between it the '/' terminator. Source code in optuna_hm/handlers/_ecl_simh.py Python def update ( self , new_values ): \"\"\"Replace objective parameter values with *new_values* in a ECL .DAT file using pre-defined *flags* Args: flags (list): List of parameter flags for new_values new_values (list): List of values to replace where flags Example: ECL Data File contains EQUALS record like this: EQUALS PERMX -999 1 11 1 11 1 1 / PERMXL1 0 PERMXL2 2 The flag PERMXL1 follows the '/' terminator and fills an ECL control file comment. The integer imediately following the flag tells update which parameter on the line will replaced starting from 0. Here -999 will be replaced. Multiple flags can be used per line such as with PERMXL2 where the first 11 at position 2 will be replaced. If the last value before the '/' terminator is the targeted ensure that there is at least one space ' ' between it the '/' terminator. \"\"\" # check length of flgas and new values - should be the same # load entire file - it is difficult to edit in-place with open ( self . filename , \"r\" ) as fdat : lines = fdat . readlines () # perform edits for i , line in enumerate ( lines ): if line [: 2 ] == \"--\" : pass else : try : for flag in new_values . index : if re . search ( f \"\\s { flag } \\s\" , line ) is not None : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) split [ ind ] = \" {:.4E} \" . format ( new_values [ \"new_values\" ][ flag ]) line = \" \" . join ( split ) + \" \\n \" lines [ i ] = line except ValueError : print ( \"Error updating simulation file.\" ) print ( f \"Problem file: { self . filename } , Problem flag: { flag } \" ) print ( f \"Problem line: { line } \" ) raise SystemExit # write back file with open ( self . filename , \"w\" ) as fdat : fdat . writelines ( lines ) ECLFakeHandler ( ECLBaseHandler ) Create Fake RSM files to run tests without ECLIPSE Source code in optuna_hm/handlers/_ecl_simh.py Python class ECLFakeHandler ( ECLBaseHandler ): \"\"\"Create Fake RSM files to run tests without ECLIPSE\"\"\" def __init__ ( self , target , reference , * args ): \"\"\"Constructor Args: target (str): column name from handler.popt to reference (pandas.DataFrame): Dataframe containing RSM results of true solution. *args: Arguments for ECLBaseHandler \"\"\" super () . __init__ ( * args ) self . logger = logging . getLogger ( \"ECLFakeHandler\" ) self . target = target self . reference = reference def __deepcopy__ ( self , memo ): # create a copy but not logger return ECLFakeHandler ( copy . deepcopy ( self . target , memo ), copy . deepcopy ( self . reference , memo ), copy . deepcopy ( self . model_name , memo ), copy . deepcopy ( self . model_path , memo ), copy . deepcopy ( self . popt , memo ), ) def clean_results ( self , modelpath , model ): \"\"\"Remove previous results\"\"\" result_file = os . path . join ( modelpath , model , \".RSM\" ) if os . path . isfile ( result_file ): os . remove ( result_file ) self . logger . info ( \"cleaning previous results\" ) def write_rsm ( self , filepath , rsm_well ): \"\"\"Write out a fake RSM file Args: filepath (str): The filepath for the RSM File rsm_well (pandas.DataFrame): \"\"\" with open ( filepath , \"w\" ) as rsmf : rsmf . write ( \" \\n \" ) rsmf . write ( \" \\t SUMMARY OF RUN GENERATED BY ECLFakeHandler \\n \" ) header = [ \" \\t \" ] for col in rsm_well . columns : header += [ col , \" \\t\\t\\t \" ] header += [ \" \\n \" ] * 4 rsmf . write ( \"\" . join ( header )) ncol = len ( rsm_well . columns ) data_template = \" \\t \" + \" {:>8g} \\t\\t \" * ncol for _ , val in rsm_well . iterrows (): rsmf . write ( data_template . format ( * val ) + \" \\n \" ) def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the simulator\"\"\" param = numpy . r_ [ self . retrieve_ecl_prop ()] misfit = ( numpy . sum ( numpy . sqrt ( numpy . square ( param / self . popt [ self . target ] . values - 1 )) ) / param . size ) scalar = 1 + misfit rsm_well = pd . DataFrame () rsm_well [ \"TIME\" ] = self . reference [ \"TIME\" ] for col in self . reference . drop ( columns = \"TIME\" ) . columns : rsm_well [ col + \"H\" ] = self . reference [ col ] rsm_well [ col ] = self . reference [ col ] / scalar filepath = os . path . join ( self . model_path , self . model_name + \".RSM\" ) self . write_rsm ( filepath , rsm_well ) __init__ ( self , target , reference , * args ) special Constructor Parameters: Name Type Description Default target str column name from handler.popt to required reference pandas.DataFrame Dataframe containing RSM results of true solution. required *args Arguments for ECLBaseHandler () Source code in optuna_hm/handlers/_ecl_simh.py Python def __init__ ( self , target , reference , * args ): \"\"\"Constructor Args: target (str): column name from handler.popt to reference (pandas.DataFrame): Dataframe containing RSM results of true solution. *args: Arguments for ECLBaseHandler \"\"\" super () . __init__ ( * args ) self . logger = logging . getLogger ( \"ECLFakeHandler\" ) self . target = target self . reference = reference clean_results ( self , modelpath , model ) Remove previous results Source code in optuna_hm/handlers/_ecl_simh.py Python def clean_results ( self , modelpath , model ): \"\"\"Remove previous results\"\"\" result_file = os . path . join ( modelpath , model , \".RSM\" ) if os . path . isfile ( result_file ): os . remove ( result_file ) self . logger . info ( \"cleaning previous results\" ) launch ( self , * cmdargs , ** cmdkwargs ) Launch the simulator Source code in optuna_hm/handlers/_ecl_simh.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the simulator\"\"\" param = numpy . r_ [ self . retrieve_ecl_prop ()] misfit = ( numpy . sum ( numpy . sqrt ( numpy . square ( param / self . popt [ self . target ] . values - 1 )) ) / param . size ) scalar = 1 + misfit rsm_well = pd . DataFrame () rsm_well [ \"TIME\" ] = self . reference [ \"TIME\" ] for col in self . reference . drop ( columns = \"TIME\" ) . columns : rsm_well [ col + \"H\" ] = self . reference [ col ] rsm_well [ col ] = self . reference [ col ] / scalar filepath = os . path . join ( self . model_path , self . model_name + \".RSM\" ) self . write_rsm ( filepath , rsm_well ) write_rsm ( self , filepath , rsm_well ) Write out a fake RSM file Parameters: Name Type Description Default filepath str The filepath for the RSM File required rsm_well pandas.DataFrame required Source code in optuna_hm/handlers/_ecl_simh.py Python def write_rsm ( self , filepath , rsm_well ): \"\"\"Write out a fake RSM file Args: filepath (str): The filepath for the RSM File rsm_well (pandas.DataFrame): \"\"\" with open ( filepath , \"w\" ) as rsmf : rsmf . write ( \" \\n \" ) rsmf . write ( \" \\t SUMMARY OF RUN GENERATED BY ECLFakeHandler \\n \" ) header = [ \" \\t \" ] for col in rsm_well . columns : header += [ col , \" \\t\\t\\t \" ] header += [ \" \\n \" ] * 4 rsmf . write ( \"\" . join ( header )) ncol = len ( rsm_well . columns ) data_template = \" \\t \" + \" {:>8g} \\t\\t \" * ncol for _ , val in rsm_well . iterrows (): rsmf . write ( data_template . format ( * val ) + \" \\n \" ) A compilation of common evaluation functions used for eclipse optimisation projects. Author Tony Hallam 2020 Error ( Exception ) Base class for other exceptions Source code in optuna_hm/handlers/_ecl_eval.py Python class Error ( Exception ): \"\"\"Base class for other exceptions\"\"\" def __init__ ( self , message = None ): self . message = message logger . error ( message ) super () . __init__ () SimulationRunError ( Error ) Raised when the input value is too small Source code in optuna_hm/handlers/_ecl_eval.py Python class SimulationRunError ( Error ): \"\"\"Raised when the input value is too small\"\"\" pass evaluate_eclipse_model ( simulator , results_dir = None , save_model_run = False , save_summary_results = False , save_properties_results = False , save_model_files = None , sleep = 5 , working_cwd = None , run_sim = True , update_prop = True , summary_results_kwargs = None , properties_results_kwargs = None , ** kwargs ) Evaluate an eclipse model. Parameters: Name Type Description Default simulator mophim.eclipse.EclBaseHandler The initialised simulator class object which can be derived from EclBaseHandler required results_dir str, pathlib.Path A directory, the directory must exist. None Source code in optuna_hm/handlers/_ecl_eval.py Python def evaluate_eclipse_model ( simulator , results_dir = None , save_model_run = False , save_summary_results = False , save_properties_results = False , save_model_files = None , sleep = 5 , working_cwd = None , run_sim = True , update_prop = True , summary_results_kwargs = None , properties_results_kwargs = None , ** kwargs , ): \"\"\"Evaluate an eclipse model. Args: simulator (mophim.eclipse.EclBaseHandler): The initialised simulator class object which can be derived from EclBaseHandler results_dir (str, pathlib.Path): A directory, the directory must exist. \"\"\" if not isinstance ( simulator , ECLBaseHandler ): raise ValueError ( f \"simulator argument must be of class { type ( ECLBaseHandler ) } , got { type ( simulator ) } \" ) if results_dir is None : results_dir = pathlib . Path ( \".\" ) . absolute () else : results_dir = pathlib . Path ( results_dir ) . absolute () if not results_dir . is_dir (): raise ValueError ( f \"results_dir must be directory and exist { results_dir } \" ) results = kwargs [ \"results\" ] optimiser = results [ \"sampler\" ] evaluation = results [ \"trial_number\" ] # create working sim logger . info ( f \"Starting { optimiser } trial number { evaluation } \" ) working_simulator = simulator . create_working_model ( working_cwd = working_cwd ) time . sleep ( sleep ) if update_prop : working_simulator . update_ecl_prop ( results [ \"p\" ]) if run_sim : working_simulator . launch () # Wait for simulation finalisation and cleanup time . sleep ( sleep ) # Save model files if requested if save_model_files is not None : model_files_save_path = results_dir / \"model_files\" try : model_files_save_path . mkdir () except FileExistsError : pass working_simulator . save_model_outputs ( model_files_save_path , save_model_files ) model_path_name = ( pathlib . Path ( working_simulator . temp_dir . name ) / working_simulator . model_name ) # Save whole model run if save_model_run : working_simulator . save_model ( results_dir / \"ecl_models\" , prefix = f \" { int ( evaluation ) : 05d } \" ) # read in simulation summary data try : summary_results = { \"well\" : None , \"failed\" : False } if summary_results_kwargs is not None : summary_results = _get_ecl_sumspec_results ( model_path_name , ** summary_results_kwargs ) else : summary_results = _get_ecl_sumspec_results ( model_path_name ) except SimulationOutputError : # simulation failed. logger . warning ( \"Results file not found %s \" , str ( model_path_name )) summary_results = { \"failed\" : True , \"well\" : None , \"end_date\" : pd . to_datetime ( 0 )} except KeyError as err : # simulation failed. logger . warning ( \"Results keys missing from summary %s \" , err ) summary_results = { \"failed\" : True , \"well\" : None , \"end_date\" : pd . to_datetime ( 0 )} except SimulationRunError as err : # simulation raised errors - probably failed logger . warning ( \"Simulation run failed. %s \" , err ) summary_results = { \"failed\" : True , \"well\" : None , \"end_date\" : pd . to_datetime ( 0 )} if summary_results [ \"well\" ] is not None and save_summary_results : name = \" {} _ {:04d} _summary.hdf5\" . format ( optimiser , evaluation ) summary_results_path = results_dir / \"summary\" try : summary_results_path . mkdir () except FileExistsError : pass summary_results_path_name = summary_results_path / name summary_results [ \"well\" ] . to_hdf ( summary_results_path_name , \"name\" , mode = \"w\" , format = \"table\" ) del summary_results [ \"well\" ] summary_results [ \"well\" ] = str ( summary_results_path_name ) logger . info ( f \"Summary results hdf5 output { summary_results_path / name } \" ) # read in simulation property data try : eclsim = None if properties_results_kwargs is not None : eclsim = _get_ecl_properties_sub ( model_path_name , ** properties_results_kwargs ) # print(\"eclsim_ret\", eclsim) # except IOError as err: # logger.info(f\"Problems reading property results evaluation {evaluation}\") # print(err) # property_results = {\"eclsim\": eclsim, \"failed\": True} except ( IOError , OSError , SimulationOutputError ) as err : logger . warning ( f \"Problems reading property results evaluation { evaluation } \" ) property_results = { \"eclsim\" : eclsim , \"failed\" : True } except KeyError as err : logger . warning ( f \"Keys not found in results file evaluation { evaluation } \" ) property_results = { \"eclsim\" : eclsim , \"failed\" : True } else : property_results = { \"eclsim\" : eclsim , \"failed\" : False } if property_results [ \"eclsim\" ] is not None and save_properties_results : name = \" {} _ {:04d} _eclsim\" . format ( optimiser , evaluation ) property_results_path = results_dir / \"eclsim\" try : property_results_path . mkdir () except FileExistsError : pass eclsim_save_path_name = property_results_path / name property_results [ \"eclsim\" ] . save ( eclsim_save_path_name ) del property_results [ \"eclsim\" ] property_results [ \"eclsim\" ] = str ( eclsim_save_path_name ) logger . info ( f \"Summary results eclsim output { property_results_path / name } \" ) if summary_results [ \"failed\" ] is True or property_results [ \"failed\" ] is True : failed = True else : failed = False results . update ( summary_results ) results . update ( property_results ) results [ \"failed\" ] = failed results . update ({ \"model_id\" : working_simulator . id }) working_simulator . cleanup ( sleep = sleep ) logger . info ( f \"Eclipse run finished and data loaded, trial number { results [ 'trial_number' ] } \" ) return results evaluate_well_prod ( log_pairs , date_range = None , method = 'kge' , data_key = 'well' , null_fitness = None , ** kwargs ) Calculated the misfit between all log pairs using method and returns a results dictionary labelled by the first log in the pair. Parameters: Name Type Description Default log_pairs list[(, ), ] A list of length 2 tuples which match labels in the input dataframe passed by the mopphim_kwargs 'results' required date_range tuple(str, str Filter the dataframe based upon a date range. The index of the input dataframe will need to be of type datetime. If the str is empty e.g. \"\" then the filter will be open in that direction. E.g. ('2020-2-02', '') or ('2020-2-02'. '2020-4-04') None columns list List of DataFrame values to perform metric on. required Source code in optuna_hm/handlers/_ecl_eval.py Python def evaluate_well_prod ( log_pairs , date_range = None , method = \"kge\" , data_key = \"well\" , null_fitness = None , ** kwargs , ): \"\"\"Calculated the misfit between all log pairs using method and returns a results dictionary labelled by the first log in the pair. Args: log_pairs (list[(, ), ]): A list of length 2 tuples which match labels in the input dataframe passed by the mopphim_kwargs['results'][data_key] date_range (tuple(str, str)): Filter the dataframe based upon a date range. The index of the input dataframe will need to be of type datetime. If the str is empty e.g. \"\" then the filter will be open in that direction. E.g. ('2020-2-02', '') or ('2020-2-02'. '2020-4-04') columns (list): List of DataFrame values to perform metric on. \"\"\" # set output metrics to null_fitness metrics = { p1 : null_fitness for p1 , _ in log_pairs } if kwargs [ \"results\" ][ \"failed\" ] and kwargs [ \"results\" ][ \"well\" ] is None : return metrics results = kwargs [ \"results\" ] data_path_name = kwargs [ \"results\" ][ data_key ] data = pd . read_hdf ( data_path_name ) available_logs = data . columns output_metrics = dict () if data is None : logger . debug ( \"Missing well results from ECL run. Skipping well evaluation.\" ) return metrics # check log_pairs for log in np . array ( log_pairs ) . flatten (): if not log in available_logs : raise ValueError ( f \"log { log } was not in results\" ) clean_data = data . dropna () if date_range is not None : clean_data = clean_data [ date_range [ 0 ] : date_range [ 1 ]] if clean_data . shape [ 0 ] == 0 : logger . debug ( \"data is empty, check date_range/simulation\" ) return metrics # NOT SURE IF THIS IS STILL NEEDED # no_data = [c for c in plogs if clean_data[c[0]].sum() == 0] # plogs = [c for c in plogs if clean_data[c[0]].sum() > 0] # for c in no_data: # metrics[c[0]] = np.nan if method == \"kge\" : # kling-gupta efficieny for p1 , p2 in log_pairs : output_metrics [ p1 ] = 1 - kge ( clean_data [ p1 ] . values , clean_data [ p2 ] . values , maxfitness = null_fitness , # incase method fails ) # elif method == \"mse\": # scaler = StandardScaler() # data_norm = clean_data.copy() # data_norm.loc[:, :] = scaler.fit_transform(clean_data.values) # for col in plogs: # metrics[col[0]] = mean_squared_error( # data_norm[col[0]].values, data_norm[col[1]].values # ) else : raise ValueError ( f \"Unknown method { method } \" ) logger ( f \"Completed well evaluation, trial_number { results [ 'trial_number' ] } \" ) return output_metrics optuna_hm.handlers.flow Flow is an alternative open-source simulator to Eclipse. It uses similar files as input and output but has a slightly different call signature. This module modifies the Eclipse methods to suit flow where needed. Evaluation and metrics functions from Eclipse can be used with Flow. Handler module for external file and process handling of ECLIPSE flow simulator - Schlumberger hand_ecl100 - Claus Aranha (caranha@cs.tsukuba.ac.jp) hand_ecldat - Tony Hallam FlowHandler ( ECLBaseHandler ) modifies ECLBaseHandler to deal with flow. Source code in optuna_hm/handlers/flow.py Python class FlowHandler ( ECLBaseHandler ): \"\"\" modifies ECLBaseHandler to deal with flow. \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"FlowHandler\" ) def __deepcopy__ ( self , memo ): # need to create a special copy function because the logger cannot be coppied # this means reinitialisation is necessary for each new simulator class args = [ self . __dict__ [ var ] for var in [ \"model_name\" , \"model_path\" , \"popt\" , \"simexe\" , \"time_out\" , \"silent\" , ] ] return FlowHandler ( * args ) def clean_results (): # FIXME: delete results file from self.model_path # beginning with self.model_name pass def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the flow simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" model_arg = \"--parameter-file=\" + str ( self . model_name ) + \".PARAM\" self . logger . info ( \"running model at %s \" , self . model_path ) return super () . launch ( model_arg ) __init__ ( self , * args , ** kwargs ) special See ECLBaseHandler Notes: Source code in optuna_hm/handlers/flow.py Python def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"FlowHandler\" ) launch ( self , * cmdargs , ** cmdkwargs ) Launch the flow simulator. Returns: Type Description bool True if run did not timeout. Source code in optuna_hm/handlers/flow.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the flow simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" model_arg = \"--parameter-file=\" + str ( self . model_name ) + \".PARAM\" self . logger . info ( \"running model at %s \" , self . model_path ) return super () . launch ( model_arg )","title":"Handlers"},{"location":"ophm/api_handlers.html#handlers","text":"Python from optuna_hm import handlers","title":"Handlers"},{"location":"ophm/api_handlers.html#optuna_hmhandlersecl","text":"Handlers for interfacing with and evaluating Eclipse (Schlumberger) Reservoir Simulation models. Eclipse is a proprietary simulation software which has a command line interface. Handler module for external file and process handling of ECLIPSE flow simulator - Schlumberger hand_ecl100 - Claus Aranha (caranha@cs.tsukuba.ac.jp) hand_ecldat - Tony Hallam","title":"optuna_hm.handlers.ecl"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECL100Handler","text":"This modules runs the ECLIPSE100 simulator in a \"sandbox\" directory, modifying the (prepared) parameter files with a set of test parameters. The results of the run are packaged for analysis by an optimizer. Source code in optuna_hm/handlers/_ecl_simh.py Python class ECL100Handler ( ECLBaseHandler ): \"\"\" This modules runs the ECLIPSE100 simulator in a \"sandbox\" directory, modifying the (prepared) parameter files with a set of test parameters. The results of the run are packaged for analysis by an optimizer. \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"ECL100Handler\" ) def __deepcopy__ ( self , memo ): # need to create a special copy function because the logger cannot be coppied # this means reinitialisation is necessary for each new simulator class args = [ self . __dict__ [ var ] for var in [ \"model_name\" , \"model_path\" , \"popt\" , \"simexe\" , \"time_out\" , \"silent\" , ] ] return ECL100Handler ( * args ) def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the ecl simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" modelfile = str ( self . model_name ) + \".DATA\" self . logger . info ( \"running model %s \" , os . path . join ( self . model_path , modelfile )) super () . launch ( self . model_name )","title":"ECL100Handler"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECL100Handler.__init__","text":"See ECLBaseHandler Notes: Source code in optuna_hm/handlers/_ecl_simh.py Python def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"ECL100Handler\" )","title":"__init__()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECL100Handler.launch","text":"Launch the ecl simulator. Returns: Type Description bool True if run did not timeout. Source code in optuna_hm/handlers/_ecl_simh.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the ecl simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" modelfile = str ( self . model_name ) + \".DATA\" self . logger . info ( \"running model %s \" , os . path . join ( self . model_path , modelfile )) super () . launch ( self . model_name )","title":"launch()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler","text":"Basic Class for interacting with ECLIPSE Simulation Program Source code in optuna_hm/handlers/_ecl_simh.py Python class ECLBaseHandler : \"\"\"Basic Class for interacting with ECLIPSE Simulation Program\"\"\" def __init__ ( self , model_name , model_path , model_param , application_path = None , rerun_license_errors = True , license_error_sleep = 600 , time_out = 900 , silent = True , original = True , ): \"\"\" Args: application_path (str): Path to simulation executable model_name (str): The name of the ECLIPSE Model model_path (str): The path to the ECLIPSE Model model_param (pandas.DataFrame): The model parameters to update the parameter key should be in the index of the DF. time_out (int): Defaults to 900 seconds. Time before cancelling subprocess simulation run. silent (bool): Defaults to True, set to False to print STDOUT from subprocess call. original (bool): Is this the original model. If true changes to the model will not be permitted. \"\"\" self . model_name = model_name self . model_path = model_path self . popt = model_param self . logger = logging . getLogger ( \"ECLBaseHandler\" ) self . temp_dir = None self . original = original self . log_path = None self . id = \"00000000\" self . rerun_le = rerun_license_errors self . sleep_le = license_error_sleep self . silent = silent if application_path is not None : self . set_ecl ( application_path ) else : self . simexe = None self . time_out = time_out def set_ecl ( self , application_path ): \"\"\"Set the simulator application path\"\"\" self . simexe = application_path if not pathlib . Path ( self . simexe ) . exists (): raise ValueError ( f \"Cannot find simulator executable { self . simexe } \" ) def __deepcopy__ ( self , memo ): # create a copy but not logger copy_list = [ \"model_name\" , \"model_path\" , \"popt\" , \"simexe\" , \"time_out\" , \"silent\" ] obj_copy = object . __new__ ( type ( self )) for item in copy_list : obj_copy . __dict__ [ item ] = copy . deepcopy ( self . __dict__ [ item ], memo ) return obj_copy def update_ecl_prop ( self , prop ): \"\"\"Creates appropriate property values from random floats in range 0-1 Args: prop (dict): list or random floats in range (0-1) supplied by population update \"\"\" # normalise prop random floats (0-1) to property ranges # this replaces unnormalise if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) self . popt [ \"new_values\" ] = self . popt [ \"NAME\" ] . map ( prop ) for file_name , val in self . popt . groupby ( \"FILE\" ): filepath = os . path . join ( self . model_path , file_name ) updatefile = ECLDatHandler ( filepath ) # change this to write actual update values updatefile . update ( val [[ \"NAME\" , \"new_values\" ]] . set_index ( \"NAME\" )) self . popt = self . popt . drop ( columns = \"new_values\" ) def retrieve_ecl_prop ( self ): \"\"\"Retrieve objective parameter values Returns: (list): list of parameters corresponding to flags \"\"\" values = dict () flags = self . popt . index . values flags = [ flg . upper () for flg in flags ] for file_name , _ in self . popt . groupby ( \"FILE\" ): filepath = self . model_path / file_name with open ( filepath , \"r\" ) as fdat : lines = fdat . readlines () for line in lines : for flag in flags : if flag in line : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) values [ flag ] = float ( split [ ind ]) return [ values [ file_name ] for file_name in flags ] def set_model_path ( self , newpath ): \"\"\"Set the path to the model\"\"\" self . model_path = newpath def set_save_sim_logs ( self , path ): \"\"\"Set location to save model logs. For Eclipse these are the DBG files created by the run. Args: path (str): The path to save the logs to. If directory doesn't exist it will be created. \"\"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () self . log_path = path logging . info ( \"Simulation logs will be saved to: %s \" , str ( path )) def save_model ( self , path , prefix = None ): \"\"\"Save the whole model folder to a new path. Args: path (pathlike) prefix (str, optional) \"\"\" new_folder_name = \"_\" . join if prefix is not None : new_folder_name = f \" { prefix } _ { self . model_name } \" else : new_folder_name = self . model_name save_path = pathlib . Path ( path ) / new_folder_name if not save_path . exists (): save_path . mkdir ( parents = True , exist_ok = True ) for item in self . model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , save_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( save_path / item . name )) logging . info ( f \"Saved model successfully to { str ( save_path ) } \" ) def save_model_outputs ( self , path , files , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: files (list): List of files to save. outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () for file in files : file = pathlib . Path ( file ) name = self . id + \"_\" + file . name shutil . copy2 ( self . model_path / file , path / name ) def set_save_model_outputs ( self , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" if outputs is None : shutil . copytree ( self . model_path , prefix + \"_\" + self . id ) def create_working_model ( self , working_dir = None , working_cwd = None ): \"\"\"Create a working copy of this simulator so it can be modified without destroying the original. Args: working_dir (str): If None, a temporary directory in the working_cwd will be created. Otherwise, specify a path to a preferred working directory. Defaults to None. working_cwd (str): If None, use the current working director. Otherwise will create temporary space in working_cwd. Defaults to None. This can be useful when using distributed processing and you want models to be evaluated on remote storage. Returns: (EclBaseHandler): A copy of simulator with a new working directory. \"\"\" # create working directory and simulator class working_simulator = copy . deepcopy ( self ) if working_cwd is None : working_cwd = os . getcwd () if working_dir is None : temp_dir = tempfile . TemporaryDirectory ( prefix = f \"tempECL_ { self . model_name } \" , dir = working_cwd ) # store temp dir with model so we don't lose it when exiting this namespace working_simulator . temp_dir = temp_dir working_dir = temp_dir . name working_simulator . id = temp_dir . name [ - 8 :] else : temp_dir = working_dir working_simulator . id = working_dir working_path = pathlib . Path ( working_dir ) logging . info ( \"working directory is %s \" , working_path ) working_simulator . set_model_path ( working_path ) # get the original model path model_path = pathlib . Path ( self . model_path ) model_path_size = sum ( f . stat () . st_size for f in model_path . iterdir () if f . is_file () ) # copy files into working directory - THIS could be updated to give more info logging . info ( \"Copying model directory to %s \" , working_path ) for item in model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , working_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( working_path / item . name )) logging . info ( \"Coppied model successfully\" ) working_simulator . original = False # working_simulator.id = temp_dir.name[-8:] working_simulator . log_path = copy . deepcopy ( self . log_path ) copied = False while not copied : working_path_size = sum ( f . stat () . st_size for f in working_path . iterdir () if f . is_file () ) if working_path_size == model_path_size : copied = True time . sleep ( 5 ) # print(working_path.name, working_path_size, model_path_size, copied) return working_simulator def _launch_internal_loop ( self , cmd ): process = subprocess . Popen ( cmd , cwd = self . model_path , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) count = 0 stdout = \"\" stderr = \"\" while True : proc_status = process . poll () if count > self . time_out : process . terminate () self . logger . warning ( \"Simulation Run stopped due to timeout\" ) return False , stdout , proc_status output = process . stdout . read () . decode () error = process . stderr . read () . decode () if self . log_path is not None : with open ( self . log_path / \"optuna-hm-stdout.txt\" , mode = \"a\" ) as f : f . write ( output ) with open ( self . log_path / \"optuna-hm-stderr.txt\" , mode = \"a\" ) as f : f . write ( error ) elif not self . silent : print ( output ) print ( error ) if output == \"\" and proc_status is not None : self . logger . info ( \"Model run finished with exit %s \" , proc_status ) return True , stdout , proc_status time . sleep ( 1 ) count = count + 1 def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launches an eclipse instance, run a simulation.\"\"\" if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) start_time = time . time () cmd = [ self . simexe ] for c in cmdargs : cmd . append ( c ) for cmdkw in cmdkwargs : cmd = cmd + [ f \"- { cmdkw } \" , str ( cmdkwargs [ cmdkw ])] print ( cmd ) while True : good_run , stdout , proc_status = self . _launch_internal_loop ( cmd ) if self . rerun_le : # there was a problem with the license server if \"LICENSE FAILURE\" in stdout : self . logger . warn ( \"License acquisition failure for eclipse.\" ) time . sleep ( self . sleep_le ) # if is int, count down number of valid times to retry if isinstance ( self . rerun_le , int ): self . rerun_le -= 1 # everything was ok else : break else : # don't check for license errors break # copy simulation terminal log and debug to save path if requested if self . log_path is not None : # copying debug file log = self . model_path / self . model_name log = log . with_suffix ( \".DBG\" ) if log . exists (): cp_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) cp_to = cp_to . with_suffix ( \".DBG\" ) shutil . copyfile ( log , cp_to ) self . logger . info ( \"Coppied simulation log file.\" ) else : self . logger . info ( \"Could not find log file.\" ) # writing out STDOUT write_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) write_to = write_to . with_suffix ( \".STDOUT\" ) with open ( write_to , \"w\" ) as stdout_log : stdout_log . write ( stdout ) self . logger . info ( \"Wrote simulation STDOUT\" ) # TODO - Save model ouputs if requested. end_time = time . time () - start_time if proc_status == 0 : self . logger . info ( \"simulation completed in %s seconds\" , str ( end_time )) return good_run def cleanup ( self , retries = 4 , sleep = 10 ): \"\"\"Cleanup the working directory correctly. Args: retries (int, optional): [description]. Defaults to 4. sleep (int, optional): [description]. Defaults to 10. \"\"\" if self . original : logging . info ( \"You cannot cleanup the original model.\" ) else : can_delete = False tries = 0 while not can_delete : time . sleep ( sleep ) tries = tries + 1 try : self . temp_dir . cleanup () can_delete = True except OSError : # can't delete just now if tries > retries : pass","title":"ECLBaseHandler"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.__init__","text":"Parameters: Name Type Description Default application_path str Path to simulation executable None model_name str The name of the ECLIPSE Model required model_path str The path to the ECLIPSE Model required model_param pandas.DataFrame The model parameters to update the parameter key should be in the index of the DF. required time_out int Defaults to 900 seconds. Time before cancelling subprocess simulation run. 900 silent bool Defaults to True, set to False to print STDOUT from subprocess call. True original bool Is this the original model. If true changes to the model will not be permitted. True Source code in optuna_hm/handlers/_ecl_simh.py Python def __init__ ( self , model_name , model_path , model_param , application_path = None , rerun_license_errors = True , license_error_sleep = 600 , time_out = 900 , silent = True , original = True , ): \"\"\" Args: application_path (str): Path to simulation executable model_name (str): The name of the ECLIPSE Model model_path (str): The path to the ECLIPSE Model model_param (pandas.DataFrame): The model parameters to update the parameter key should be in the index of the DF. time_out (int): Defaults to 900 seconds. Time before cancelling subprocess simulation run. silent (bool): Defaults to True, set to False to print STDOUT from subprocess call. original (bool): Is this the original model. If true changes to the model will not be permitted. \"\"\" self . model_name = model_name self . model_path = model_path self . popt = model_param self . logger = logging . getLogger ( \"ECLBaseHandler\" ) self . temp_dir = None self . original = original self . log_path = None self . id = \"00000000\" self . rerun_le = rerun_license_errors self . sleep_le = license_error_sleep self . silent = silent if application_path is not None : self . set_ecl ( application_path ) else : self . simexe = None self . time_out = time_out","title":"__init__()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.cleanup","text":"Cleanup the working directory correctly. Parameters: Name Type Description Default retries int [description]. Defaults to 4. 4 sleep int [description]. Defaults to 10. 10 Source code in optuna_hm/handlers/_ecl_simh.py Python def cleanup ( self , retries = 4 , sleep = 10 ): \"\"\"Cleanup the working directory correctly. Args: retries (int, optional): [description]. Defaults to 4. sleep (int, optional): [description]. Defaults to 10. \"\"\" if self . original : logging . info ( \"You cannot cleanup the original model.\" ) else : can_delete = False tries = 0 while not can_delete : time . sleep ( sleep ) tries = tries + 1 try : self . temp_dir . cleanup () can_delete = True except OSError : # can't delete just now if tries > retries : pass","title":"cleanup()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.create_working_model","text":"Create a working copy of this simulator so it can be modified without destroying the original. Parameters: Name Type Description Default working_dir str If None, a temporary directory in the working_cwd will be created. Otherwise, specify a path to a preferred working directory. Defaults to None. None working_cwd str If None, use the current working director. Otherwise will create temporary space in working_cwd. Defaults to None. This can be useful when using distributed processing and you want models to be evaluated on remote storage. None Returns: Type Description (EclBaseHandler) A copy of simulator with a new working directory. Source code in optuna_hm/handlers/_ecl_simh.py Python def create_working_model ( self , working_dir = None , working_cwd = None ): \"\"\"Create a working copy of this simulator so it can be modified without destroying the original. Args: working_dir (str): If None, a temporary directory in the working_cwd will be created. Otherwise, specify a path to a preferred working directory. Defaults to None. working_cwd (str): If None, use the current working director. Otherwise will create temporary space in working_cwd. Defaults to None. This can be useful when using distributed processing and you want models to be evaluated on remote storage. Returns: (EclBaseHandler): A copy of simulator with a new working directory. \"\"\" # create working directory and simulator class working_simulator = copy . deepcopy ( self ) if working_cwd is None : working_cwd = os . getcwd () if working_dir is None : temp_dir = tempfile . TemporaryDirectory ( prefix = f \"tempECL_ { self . model_name } \" , dir = working_cwd ) # store temp dir with model so we don't lose it when exiting this namespace working_simulator . temp_dir = temp_dir working_dir = temp_dir . name working_simulator . id = temp_dir . name [ - 8 :] else : temp_dir = working_dir working_simulator . id = working_dir working_path = pathlib . Path ( working_dir ) logging . info ( \"working directory is %s \" , working_path ) working_simulator . set_model_path ( working_path ) # get the original model path model_path = pathlib . Path ( self . model_path ) model_path_size = sum ( f . stat () . st_size for f in model_path . iterdir () if f . is_file () ) # copy files into working directory - THIS could be updated to give more info logging . info ( \"Copying model directory to %s \" , working_path ) for item in model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , working_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( working_path / item . name )) logging . info ( \"Coppied model successfully\" ) working_simulator . original = False # working_simulator.id = temp_dir.name[-8:] working_simulator . log_path = copy . deepcopy ( self . log_path ) copied = False while not copied : working_path_size = sum ( f . stat () . st_size for f in working_path . iterdir () if f . is_file () ) if working_path_size == model_path_size : copied = True time . sleep ( 5 ) # print(working_path.name, working_path_size, model_path_size, copied) return working_simulator","title":"create_working_model()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.launch","text":"Launches an eclipse instance, run a simulation. Source code in optuna_hm/handlers/_ecl_simh.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launches an eclipse instance, run a simulation.\"\"\" if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) start_time = time . time () cmd = [ self . simexe ] for c in cmdargs : cmd . append ( c ) for cmdkw in cmdkwargs : cmd = cmd + [ f \"- { cmdkw } \" , str ( cmdkwargs [ cmdkw ])] print ( cmd ) while True : good_run , stdout , proc_status = self . _launch_internal_loop ( cmd ) if self . rerun_le : # there was a problem with the license server if \"LICENSE FAILURE\" in stdout : self . logger . warn ( \"License acquisition failure for eclipse.\" ) time . sleep ( self . sleep_le ) # if is int, count down number of valid times to retry if isinstance ( self . rerun_le , int ): self . rerun_le -= 1 # everything was ok else : break else : # don't check for license errors break # copy simulation terminal log and debug to save path if requested if self . log_path is not None : # copying debug file log = self . model_path / self . model_name log = log . with_suffix ( \".DBG\" ) if log . exists (): cp_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) cp_to = cp_to . with_suffix ( \".DBG\" ) shutil . copyfile ( log , cp_to ) self . logger . info ( \"Coppied simulation log file.\" ) else : self . logger . info ( \"Could not find log file.\" ) # writing out STDOUT write_to = self . log_path / \"_\" . join ([ log . stem , self . id ]) write_to = write_to . with_suffix ( \".STDOUT\" ) with open ( write_to , \"w\" ) as stdout_log : stdout_log . write ( stdout ) self . logger . info ( \"Wrote simulation STDOUT\" ) # TODO - Save model ouputs if requested. end_time = time . time () - start_time if proc_status == 0 : self . logger . info ( \"simulation completed in %s seconds\" , str ( end_time )) return good_run","title":"launch()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.retrieve_ecl_prop","text":"Retrieve objective parameter values Returns: Type Description (list) list of parameters corresponding to flags Source code in optuna_hm/handlers/_ecl_simh.py Python def retrieve_ecl_prop ( self ): \"\"\"Retrieve objective parameter values Returns: (list): list of parameters corresponding to flags \"\"\" values = dict () flags = self . popt . index . values flags = [ flg . upper () for flg in flags ] for file_name , _ in self . popt . groupby ( \"FILE\" ): filepath = self . model_path / file_name with open ( filepath , \"r\" ) as fdat : lines = fdat . readlines () for line in lines : for flag in flags : if flag in line : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) values [ flag ] = float ( split [ ind ]) return [ values [ file_name ] for file_name in flags ]","title":"retrieve_ecl_prop()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.save_model","text":"Save the whole model folder to a new path. Source code in optuna_hm/handlers/_ecl_simh.py Python def save_model ( self , path , prefix = None ): \"\"\"Save the whole model folder to a new path. Args: path (pathlike) prefix (str, optional) \"\"\" new_folder_name = \"_\" . join if prefix is not None : new_folder_name = f \" { prefix } _ { self . model_name } \" else : new_folder_name = self . model_name save_path = pathlib . Path ( path ) / new_folder_name if not save_path . exists (): save_path . mkdir ( parents = True , exist_ok = True ) for item in self . model_path . iterdir (): if item . is_file (): shutil . copy2 ( item , save_path ) elif item . is_dir (): from distutils.dir_util import copy_tree copy_tree ( str ( item ), str ( save_path / item . name )) logging . info ( f \"Saved model successfully to { str ( save_path ) } \" )","title":"save_model()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.save_model_outputs","text":"Specify model outputs to save for debugging or further review. Parameters: Name Type Description Default files list List of files to save. required outputs list List of files to save. None Source code in optuna_hm/handlers/_ecl_simh.py Python def save_model_outputs ( self , path , files , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: files (list): List of files to save. outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () for file in files : file = pathlib . Path ( file ) name = self . id + \"_\" + file . name shutil . copy2 ( self . model_path / file , path / name )","title":"save_model_outputs()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.set_ecl","text":"Set the simulator application path Source code in optuna_hm/handlers/_ecl_simh.py Python def set_ecl ( self , application_path ): \"\"\"Set the simulator application path\"\"\" self . simexe = application_path if not pathlib . Path ( self . simexe ) . exists (): raise ValueError ( f \"Cannot find simulator executable { self . simexe } \" )","title":"set_ecl()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.set_model_path","text":"Set the path to the model Source code in optuna_hm/handlers/_ecl_simh.py Python def set_model_path ( self , newpath ): \"\"\"Set the path to the model\"\"\" self . model_path = newpath","title":"set_model_path()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.set_save_model_outputs","text":"Specify model outputs to save for debugging or further review. Parameters: Name Type Description Default outputs list List of files to save. None Source code in optuna_hm/handlers/_ecl_simh.py Python def set_save_model_outputs ( self , outputs = None , prefix = None ): \"\"\"Specify model outputs to save for debugging or further review. Args: outputs (list): List of files to save. \"\"\" if prefix is None : prefix = \"\" if outputs is None : shutil . copytree ( self . model_path , prefix + \"_\" + self . id )","title":"set_save_model_outputs()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.set_save_sim_logs","text":"Set location to save model logs. For Eclipse these are the DBG files created by the run. Parameters: Name Type Description Default path str The path to save the logs to. If directory doesn't exist it will be created. required Source code in optuna_hm/handlers/_ecl_simh.py Python def set_save_sim_logs ( self , path ): \"\"\"Set location to save model logs. For Eclipse these are the DBG files created by the run. Args: path (str): The path to save the logs to. If directory doesn't exist it will be created. \"\"\" path = pathlib . Path ( path ) if not path . exists (): path . mkdir () self . log_path = path logging . info ( \"Simulation logs will be saved to: %s \" , str ( path ))","title":"set_save_sim_logs()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLBaseHandler.update_ecl_prop","text":"Creates appropriate property values from random floats in range 0-1 Parameters: Name Type Description Default prop dict list or random floats in range (0-1) supplied by population update required Source code in optuna_hm/handlers/_ecl_simh.py Python def update_ecl_prop ( self , prop ): \"\"\"Creates appropriate property values from random floats in range 0-1 Args: prop (dict): list or random floats in range (0-1) supplied by population update \"\"\" # normalise prop random floats (0-1) to property ranges # this replaces unnormalise if self . original : raise PermissionError ( \"You must create a working copy of the model using\" + \" create_working_model, changes to the original model are not permitted.\" ) self . popt [ \"new_values\" ] = self . popt [ \"NAME\" ] . map ( prop ) for file_name , val in self . popt . groupby ( \"FILE\" ): filepath = os . path . join ( self . model_path , file_name ) updatefile = ECLDatHandler ( filepath ) # change this to write actual update values updatefile . update ( val [[ \"NAME\" , \"new_values\" ]] . set_index ( \"NAME\" )) self . popt = self . popt . drop ( columns = \"new_values\" )","title":"update_ecl_prop()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLDatHandler","text":"Class to update simulation properties based on a comment flag Source code in optuna_hm/handlers/_ecl_simh.py Python class ECLDatHandler : \"\"\" Class to update simulation properties based on a comment flag \"\"\" def __init__ ( self , filename ): \"\"\"\"\"\" logger = logging . getLogger ( __name__ ) try : fdat = open ( filename , \"r\" ) fdat . close () self . filename = filename except FileNotFoundError as err : logger . error ( \"No such ECL DAT file: %s \" , filename ) raise type ( err ) def update ( self , new_values ): \"\"\"Replace objective parameter values with *new_values* in a ECL .DAT file using pre-defined *flags* Args: flags (list): List of parameter flags for new_values new_values (list): List of values to replace where flags Example: ECL Data File contains EQUALS record like this: EQUALS PERMX -999 1 11 1 11 1 1 / PERMXL1 0 PERMXL2 2 The flag PERMXL1 follows the '/' terminator and fills an ECL control file comment. The integer imediately following the flag tells update which parameter on the line will replaced starting from 0. Here -999 will be replaced. Multiple flags can be used per line such as with PERMXL2 where the first 11 at position 2 will be replaced. If the last value before the '/' terminator is the targeted ensure that there is at least one space ' ' between it the '/' terminator. \"\"\" # check length of flgas and new values - should be the same # load entire file - it is difficult to edit in-place with open ( self . filename , \"r\" ) as fdat : lines = fdat . readlines () # perform edits for i , line in enumerate ( lines ): if line [: 2 ] == \"--\" : pass else : try : for flag in new_values . index : if re . search ( f \"\\s { flag } \\s\" , line ) is not None : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) split [ ind ] = \" {:.4E} \" . format ( new_values [ \"new_values\" ][ flag ]) line = \" \" . join ( split ) + \" \\n \" lines [ i ] = line except ValueError : print ( \"Error updating simulation file.\" ) print ( f \"Problem file: { self . filename } , Problem flag: { flag } \" ) print ( f \"Problem line: { line } \" ) raise SystemExit # write back file with open ( self . filename , \"w\" ) as fdat : fdat . writelines ( lines )","title":"ECLDatHandler"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLDatHandler.update","text":"Replace objective parameter values with new_values in a ECL .DAT file using pre-defined flags Parameters: Name Type Description Default flags list List of parameter flags for new_values required new_values list List of values to replace where flags required Examples: ECL Data File contains EQUALS record like this: EQUALS PERMX -999 1 11 1 11 1 1 / PERMXL1 0 PERMXL2 2 The flag PERMXL1 follows the '/' terminator and fills an ECL control file comment. The integer imediately following the flag tells update which parameter on the line will replaced starting from 0. Here -999 will be replaced. Multiple flags can be used per line such as with PERMXL2 where the first 11 at position 2 will be replaced. If the last value before the '/' terminator is the targeted ensure that there is at least one space ' ' between it the '/' terminator. Source code in optuna_hm/handlers/_ecl_simh.py Python def update ( self , new_values ): \"\"\"Replace objective parameter values with *new_values* in a ECL .DAT file using pre-defined *flags* Args: flags (list): List of parameter flags for new_values new_values (list): List of values to replace where flags Example: ECL Data File contains EQUALS record like this: EQUALS PERMX -999 1 11 1 11 1 1 / PERMXL1 0 PERMXL2 2 The flag PERMXL1 follows the '/' terminator and fills an ECL control file comment. The integer imediately following the flag tells update which parameter on the line will replaced starting from 0. Here -999 will be replaced. Multiple flags can be used per line such as with PERMXL2 where the first 11 at position 2 will be replaced. If the last value before the '/' terminator is the targeted ensure that there is at least one space ' ' between it the '/' terminator. \"\"\" # check length of flgas and new values - should be the same # load entire file - it is difficult to edit in-place with open ( self . filename , \"r\" ) as fdat : lines = fdat . readlines () # perform edits for i , line in enumerate ( lines ): if line [: 2 ] == \"--\" : pass else : try : for flag in new_values . index : if re . search ( f \"\\s { flag } \\s\" , line ) is not None : split = line . strip () . split () find = split . index ( flag ) ind = int ( split [ find + 1 ]) split [ ind ] = \" {:.4E} \" . format ( new_values [ \"new_values\" ][ flag ]) line = \" \" . join ( split ) + \" \\n \" lines [ i ] = line except ValueError : print ( \"Error updating simulation file.\" ) print ( f \"Problem file: { self . filename } , Problem flag: { flag } \" ) print ( f \"Problem line: { line } \" ) raise SystemExit # write back file with open ( self . filename , \"w\" ) as fdat : fdat . writelines ( lines )","title":"update()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLFakeHandler","text":"Create Fake RSM files to run tests without ECLIPSE Source code in optuna_hm/handlers/_ecl_simh.py Python class ECLFakeHandler ( ECLBaseHandler ): \"\"\"Create Fake RSM files to run tests without ECLIPSE\"\"\" def __init__ ( self , target , reference , * args ): \"\"\"Constructor Args: target (str): column name from handler.popt to reference (pandas.DataFrame): Dataframe containing RSM results of true solution. *args: Arguments for ECLBaseHandler \"\"\" super () . __init__ ( * args ) self . logger = logging . getLogger ( \"ECLFakeHandler\" ) self . target = target self . reference = reference def __deepcopy__ ( self , memo ): # create a copy but not logger return ECLFakeHandler ( copy . deepcopy ( self . target , memo ), copy . deepcopy ( self . reference , memo ), copy . deepcopy ( self . model_name , memo ), copy . deepcopy ( self . model_path , memo ), copy . deepcopy ( self . popt , memo ), ) def clean_results ( self , modelpath , model ): \"\"\"Remove previous results\"\"\" result_file = os . path . join ( modelpath , model , \".RSM\" ) if os . path . isfile ( result_file ): os . remove ( result_file ) self . logger . info ( \"cleaning previous results\" ) def write_rsm ( self , filepath , rsm_well ): \"\"\"Write out a fake RSM file Args: filepath (str): The filepath for the RSM File rsm_well (pandas.DataFrame): \"\"\" with open ( filepath , \"w\" ) as rsmf : rsmf . write ( \" \\n \" ) rsmf . write ( \" \\t SUMMARY OF RUN GENERATED BY ECLFakeHandler \\n \" ) header = [ \" \\t \" ] for col in rsm_well . columns : header += [ col , \" \\t\\t\\t \" ] header += [ \" \\n \" ] * 4 rsmf . write ( \"\" . join ( header )) ncol = len ( rsm_well . columns ) data_template = \" \\t \" + \" {:>8g} \\t\\t \" * ncol for _ , val in rsm_well . iterrows (): rsmf . write ( data_template . format ( * val ) + \" \\n \" ) def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the simulator\"\"\" param = numpy . r_ [ self . retrieve_ecl_prop ()] misfit = ( numpy . sum ( numpy . sqrt ( numpy . square ( param / self . popt [ self . target ] . values - 1 )) ) / param . size ) scalar = 1 + misfit rsm_well = pd . DataFrame () rsm_well [ \"TIME\" ] = self . reference [ \"TIME\" ] for col in self . reference . drop ( columns = \"TIME\" ) . columns : rsm_well [ col + \"H\" ] = self . reference [ col ] rsm_well [ col ] = self . reference [ col ] / scalar filepath = os . path . join ( self . model_path , self . model_name + \".RSM\" ) self . write_rsm ( filepath , rsm_well )","title":"ECLFakeHandler"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLFakeHandler.__init__","text":"Constructor Parameters: Name Type Description Default target str column name from handler.popt to required reference pandas.DataFrame Dataframe containing RSM results of true solution. required *args Arguments for ECLBaseHandler () Source code in optuna_hm/handlers/_ecl_simh.py Python def __init__ ( self , target , reference , * args ): \"\"\"Constructor Args: target (str): column name from handler.popt to reference (pandas.DataFrame): Dataframe containing RSM results of true solution. *args: Arguments for ECLBaseHandler \"\"\" super () . __init__ ( * args ) self . logger = logging . getLogger ( \"ECLFakeHandler\" ) self . target = target self . reference = reference","title":"__init__()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLFakeHandler.clean_results","text":"Remove previous results Source code in optuna_hm/handlers/_ecl_simh.py Python def clean_results ( self , modelpath , model ): \"\"\"Remove previous results\"\"\" result_file = os . path . join ( modelpath , model , \".RSM\" ) if os . path . isfile ( result_file ): os . remove ( result_file ) self . logger . info ( \"cleaning previous results\" )","title":"clean_results()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLFakeHandler.launch","text":"Launch the simulator Source code in optuna_hm/handlers/_ecl_simh.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the simulator\"\"\" param = numpy . r_ [ self . retrieve_ecl_prop ()] misfit = ( numpy . sum ( numpy . sqrt ( numpy . square ( param / self . popt [ self . target ] . values - 1 )) ) / param . size ) scalar = 1 + misfit rsm_well = pd . DataFrame () rsm_well [ \"TIME\" ] = self . reference [ \"TIME\" ] for col in self . reference . drop ( columns = \"TIME\" ) . columns : rsm_well [ col + \"H\" ] = self . reference [ col ] rsm_well [ col ] = self . reference [ col ] / scalar filepath = os . path . join ( self . model_path , self . model_name + \".RSM\" ) self . write_rsm ( filepath , rsm_well )","title":"launch()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_simh.ECLFakeHandler.write_rsm","text":"Write out a fake RSM file Parameters: Name Type Description Default filepath str The filepath for the RSM File required rsm_well pandas.DataFrame required Source code in optuna_hm/handlers/_ecl_simh.py Python def write_rsm ( self , filepath , rsm_well ): \"\"\"Write out a fake RSM file Args: filepath (str): The filepath for the RSM File rsm_well (pandas.DataFrame): \"\"\" with open ( filepath , \"w\" ) as rsmf : rsmf . write ( \" \\n \" ) rsmf . write ( \" \\t SUMMARY OF RUN GENERATED BY ECLFakeHandler \\n \" ) header = [ \" \\t \" ] for col in rsm_well . columns : header += [ col , \" \\t\\t\\t \" ] header += [ \" \\n \" ] * 4 rsmf . write ( \"\" . join ( header )) ncol = len ( rsm_well . columns ) data_template = \" \\t \" + \" {:>8g} \\t\\t \" * ncol for _ , val in rsm_well . iterrows (): rsmf . write ( data_template . format ( * val ) + \" \\n \" ) A compilation of common evaluation functions used for eclipse optimisation projects. Author Tony Hallam 2020","title":"write_rsm()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_eval.Error","text":"Base class for other exceptions Source code in optuna_hm/handlers/_ecl_eval.py Python class Error ( Exception ): \"\"\"Base class for other exceptions\"\"\" def __init__ ( self , message = None ): self . message = message logger . error ( message ) super () . __init__ ()","title":"Error"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_eval.SimulationRunError","text":"Raised when the input value is too small Source code in optuna_hm/handlers/_ecl_eval.py Python class SimulationRunError ( Error ): \"\"\"Raised when the input value is too small\"\"\" pass","title":"SimulationRunError"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_eval.evaluate_eclipse_model","text":"Evaluate an eclipse model. Parameters: Name Type Description Default simulator mophim.eclipse.EclBaseHandler The initialised simulator class object which can be derived from EclBaseHandler required results_dir str, pathlib.Path A directory, the directory must exist. None Source code in optuna_hm/handlers/_ecl_eval.py Python def evaluate_eclipse_model ( simulator , results_dir = None , save_model_run = False , save_summary_results = False , save_properties_results = False , save_model_files = None , sleep = 5 , working_cwd = None , run_sim = True , update_prop = True , summary_results_kwargs = None , properties_results_kwargs = None , ** kwargs , ): \"\"\"Evaluate an eclipse model. Args: simulator (mophim.eclipse.EclBaseHandler): The initialised simulator class object which can be derived from EclBaseHandler results_dir (str, pathlib.Path): A directory, the directory must exist. \"\"\" if not isinstance ( simulator , ECLBaseHandler ): raise ValueError ( f \"simulator argument must be of class { type ( ECLBaseHandler ) } , got { type ( simulator ) } \" ) if results_dir is None : results_dir = pathlib . Path ( \".\" ) . absolute () else : results_dir = pathlib . Path ( results_dir ) . absolute () if not results_dir . is_dir (): raise ValueError ( f \"results_dir must be directory and exist { results_dir } \" ) results = kwargs [ \"results\" ] optimiser = results [ \"sampler\" ] evaluation = results [ \"trial_number\" ] # create working sim logger . info ( f \"Starting { optimiser } trial number { evaluation } \" ) working_simulator = simulator . create_working_model ( working_cwd = working_cwd ) time . sleep ( sleep ) if update_prop : working_simulator . update_ecl_prop ( results [ \"p\" ]) if run_sim : working_simulator . launch () # Wait for simulation finalisation and cleanup time . sleep ( sleep ) # Save model files if requested if save_model_files is not None : model_files_save_path = results_dir / \"model_files\" try : model_files_save_path . mkdir () except FileExistsError : pass working_simulator . save_model_outputs ( model_files_save_path , save_model_files ) model_path_name = ( pathlib . Path ( working_simulator . temp_dir . name ) / working_simulator . model_name ) # Save whole model run if save_model_run : working_simulator . save_model ( results_dir / \"ecl_models\" , prefix = f \" { int ( evaluation ) : 05d } \" ) # read in simulation summary data try : summary_results = { \"well\" : None , \"failed\" : False } if summary_results_kwargs is not None : summary_results = _get_ecl_sumspec_results ( model_path_name , ** summary_results_kwargs ) else : summary_results = _get_ecl_sumspec_results ( model_path_name ) except SimulationOutputError : # simulation failed. logger . warning ( \"Results file not found %s \" , str ( model_path_name )) summary_results = { \"failed\" : True , \"well\" : None , \"end_date\" : pd . to_datetime ( 0 )} except KeyError as err : # simulation failed. logger . warning ( \"Results keys missing from summary %s \" , err ) summary_results = { \"failed\" : True , \"well\" : None , \"end_date\" : pd . to_datetime ( 0 )} except SimulationRunError as err : # simulation raised errors - probably failed logger . warning ( \"Simulation run failed. %s \" , err ) summary_results = { \"failed\" : True , \"well\" : None , \"end_date\" : pd . to_datetime ( 0 )} if summary_results [ \"well\" ] is not None and save_summary_results : name = \" {} _ {:04d} _summary.hdf5\" . format ( optimiser , evaluation ) summary_results_path = results_dir / \"summary\" try : summary_results_path . mkdir () except FileExistsError : pass summary_results_path_name = summary_results_path / name summary_results [ \"well\" ] . to_hdf ( summary_results_path_name , \"name\" , mode = \"w\" , format = \"table\" ) del summary_results [ \"well\" ] summary_results [ \"well\" ] = str ( summary_results_path_name ) logger . info ( f \"Summary results hdf5 output { summary_results_path / name } \" ) # read in simulation property data try : eclsim = None if properties_results_kwargs is not None : eclsim = _get_ecl_properties_sub ( model_path_name , ** properties_results_kwargs ) # print(\"eclsim_ret\", eclsim) # except IOError as err: # logger.info(f\"Problems reading property results evaluation {evaluation}\") # print(err) # property_results = {\"eclsim\": eclsim, \"failed\": True} except ( IOError , OSError , SimulationOutputError ) as err : logger . warning ( f \"Problems reading property results evaluation { evaluation } \" ) property_results = { \"eclsim\" : eclsim , \"failed\" : True } except KeyError as err : logger . warning ( f \"Keys not found in results file evaluation { evaluation } \" ) property_results = { \"eclsim\" : eclsim , \"failed\" : True } else : property_results = { \"eclsim\" : eclsim , \"failed\" : False } if property_results [ \"eclsim\" ] is not None and save_properties_results : name = \" {} _ {:04d} _eclsim\" . format ( optimiser , evaluation ) property_results_path = results_dir / \"eclsim\" try : property_results_path . mkdir () except FileExistsError : pass eclsim_save_path_name = property_results_path / name property_results [ \"eclsim\" ] . save ( eclsim_save_path_name ) del property_results [ \"eclsim\" ] property_results [ \"eclsim\" ] = str ( eclsim_save_path_name ) logger . info ( f \"Summary results eclsim output { property_results_path / name } \" ) if summary_results [ \"failed\" ] is True or property_results [ \"failed\" ] is True : failed = True else : failed = False results . update ( summary_results ) results . update ( property_results ) results [ \"failed\" ] = failed results . update ({ \"model_id\" : working_simulator . id }) working_simulator . cleanup ( sleep = sleep ) logger . info ( f \"Eclipse run finished and data loaded, trial number { results [ 'trial_number' ] } \" ) return results","title":"evaluate_eclipse_model()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers._ecl_eval.evaluate_well_prod","text":"Calculated the misfit between all log pairs using method and returns a results dictionary labelled by the first log in the pair. Parameters: Name Type Description Default log_pairs list[(, ), ] A list of length 2 tuples which match labels in the input dataframe passed by the mopphim_kwargs 'results' required date_range tuple(str, str Filter the dataframe based upon a date range. The index of the input dataframe will need to be of type datetime. If the str is empty e.g. \"\" then the filter will be open in that direction. E.g. ('2020-2-02', '') or ('2020-2-02'. '2020-4-04') None columns list List of DataFrame values to perform metric on. required Source code in optuna_hm/handlers/_ecl_eval.py Python def evaluate_well_prod ( log_pairs , date_range = None , method = \"kge\" , data_key = \"well\" , null_fitness = None , ** kwargs , ): \"\"\"Calculated the misfit between all log pairs using method and returns a results dictionary labelled by the first log in the pair. Args: log_pairs (list[(, ), ]): A list of length 2 tuples which match labels in the input dataframe passed by the mopphim_kwargs['results'][data_key] date_range (tuple(str, str)): Filter the dataframe based upon a date range. The index of the input dataframe will need to be of type datetime. If the str is empty e.g. \"\" then the filter will be open in that direction. E.g. ('2020-2-02', '') or ('2020-2-02'. '2020-4-04') columns (list): List of DataFrame values to perform metric on. \"\"\" # set output metrics to null_fitness metrics = { p1 : null_fitness for p1 , _ in log_pairs } if kwargs [ \"results\" ][ \"failed\" ] and kwargs [ \"results\" ][ \"well\" ] is None : return metrics results = kwargs [ \"results\" ] data_path_name = kwargs [ \"results\" ][ data_key ] data = pd . read_hdf ( data_path_name ) available_logs = data . columns output_metrics = dict () if data is None : logger . debug ( \"Missing well results from ECL run. Skipping well evaluation.\" ) return metrics # check log_pairs for log in np . array ( log_pairs ) . flatten (): if not log in available_logs : raise ValueError ( f \"log { log } was not in results\" ) clean_data = data . dropna () if date_range is not None : clean_data = clean_data [ date_range [ 0 ] : date_range [ 1 ]] if clean_data . shape [ 0 ] == 0 : logger . debug ( \"data is empty, check date_range/simulation\" ) return metrics # NOT SURE IF THIS IS STILL NEEDED # no_data = [c for c in plogs if clean_data[c[0]].sum() == 0] # plogs = [c for c in plogs if clean_data[c[0]].sum() > 0] # for c in no_data: # metrics[c[0]] = np.nan if method == \"kge\" : # kling-gupta efficieny for p1 , p2 in log_pairs : output_metrics [ p1 ] = 1 - kge ( clean_data [ p1 ] . values , clean_data [ p2 ] . values , maxfitness = null_fitness , # incase method fails ) # elif method == \"mse\": # scaler = StandardScaler() # data_norm = clean_data.copy() # data_norm.loc[:, :] = scaler.fit_transform(clean_data.values) # for col in plogs: # metrics[col[0]] = mean_squared_error( # data_norm[col[0]].values, data_norm[col[1]].values # ) else : raise ValueError ( f \"Unknown method { method } \" ) logger ( f \"Completed well evaluation, trial_number { results [ 'trial_number' ] } \" ) return output_metrics","title":"evaluate_well_prod()"},{"location":"ophm/api_handlers.html#optuna_hmhandlersflow","text":"Flow is an alternative open-source simulator to Eclipse. It uses similar files as input and output but has a slightly different call signature. This module modifies the Eclipse methods to suit flow where needed. Evaluation and metrics functions from Eclipse can be used with Flow. Handler module for external file and process handling of ECLIPSE flow simulator - Schlumberger hand_ecl100 - Claus Aranha (caranha@cs.tsukuba.ac.jp) hand_ecldat - Tony Hallam","title":"optuna_hm.handlers.flow"},{"location":"ophm/api_handlers.html#optuna_hm.handlers.flow.FlowHandler","text":"modifies ECLBaseHandler to deal with flow. Source code in optuna_hm/handlers/flow.py Python class FlowHandler ( ECLBaseHandler ): \"\"\" modifies ECLBaseHandler to deal with flow. \"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"FlowHandler\" ) def __deepcopy__ ( self , memo ): # need to create a special copy function because the logger cannot be coppied # this means reinitialisation is necessary for each new simulator class args = [ self . __dict__ [ var ] for var in [ \"model_name\" , \"model_path\" , \"popt\" , \"simexe\" , \"time_out\" , \"silent\" , ] ] return FlowHandler ( * args ) def clean_results (): # FIXME: delete results file from self.model_path # beginning with self.model_name pass def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the flow simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" model_arg = \"--parameter-file=\" + str ( self . model_name ) + \".PARAM\" self . logger . info ( \"running model at %s \" , self . model_path ) return super () . launch ( model_arg )","title":"FlowHandler"},{"location":"ophm/api_handlers.html#optuna_hm.handlers.flow.FlowHandler.__init__","text":"See ECLBaseHandler Notes: Source code in optuna_hm/handlers/flow.py Python def __init__ ( self , * args , ** kwargs ): \"\"\"See ECLBaseHandler Notes: \"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"FlowHandler\" )","title":"__init__()"},{"location":"ophm/api_handlers.html#optuna_hm.handlers.flow.FlowHandler.launch","text":"Launch the flow simulator. Returns: Type Description bool True if run did not timeout. Source code in optuna_hm/handlers/flow.py Python def launch ( self , * cmdargs , ** cmdkwargs ): \"\"\"Launch the flow simulator. Args: None Returns: bool: True if run did not timeout. \"\"\" model_arg = \"--parameter-file=\" + str ( self . model_name ) + \".PARAM\" self . logger . info ( \"running model at %s \" , self . model_path ) return super () . launch ( model_arg )","title":"launch()"},{"location":"ophm/api_metrics.html","text":"Metrics Python from optuna_hm import metrics Functions for evaluation of data differences aka difference metrics This module is a port of internal functions for MOPHiM Vectorised by Tony Hallam 2019 correlation ( m1 , m2 ) Correlation metric Parameters: Name Type Description Default m1 ndarray Array 1 required m2 ndarray Array 2 required Returns: Type Description float metric Source code in optuna_hm/metrics/_metrics.py Python def correlation ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Correlation metric Args: m1: Array 1 m2: Array 2 Returns: metric \"\"\" a = ( m1 - np . mean ( m1 )) / np . std ( m1 ) b = ( m2 - np . mean ( m2 )) / np . std ( m2 ) return 1 - np . abs ( np . sum ( a * b ) / m1 . size ) denom_zdiv ( a , b ) Helper function to avoid divide by zero in many areas. Parameters: Name Type Description Default a array-like Numerator required b array-like Deominator required Returns: Type Description a/b (array-like) Replace div0 by 0 Source code in optuna_hm/metrics/_metrics.py Python def denom_zdiv ( a : np . ndarray , b : np . ndarray ) -> np . ndarray : \"\"\"Helper function to avoid divide by zero in many areas. Args: a (array-like): Numerator b (array-like): Deominator Returns: a/b (array-like): Replace div0 by 0 \"\"\" return np . divide ( a , b , out = np . zeros_like ( b ), where = b != 0.0 ) kendall_tau ( m1 , m2 ) Kendall-Tau Parameters: Name Type Description Default m1 ndarray Array 1 required m2 ndarray Array 2 required Returns: Type Description float metric Source code in optuna_hm/metrics/_metrics.py Python def kendall_tau ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Kendall-Tau Args: m1: Array 1 m2: Array 2 Returns: metric \"\"\" m1 = m1 . flatten () m2 = m2 . flatten () n = m1 . size i_ = np . zeros ( np . sum ( np . arange ( 0 , n )), dtype = int ) j_ = np . zeros_like ( i_ , dtype = int ) k = 0 for i in range ( n ): for j in range ( n - i - 1 ): i_ [ k ] = i j_ [ k ] = j + i + 1 k += 1 nc = np . sum ( np . sign ( m1 [ i_ ] - m1 [ j_ ]) == np . sign ( m2 [ i_ ] - m2 [ j_ ])) nd = k - nc return 1 - ( nc - nd ) / ( n * ( n - 1 ) / 2 ) kge ( m1 , m2 , maxfitness = 100 , s = ( 1 , 1 , 1 ), return_all = False ) COPIED FROM HydroErr Python Package Compute the Kling-Gupta efficiency (2012). Notes : The Range -inf < KGE (2012) < 1, does not indicate bias, larger is better. This is the modified version of the KGE (2009). Kling proposed this version to avoid cross-correlation between bias and variability ratios. Parameters: Name Type Description Default m1 ndarray An array (1D) of simulated data from the time series. required m2 ndarray An array (1D) of observed data from the time series. required s (tuple of length three) Represents the scaling factors to be used for re-scaling the Pearson product-moment correlation coefficient \u00ae, gamma, and Beta, respectively. (1, 1, 1) maxfitness float Return if kge failes. 100 return_all bool If True, returns all of the components of the KGE metric, which are r, gamma, and beta, respectively. False Returns: Type Description float The Kling-Gupta (2012) efficiency value, unless the return_all parameter is True. Refs Kling, H., Fuchs, M., & Paulin, M. (2012). Runoff conditions in the upper Danube basin under an ensemble of climate change scenarios. Journal of Hydrology, 424, 264-277. Source code in optuna_hm/metrics/_metrics.py Python def kge ( m1 : np . ndarray , m2 : np . ndarray , maxfitness : float = 100 , s = ( 1 , 1 , 1 ), return_all : bool = False ) -> float : \"\"\" COPIED FROM HydroErr Python Package Compute the Kling-Gupta efficiency (2012). ***Notes***: - **The Range** -inf < KGE (2012) < 1, does not indicate bias, larger is better. - This is the modified version of the KGE (2009). Kling proposed this version to avoid cross-correlation between bias and variability ratios. Args: m1: An array (1D) of simulated data from the time series. m2: An array (1D) of observed data from the time series. s: (tuple of length three) Represents the scaling factors to be used for re-scaling the Pearson product-moment correlation coefficient (r), gamma, and Beta, respectively. maxfitness: Return if kge failes. return_all: If True, returns all of the components of the KGE metric, which are r, gamma, and beta, respectively. Returns: The Kling-Gupta (2012) efficiency value, unless the return_all parameter is True. Refs: Kling, H., Fuchs, M., & Paulin, M. (2012). Runoff conditions in the upper Danube basin under an ensemble of climate change scenarios. Journal of Hydrology, 424, 264-277. \"\"\" # Means sim_mean = np . nanmean ( m1 ) obs_mean = np . nanmean ( m2 ) m1 = np . where ( np . isnan ( m1 ), sim_mean , m1 ) m2 = np . where ( np . isnan ( m2 ), obs_mean , m2 ) # Standard Deviations sim_sigma = np . std ( m1 ) obs_sigma = np . std ( m2 ) # Pearson R top_pr = np . sum (( m2 - obs_mean ) * ( m1 - sim_mean )) bot1_pr = np . sqrt ( np . sum (( m2 - obs_mean ) ** 2 )) bot2_pr = np . sqrt ( np . sum (( m1 - sim_mean ) ** 2 )) pear_r = top_pr / ( bot1_pr * bot2_pr ) # Ratio between mean of simulated and observed data beta = sim_mean / obs_mean # CV is the coefficient of variation (standard deviation / mean) sim_cv = sim_sigma / sim_mean obs_cv = obs_sigma / obs_mean # Variability Ratio, or the ratio of simulated CV to observed CV gam = sim_cv / obs_cv if obs_mean != 0 and obs_sigma != 0 and sim_mean != 0 : kge_meas = 1 - np . sqrt ( ( s [ 0 ] * ( pear_r - 1 )) ** 2 + ( s [ 1 ] * ( gam - 1 )) ** 2 + ( s [ 2 ] * ( beta - 1 )) ** 2 ) else : kge_meas = - maxfitness if return_all : return pear_r , gam , beta , kge_meas else : return kge_meas minimum_ratio ( m1 , m2 ) Minimum ratio between two arrays m1 and m2 have same shape Parameters: Name Type Description Default m1 ndarray Array 1 required m2 ndarray Array 2 required Returns: Type Description float The disimilarity metric Note While the minimum ratio is a similarity metric this function return (1 - this) for the disimilarity measure. Source code in optuna_hm/metrics/_metrics.py Python def minimum_ratio ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Minimum ratio between two arrays m1 and m2 have same shape Args: m1: Array 1 m2: Array 2 Returns: The disimilarity metric Note: While the minimum ratio is a similarity metric this function return (1 - this) for the disimilarity measure. \"\"\" m1 = m1 . astype ( float ) m2 = m2 . astype ( float ) ret = np . zeros_like ( m1 ) both_zero = np . logical_and ( m1 == 0 , m2 == 0 ) both_nonzero = np . logical_and ( m1 != 0 , m2 != 0 ) ret = np . where ( both_nonzero , np . minimum ( denom_zdiv ( m1 , m2 ), denom_zdiv ( m2 , m1 )), ret ) ret = np . where ( both_zero , 1 , ret ) return 1.0 - ( np . sum ( ret ) / m1 . size ) mse ( m1 , m2 ) Mean square error of two matrices Parameters: Name Type Description Default m1 ndarray Matrix 1 required m2 ndarray Matrix 2 required Returns: Type Description float mse for m1 m2 Source code in optuna_hm/metrics/_metrics.py Python def mse ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Mean square error of two matrices Args: m1: Matrix 1 m2: Matrix 2 Returns: mse for m1 m2 \"\"\" return np . square ( np . subtract ( m1 , m2 )) . mean () norm ( m1 , m2 ) Calculates and returns the differences between two matrices Parameters: Name Type Description Default m1 ndarray Matrix 1 required m2 ndarray Matrix 2 required Returns: Type Description float Normalised difference of m1 and m2 Source code in optuna_hm/metrics/_metrics.py Python def norm ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Calculates and returns the differences between two matrices Args: m1: Matrix 1 m2: Matrix 2 Returns: Normalised difference of m1 and m2 \"\"\" difference = 0 for i , j in zip ( m1 , m2 ): # http://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy ii = np . array ( i ) jj = np . array ( j ) difference += (( ii - jj ) ** 2 ) . mean () return difference pixel_error ( true , test , mode = 'mse' , normalise = True ) Simple pixel bases comparison metric. Other metrics for testing should have this form. Other functions can have multiple kwargs. Parameters: Name Type Description Default true nd.array The truth array. required test nd.array The array to compare to truth. required mode str The mode of comparison for this function. 'mse' Returns: Type Description float The misfit metric. Source code in optuna_hm/metrics/_metrics.py Python def pixel_error ( true , test , mode = \"mse\" , normalise = True ): \"\"\"Simple pixel bases comparison metric. Other metrics for testing should have this form. Other functions can have multiple kwargs. Args: true (nd.array): The truth array. test (nd.array): The array to compare to truth. mode (str): The mode of comparison for this function. Returns: float: The misfit metric. \"\"\" if normalise : std_tru = np . nanstd ( true ) std_tst = np . nanstd ( test ) test = test * ( std_tru / std_tst ) if mode == \"mse\" : return np . nanmean ( np . square ( true - test )) if mode == \"absum\" : return np . nansum ( np . abs ( true - test ))","title":"Metrics"},{"location":"ophm/api_metrics.html#metrics","text":"Python from optuna_hm import metrics Functions for evaluation of data differences aka difference metrics This module is a port of internal functions for MOPHiM Vectorised by Tony Hallam 2019","title":"Metrics"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.correlation","text":"Correlation metric Parameters: Name Type Description Default m1 ndarray Array 1 required m2 ndarray Array 2 required Returns: Type Description float metric Source code in optuna_hm/metrics/_metrics.py Python def correlation ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Correlation metric Args: m1: Array 1 m2: Array 2 Returns: metric \"\"\" a = ( m1 - np . mean ( m1 )) / np . std ( m1 ) b = ( m2 - np . mean ( m2 )) / np . std ( m2 ) return 1 - np . abs ( np . sum ( a * b ) / m1 . size )","title":"correlation()"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.denom_zdiv","text":"Helper function to avoid divide by zero in many areas. Parameters: Name Type Description Default a array-like Numerator required b array-like Deominator required Returns: Type Description a/b (array-like) Replace div0 by 0 Source code in optuna_hm/metrics/_metrics.py Python def denom_zdiv ( a : np . ndarray , b : np . ndarray ) -> np . ndarray : \"\"\"Helper function to avoid divide by zero in many areas. Args: a (array-like): Numerator b (array-like): Deominator Returns: a/b (array-like): Replace div0 by 0 \"\"\" return np . divide ( a , b , out = np . zeros_like ( b ), where = b != 0.0 )","title":"denom_zdiv()"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.kendall_tau","text":"Kendall-Tau Parameters: Name Type Description Default m1 ndarray Array 1 required m2 ndarray Array 2 required Returns: Type Description float metric Source code in optuna_hm/metrics/_metrics.py Python def kendall_tau ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Kendall-Tau Args: m1: Array 1 m2: Array 2 Returns: metric \"\"\" m1 = m1 . flatten () m2 = m2 . flatten () n = m1 . size i_ = np . zeros ( np . sum ( np . arange ( 0 , n )), dtype = int ) j_ = np . zeros_like ( i_ , dtype = int ) k = 0 for i in range ( n ): for j in range ( n - i - 1 ): i_ [ k ] = i j_ [ k ] = j + i + 1 k += 1 nc = np . sum ( np . sign ( m1 [ i_ ] - m1 [ j_ ]) == np . sign ( m2 [ i_ ] - m2 [ j_ ])) nd = k - nc return 1 - ( nc - nd ) / ( n * ( n - 1 ) / 2 )","title":"kendall_tau()"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.kge","text":"COPIED FROM HydroErr Python Package Compute the Kling-Gupta efficiency (2012). Notes : The Range -inf < KGE (2012) < 1, does not indicate bias, larger is better. This is the modified version of the KGE (2009). Kling proposed this version to avoid cross-correlation between bias and variability ratios. Parameters: Name Type Description Default m1 ndarray An array (1D) of simulated data from the time series. required m2 ndarray An array (1D) of observed data from the time series. required s (tuple of length three) Represents the scaling factors to be used for re-scaling the Pearson product-moment correlation coefficient \u00ae, gamma, and Beta, respectively. (1, 1, 1) maxfitness float Return if kge failes. 100 return_all bool If True, returns all of the components of the KGE metric, which are r, gamma, and beta, respectively. False Returns: Type Description float The Kling-Gupta (2012) efficiency value, unless the return_all parameter is True. Refs Kling, H., Fuchs, M., & Paulin, M. (2012). Runoff conditions in the upper Danube basin under an ensemble of climate change scenarios. Journal of Hydrology, 424, 264-277. Source code in optuna_hm/metrics/_metrics.py Python def kge ( m1 : np . ndarray , m2 : np . ndarray , maxfitness : float = 100 , s = ( 1 , 1 , 1 ), return_all : bool = False ) -> float : \"\"\" COPIED FROM HydroErr Python Package Compute the Kling-Gupta efficiency (2012). ***Notes***: - **The Range** -inf < KGE (2012) < 1, does not indicate bias, larger is better. - This is the modified version of the KGE (2009). Kling proposed this version to avoid cross-correlation between bias and variability ratios. Args: m1: An array (1D) of simulated data from the time series. m2: An array (1D) of observed data from the time series. s: (tuple of length three) Represents the scaling factors to be used for re-scaling the Pearson product-moment correlation coefficient (r), gamma, and Beta, respectively. maxfitness: Return if kge failes. return_all: If True, returns all of the components of the KGE metric, which are r, gamma, and beta, respectively. Returns: The Kling-Gupta (2012) efficiency value, unless the return_all parameter is True. Refs: Kling, H., Fuchs, M., & Paulin, M. (2012). Runoff conditions in the upper Danube basin under an ensemble of climate change scenarios. Journal of Hydrology, 424, 264-277. \"\"\" # Means sim_mean = np . nanmean ( m1 ) obs_mean = np . nanmean ( m2 ) m1 = np . where ( np . isnan ( m1 ), sim_mean , m1 ) m2 = np . where ( np . isnan ( m2 ), obs_mean , m2 ) # Standard Deviations sim_sigma = np . std ( m1 ) obs_sigma = np . std ( m2 ) # Pearson R top_pr = np . sum (( m2 - obs_mean ) * ( m1 - sim_mean )) bot1_pr = np . sqrt ( np . sum (( m2 - obs_mean ) ** 2 )) bot2_pr = np . sqrt ( np . sum (( m1 - sim_mean ) ** 2 )) pear_r = top_pr / ( bot1_pr * bot2_pr ) # Ratio between mean of simulated and observed data beta = sim_mean / obs_mean # CV is the coefficient of variation (standard deviation / mean) sim_cv = sim_sigma / sim_mean obs_cv = obs_sigma / obs_mean # Variability Ratio, or the ratio of simulated CV to observed CV gam = sim_cv / obs_cv if obs_mean != 0 and obs_sigma != 0 and sim_mean != 0 : kge_meas = 1 - np . sqrt ( ( s [ 0 ] * ( pear_r - 1 )) ** 2 + ( s [ 1 ] * ( gam - 1 )) ** 2 + ( s [ 2 ] * ( beta - 1 )) ** 2 ) else : kge_meas = - maxfitness if return_all : return pear_r , gam , beta , kge_meas else : return kge_meas","title":"kge()"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.minimum_ratio","text":"Minimum ratio between two arrays m1 and m2 have same shape Parameters: Name Type Description Default m1 ndarray Array 1 required m2 ndarray Array 2 required Returns: Type Description float The disimilarity metric Note While the minimum ratio is a similarity metric this function return (1 - this) for the disimilarity measure. Source code in optuna_hm/metrics/_metrics.py Python def minimum_ratio ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Minimum ratio between two arrays m1 and m2 have same shape Args: m1: Array 1 m2: Array 2 Returns: The disimilarity metric Note: While the minimum ratio is a similarity metric this function return (1 - this) for the disimilarity measure. \"\"\" m1 = m1 . astype ( float ) m2 = m2 . astype ( float ) ret = np . zeros_like ( m1 ) both_zero = np . logical_and ( m1 == 0 , m2 == 0 ) both_nonzero = np . logical_and ( m1 != 0 , m2 != 0 ) ret = np . where ( both_nonzero , np . minimum ( denom_zdiv ( m1 , m2 ), denom_zdiv ( m2 , m1 )), ret ) ret = np . where ( both_zero , 1 , ret ) return 1.0 - ( np . sum ( ret ) / m1 . size )","title":"minimum_ratio()"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.mse","text":"Mean square error of two matrices Parameters: Name Type Description Default m1 ndarray Matrix 1 required m2 ndarray Matrix 2 required Returns: Type Description float mse for m1 m2 Source code in optuna_hm/metrics/_metrics.py Python def mse ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Mean square error of two matrices Args: m1: Matrix 1 m2: Matrix 2 Returns: mse for m1 m2 \"\"\" return np . square ( np . subtract ( m1 , m2 )) . mean ()","title":"mse()"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.norm","text":"Calculates and returns the differences between two matrices Parameters: Name Type Description Default m1 ndarray Matrix 1 required m2 ndarray Matrix 2 required Returns: Type Description float Normalised difference of m1 and m2 Source code in optuna_hm/metrics/_metrics.py Python def norm ( m1 : np . ndarray , m2 : np . ndarray ) -> float : \"\"\"Calculates and returns the differences between two matrices Args: m1: Matrix 1 m2: Matrix 2 Returns: Normalised difference of m1 and m2 \"\"\" difference = 0 for i , j in zip ( m1 , m2 ): # http://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy ii = np . array ( i ) jj = np . array ( j ) difference += (( ii - jj ) ** 2 ) . mean () return difference","title":"norm()"},{"location":"ophm/api_metrics.html#optuna_hm.metrics._metrics.pixel_error","text":"Simple pixel bases comparison metric. Other metrics for testing should have this form. Other functions can have multiple kwargs. Parameters: Name Type Description Default true nd.array The truth array. required test nd.array The array to compare to truth. required mode str The mode of comparison for this function. 'mse' Returns: Type Description float The misfit metric. Source code in optuna_hm/metrics/_metrics.py Python def pixel_error ( true , test , mode = \"mse\" , normalise = True ): \"\"\"Simple pixel bases comparison metric. Other metrics for testing should have this form. Other functions can have multiple kwargs. Args: true (nd.array): The truth array. test (nd.array): The array to compare to truth. mode (str): The mode of comparison for this function. Returns: float: The misfit metric. \"\"\" if normalise : std_tru = np . nanstd ( true ) std_tst = np . nanstd ( test ) test = test * ( std_tru / std_tst ) if mode == \"mse\" : return np . nanmean ( np . square ( true - test )) if mode == \"absum\" : return np . nansum ( np . abs ( true - test ))","title":"pixel_error()"},{"location":"ophm/cli.html","text":"","title":"Cli"},{"location":"ophm/config.html","text":"","title":"Config"},{"location":"ophm/tutorial.html","text":"","title":"Tutorial"},{"location":"opt/cmaes.html","text":"","title":"Cma-Es"},{"location":"opt/intro.html","text":"","title":"Introduction"},{"location":"opt/lexde.html","text":"","title":"Lex-De"},{"location":"sa/intro.html","text":"","title":"Introduction"},{"location":"sa/ovat.html","text":"","title":"OVAT"},{"location":"sa/sobol.html","text":"","title":"Sobol"},{"location":"ug/framework.html","text":"","title":"Optuna-ExternM Framework"}]}